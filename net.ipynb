{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>EmpathNet: the New CherryStems algorithm</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the new Empath musical audio generation with deep learning models. The baseline model is using the reference of an amazing blog post by https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 1: Import libraries</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#library for understanding music\n",
    "from music21 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 2: Read Musical Files</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for reading the MIDI files, it returns the array of notes and choids present in the musical file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to read MIDI files\n",
    "def read_midi(file):\n",
    "    \n",
    "    print(\"Loading Music File:\",file)\n",
    "    \n",
    "    notes=[]\n",
    "    notes_to_parse = None\n",
    "    \n",
    "    #parsing a midi file\n",
    "    midi = converter.parse(file)\n",
    "  \n",
    "    #grouping based on different instruments\n",
    "    s2 = instrument.partitionByInstrument(midi)\n",
    "\n",
    "    #Looping over all the instruments\n",
    "    for part in s2.parts:\n",
    "    \n",
    "        #select elements of only piano\n",
    "        if 'Piano' in str(part): \n",
    "        \n",
    "            notes_to_parse = part.recurse() \n",
    "      \n",
    "            #finding whether a particular element is note or a chord\n",
    "            for element in notes_to_parse:\n",
    "                \n",
    "                #note\n",
    "                if isinstance(element, note.Note):\n",
    "                    notes.append(str(element.pitch))\n",
    "                \n",
    "                #chord\n",
    "                elif isinstance(element, chord.Chord):\n",
    "                    notes.append('.'.join(str(n) for n in element.normalOrder))\n",
    "\n",
    "    return np.array(notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 3: Load the MIDI files into our environment</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Music File: schubert/schumm-1.mid\n",
      "Loading Music File: schubert/schumm-2.mid\n",
      "Loading Music File: schubert/schub_d960_4.mid\n",
      "Loading Music File: schubert/schumm-3.mid\n",
      "Loading Music File: schubert/schub_d960_1.mid\n",
      "Loading Music File: schubert/schumm-6.mid\n",
      "Loading Music File: schubert/schumm-4.mid\n",
      "Loading Music File: schubert/schub_d960_2.mid\n",
      "Loading Music File: schubert/schub_d960_3.mid\n",
      "Loading Music File: schubert/schumm-5.mid\n",
      "Loading Music File: schubert/schuim-4.mid\n",
      "Loading Music File: schubert/schuim-1.mid\n",
      "Loading Music File: schubert/schuim-3.mid\n",
      "Loading Music File: schubert/schuim-2.mid\n",
      "Loading Music File: schubert/schubert_D850_4.mid\n",
      "Loading Music File: schubert/schubert_D935_4.mid\n",
      "Loading Music File: schubert/schub_d760_4.mid\n",
      "Loading Music File: schubert/schubert_D850_1.mid\n",
      "Loading Music File: schubert/schubert_D935_1.mid\n",
      "Loading Music File: schubert/schub_d760_1.mid\n",
      "Loading Music File: schubert/schubert_D850_2.mid\n",
      "Loading Music File: schubert/schub_d760_3.mid\n",
      "Loading Music File: schubert/schubert_D935_2.mid\n",
      "Loading Music File: schubert/schubert_D935_3.mid\n",
      "Loading Music File: schubert/schubert_D850_3.mid\n",
      "Loading Music File: schubert/schub_d760_2.mid\n",
      "Loading Music File: schubert/schu_143_2.mid\n",
      "Loading Music File: schubert/schu_143_3.mid\n",
      "Loading Music File: schubert/schu_143_1.mid\n"
     ]
    }
   ],
   "source": [
    "#for listing down the file names\n",
    "import os\n",
    "\n",
    "#Array Processing\n",
    "import numpy as np\n",
    "\n",
    "#specify the path\n",
    "path='schubert/'\n",
    "\n",
    "#read all the filenames\n",
    "files=[i for i in os.listdir(path) if i.endswith(\".mid\")]\n",
    "\n",
    "#reading each midi file\n",
    "notes_array = np.array([read_midi(path+i) for i in files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 4: Understand the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304\n"
     ]
    }
   ],
   "source": [
    "#converting 2D array into 1D array\n",
    "notes_ = [element for note_ in notes_array for element in note_]\n",
    "\n",
    "#No. of unique notes\n",
    "unique_notes = list(set(notes_))\n",
    "print(len(unique_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Now see the distribution of the notes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([187.,  41.,  26.,  11.,   6.,   9.,  12.,   6.,   3.,   3.]),\n",
       " array([1.0000e+00, 1.4790e+02, 2.9480e+02, 4.4170e+02, 5.8860e+02,\n",
       "        7.3550e+02, 8.8240e+02, 1.0293e+03, 1.1762e+03, 1.3231e+03,\n",
       "        1.4700e+03]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 302,
       "width": 319
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing library\n",
    "from collections import Counter\n",
    "\n",
    "#computing frequency of each note\n",
    "#the use of the word 'freq' means the occurence frequency of notes not the musical frequency\n",
    "freq = dict(Counter(notes_))\n",
    "\n",
    "#library for visualiation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#consider only the frequencies\n",
    "no=[count for _,count in freq.items()]\n",
    "\n",
    "#set the figure size\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "#plot\n",
    "plt.hist(no)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plot, we can infer that most of the notes have a very low frequency. So, let us keep the top frequent notes and ignore the low-frequency ones. Here, I am defining the threshold as 50. Nevertheless, the parameter can be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "frequent_notes = [note_ for note_, count in freq.items() if count>=50]\n",
    "print(len(frequent_notes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 5: Prepare the data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare new musical files which contain only the top frequent notes\n",
    "\n",
    "new_music=[]\n",
    "\n",
    "for notes in notes_array:\n",
    "    temp=[]\n",
    "    for note_ in notes:\n",
    "        if note_ in frequent_notes:\n",
    "            temp.append(note_)            \n",
    "    new_music.append(temp)\n",
    "    \n",
    "new_music = np.array(new_music)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preparing the input and output sequences as mentioned in the article:\n",
    "no_of_timesteps = 32\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for note_ in new_music:\n",
    "    for i in range(0, len(note_) - no_of_timesteps, 1):\n",
    "        \n",
    "        #preparing input and output sequences\n",
    "        input_ = note_[i:i + no_of_timesteps]\n",
    "        output = note_[i + no_of_timesteps]\n",
    "        \n",
    "        x.append(input_)\n",
    "        y.append(output)\n",
    "        \n",
    "x=np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assign a unique integer to every note:\n",
    "unique_x = list(set(x.ravel()))\n",
    "x_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing input sequences\n",
    "x_seq=[]\n",
    "for i in x:\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        #assigning unique integer to every note\n",
    "        temp.append(x_note_to_int[j])\n",
    "    x_seq.append(temp)\n",
    "    \n",
    "x_seq = np.array(x_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## prepare output sequences\n",
    "unique_y = list(set(y))\n",
    "y_note_to_int = dict((note_, number) for number, note_ in enumerate(unique_y)) \n",
    "y_seq=np.array([y_note_to_int[i] for i in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 80% of the data for training and 20% for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_tr, x_val, y_tr, y_val = train_test_split(x_seq,y_seq,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 6: Build Model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>WaveNet model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 32, 100)           16700     \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 32, 64)            19264     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 16, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16, 128)           24704     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 8, 256)            98560     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 167)               42919     \n",
      "=================================================================\n",
      "Total params: 267,939\n",
      "Trainable params: 267,939\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.callbacks import *\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()\n",
    "model = Sequential()\n",
    "    \n",
    "#embedding layer\n",
    "model.add(Embedding(len(unique_x), 100, input_length=32, trainable=True)) \n",
    "\n",
    "model.add(Conv1D(64,3, padding='causal', activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "    \n",
    "model.add(Conv1D(128,3,activation='relu',dilation_rate=2,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "\n",
    "model.add(Conv1D(256,3,activation='relu',dilation_rate=4,padding='causal'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(2))\n",
    "          \n",
    "#model.add(Conv1D(256,5,activation='relu'))    \n",
    "model.add(GlobalMaxPool1D())\n",
    "    \n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(len(unique_y), activation='softmax'))\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>LSTM model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(128,return_sequences=True))\n",
    "model2.add(LSTM(128))\n",
    "model2.add(Dense(256))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dense(256))\n",
    "model2.add(Activation('softmax'))\n",
    "model2.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Define the callback to save the best model during training</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc=ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True,verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 7: Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from last time\n"
     ]
    }
   ],
   "source": [
    "#loading best model from previous training if available\n",
    "from keras.models import load_model\n",
    "\n",
    "try:\n",
    "    previous_model = load_model('best_model.h5')\n",
    "    model = previous_model\n",
    "    print(\"loaded from last time\")\n",
    "except ImportError:\n",
    "    print(\"starting a new model\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51530 samples, validate on 12883 samples\n",
      "Epoch 1/3000\n",
      "51530/51530 [==============================] - 13s 261us/step - loss: 1.8033 - val_loss: 2.5675\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.56749, saving model to best_model.h5\n",
      "Epoch 2/3000\n",
      "51530/51530 [==============================] - 13s 260us/step - loss: 1.8079 - val_loss: 2.5733\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.56749\n",
      "Epoch 3/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.8131 - val_loss: 2.5718\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.56749\n",
      "Epoch 4/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.8072 - val_loss: 2.5720\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.56749\n",
      "Epoch 5/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8073 - val_loss: 2.5716\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.56749\n",
      "Epoch 6/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.8074 - val_loss: 2.5692\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.56749\n",
      "Epoch 7/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.8008 - val_loss: 2.5885\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.56749\n",
      "Epoch 8/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.8057 - val_loss: 2.5773\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.56749\n",
      "Epoch 9/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.8128 - val_loss: 2.5761\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.56749\n",
      "Epoch 10/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.8020 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.56749\n",
      "Epoch 11/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.8024 - val_loss: 2.5694\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.56749\n",
      "Epoch 12/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8004 - val_loss: 2.5636\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.56749 to 2.56357, saving model to best_model.h5\n",
      "Epoch 13/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8017 - val_loss: 2.5720\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.56357\n",
      "Epoch 14/3000\n",
      "51530/51530 [==============================] - 19s 374us/step - loss: 1.7986 - val_loss: 2.5581\n",
      "\n",
      "Epoch 00014: val_loss improved from 2.56357 to 2.55809, saving model to best_model.h5\n",
      "Epoch 15/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.8093 - val_loss: 2.5550\n",
      "\n",
      "Epoch 00015: val_loss improved from 2.55809 to 2.55497, saving model to best_model.h5\n",
      "Epoch 16/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7952 - val_loss: 2.5679\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.55497\n",
      "Epoch 17/3000\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 1.8044 - val_loss: 2.5669\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.55497\n",
      "Epoch 18/3000\n",
      "51530/51530 [==============================] - 19s 369us/step - loss: 1.8123 - val_loss: 2.5697\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.55497\n",
      "Epoch 19/3000\n",
      "51530/51530 [==============================] - 21s 411us/step - loss: 1.8109 - val_loss: 2.5636\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.55497\n",
      "Epoch 20/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.8100 - val_loss: 2.5581\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.55497\n",
      "Epoch 21/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.8042 - val_loss: 2.5622\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.55497\n",
      "Epoch 22/3000\n",
      "51530/51530 [==============================] - 19s 368us/step - loss: 1.8018 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.55497\n",
      "Epoch 23/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7964 - val_loss: 2.5728\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.55497\n",
      "Epoch 24/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7991 - val_loss: 2.5606\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.55497\n",
      "Epoch 25/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.8090 - val_loss: 2.5704\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.55497\n",
      "Epoch 26/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.8198 - val_loss: 2.5797\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.55497\n",
      "Epoch 27/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7933 - val_loss: 2.5762\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.55497\n",
      "Epoch 28/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.8059 - val_loss: 2.5687\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.55497\n",
      "Epoch 29/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.8037 - val_loss: 2.5804\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.55497\n",
      "Epoch 30/3000\n",
      "51530/51530 [==============================] - 19s 372us/step - loss: 1.8088 - val_loss: 2.5664\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.55497\n",
      "Epoch 31/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.8110 - val_loss: 2.5630\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.55497\n",
      "Epoch 32/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.8122 - val_loss: 2.5771\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.55497\n",
      "Epoch 33/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.8099 - val_loss: 2.5752\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.55497\n",
      "Epoch 34/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7997 - val_loss: 2.5726\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.55497\n",
      "Epoch 35/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.8084 - val_loss: 2.5628\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.55497\n",
      "Epoch 36/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.8066 - val_loss: 2.5770\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.55497\n",
      "Epoch 37/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.8014 - val_loss: 2.5667\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.55497\n",
      "Epoch 38/3000\n",
      "51530/51530 [==============================] - 19s 378us/step - loss: 1.8147 - val_loss: 2.5649\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.55497\n",
      "Epoch 39/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.8036 - val_loss: 2.5729\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.55497\n",
      "Epoch 40/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8040 - val_loss: 2.5716\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.55497\n",
      "Epoch 41/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.8106 - val_loss: 2.5795\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.55497\n",
      "Epoch 42/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7999 - val_loss: 2.5770\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.55497\n",
      "Epoch 43/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7990 - val_loss: 2.5780\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.55497\n",
      "Epoch 44/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.8026 - val_loss: 2.5652\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.55497\n",
      "Epoch 45/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.8015 - val_loss: 2.5704\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.55497\n",
      "Epoch 46/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.8019 - val_loss: 2.5862\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.55497\n",
      "Epoch 47/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.8009 - val_loss: 2.5806\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.55497\n",
      "Epoch 48/3000\n",
      "51530/51530 [==============================] - 17s 338us/step - loss: 1.8143 - val_loss: 2.5884\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.55497\n",
      "Epoch 49/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7960 - val_loss: 2.5687\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.55497\n",
      "Epoch 50/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.8029 - val_loss: 2.5726\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.55497\n",
      "Epoch 51/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.8014 - val_loss: 2.5749\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.55497\n",
      "Epoch 52/3000\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 1.8071 - val_loss: 2.5725\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.55497\n",
      "Epoch 53/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.8042 - val_loss: 2.5616\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.55497\n",
      "Epoch 54/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7965 - val_loss: 2.5793\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.55497\n",
      "Epoch 55/3000\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 1.8029 - val_loss: 2.5729\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.55497\n",
      "Epoch 56/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.8019 - val_loss: 2.5655\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.55497\n",
      "Epoch 57/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.8068 - val_loss: 2.5863\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.55497\n",
      "Epoch 58/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.8162 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.55497\n",
      "Epoch 59/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8056 - val_loss: 2.5689\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.55497\n",
      "Epoch 60/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.8064 - val_loss: 2.5682\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.55497\n",
      "Epoch 61/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.8031 - val_loss: 2.5929\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.55497\n",
      "Epoch 62/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7982 - val_loss: 2.5827\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.55497\n",
      "Epoch 63/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.8027 - val_loss: 2.5754\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.55497\n",
      "Epoch 64/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8060 - val_loss: 2.5712\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.55497\n",
      "Epoch 65/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.8038 - val_loss: 2.5686\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.55497\n",
      "Epoch 66/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7986 - val_loss: 2.5663\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.55497\n",
      "Epoch 67/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.8005 - val_loss: 2.5819\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.55497\n",
      "Epoch 68/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.8039 - val_loss: 2.5699\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.55497\n",
      "Epoch 69/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.8051 - val_loss: 2.5575\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.55497\n",
      "Epoch 70/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7957 - val_loss: 2.5687\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.55497\n",
      "Epoch 71/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7929 - val_loss: 2.5696\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.55497\n",
      "Epoch 72/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.8036 - val_loss: 2.5657\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.55497\n",
      "Epoch 73/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.8017 - val_loss: 2.5708\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.55497\n",
      "Epoch 74/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7921 - val_loss: 2.5817\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.55497\n",
      "Epoch 75/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7987 - val_loss: 2.5690\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.55497\n",
      "Epoch 76/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.8045 - val_loss: 2.5728\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.55497\n",
      "Epoch 77/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.8050 - val_loss: 2.5699\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.55497\n",
      "Epoch 78/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.8133 - val_loss: 2.5670\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.55497\n",
      "Epoch 79/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7961 - val_loss: 2.5670\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.55497\n",
      "Epoch 80/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.8068 - val_loss: 2.5572\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 2.55497\n",
      "Epoch 81/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.8025 - val_loss: 2.5753\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 2.55497\n",
      "Epoch 82/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.8059 - val_loss: 2.5739\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 2.55497\n",
      "Epoch 83/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7973 - val_loss: 2.5701\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 2.55497\n",
      "Epoch 84/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.8025 - val_loss: 2.5667\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 2.55497\n",
      "Epoch 85/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.8046 - val_loss: 2.5656\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 2.55497\n",
      "Epoch 86/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7972 - val_loss: 2.5629\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 2.55497\n",
      "Epoch 87/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7883 - val_loss: 2.5564\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 2.55497\n",
      "Epoch 88/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.8041 - val_loss: 2.5665\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 2.55497\n",
      "Epoch 89/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.8052 - val_loss: 2.5608\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 2.55497\n",
      "Epoch 90/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7874 - val_loss: 2.5586\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 2.55497\n",
      "Epoch 91/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7964 - val_loss: 2.5731\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 2.55497\n",
      "Epoch 92/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.8056 - val_loss: 2.5859\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 2.55497\n",
      "Epoch 93/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.8096 - val_loss: 2.5759\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 2.55497\n",
      "Epoch 94/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8053 - val_loss: 2.5678\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 2.55497\n",
      "Epoch 95/3000\n",
      "51530/51530 [==============================] - 17s 338us/step - loss: 1.8125 - val_loss: 2.5647\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 2.55497\n",
      "Epoch 96/3000\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 1.8038 - val_loss: 2.5737\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 2.55497\n",
      "Epoch 97/3000\n",
      "51530/51530 [==============================] - 18s 341us/step - loss: 1.8000 - val_loss: 2.5690\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 2.55497\n",
      "Epoch 98/3000\n",
      "51530/51530 [==============================] - 17s 337us/step - loss: 1.7947 - val_loss: 2.5789\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 2.55497\n",
      "Epoch 99/3000\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 1.8015 - val_loss: 2.5813\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 2.55497\n",
      "Epoch 100/3000\n",
      "51530/51530 [==============================] - 18s 340us/step - loss: 1.7997 - val_loss: 2.5772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00100: val_loss did not improve from 2.55497\n",
      "Epoch 101/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8053 - val_loss: 2.5704\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 2.55497\n",
      "Epoch 102/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8111 - val_loss: 2.5811\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 2.55497\n",
      "Epoch 103/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.8024 - val_loss: 2.5673\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 2.55497\n",
      "Epoch 104/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7921 - val_loss: 2.5718\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 2.55497\n",
      "Epoch 105/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8014 - val_loss: 2.5727\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 2.55497\n",
      "Epoch 106/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.8092 - val_loss: 2.5727\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 2.55497\n",
      "Epoch 107/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7951 - val_loss: 2.5626\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 2.55497\n",
      "Epoch 108/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.8020 - val_loss: 2.5833\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 2.55497\n",
      "Epoch 109/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7962 - val_loss: 2.5661\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 2.55497\n",
      "Epoch 110/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8070 - val_loss: 2.5758\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 2.55497\n",
      "Epoch 111/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.8034 - val_loss: 2.5872\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 2.55497\n",
      "Epoch 112/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.8092 - val_loss: 2.5793\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 2.55497\n",
      "Epoch 113/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.8021 - val_loss: 2.5771\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 2.55497\n",
      "Epoch 114/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7944 - val_loss: 2.5658\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 2.55497\n",
      "Epoch 115/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7951 - val_loss: 2.5741\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 2.55497\n",
      "Epoch 116/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.8001 - val_loss: 2.5704\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 2.55497\n",
      "Epoch 117/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.8042 - val_loss: 2.5604\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 2.55497\n",
      "Epoch 118/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.8006 - val_loss: 2.5775\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 2.55497\n",
      "Epoch 119/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.8108 - val_loss: 2.5762\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 2.55497\n",
      "Epoch 120/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.8046 - val_loss: 2.5571\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 2.55497\n",
      "Epoch 121/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7950 - val_loss: 2.5549\n",
      "\n",
      "Epoch 00121: val_loss improved from 2.55497 to 2.55488, saving model to best_model.h5\n",
      "Epoch 122/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7983 - val_loss: 2.5445\n",
      "\n",
      "Epoch 00122: val_loss improved from 2.55488 to 2.54449, saving model to best_model.h5\n",
      "Epoch 123/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.8013 - val_loss: 2.5610\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 2.54449\n",
      "Epoch 124/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.8012 - val_loss: 2.5700\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 2.54449\n",
      "Epoch 125/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.8074 - val_loss: 2.5701\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 2.54449\n",
      "Epoch 126/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7993 - val_loss: 2.5604\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 2.54449\n",
      "Epoch 127/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.8089 - val_loss: 2.5732\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 2.54449\n",
      "Epoch 128/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.8000 - val_loss: 2.5743\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 2.54449\n",
      "Epoch 129/3000\n",
      "51530/51530 [==============================] - 21s 409us/step - loss: 1.8008 - val_loss: 2.5768\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 2.54449\n",
      "Epoch 130/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.8104 - val_loss: 2.5669\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 2.54449\n",
      "Epoch 131/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7977 - val_loss: 2.5592\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 2.54449\n",
      "Epoch 132/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8088 - val_loss: 2.5699\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 2.54449\n",
      "Epoch 133/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.8018 - val_loss: 2.5643\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 2.54449\n",
      "Epoch 134/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.8038 - val_loss: 2.5538\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 2.54449\n",
      "Epoch 135/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.8015 - val_loss: 2.5601\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 2.54449\n",
      "Epoch 136/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7957 - val_loss: 2.5584\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 2.54449\n",
      "Epoch 137/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.8052 - val_loss: 2.5672\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 2.54449\n",
      "Epoch 138/3000\n",
      "51530/51530 [==============================] - 18s 340us/step - loss: 1.7987 - val_loss: 2.5603\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 2.54449\n",
      "Epoch 139/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.8035 - val_loss: 2.5737\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 2.54449\n",
      "Epoch 140/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7999 - val_loss: 2.5692\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 2.54449\n",
      "Epoch 141/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7975 - val_loss: 2.5688\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 2.54449\n",
      "Epoch 142/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.8013 - val_loss: 2.5729\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 2.54449\n",
      "Epoch 143/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8076 - val_loss: 2.5711\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 2.54449\n",
      "Epoch 144/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7971 - val_loss: 2.5691\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 2.54449\n",
      "Epoch 145/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8010 - val_loss: 2.5559\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 2.54449\n",
      "Epoch 146/3000\n",
      "51530/51530 [==============================] - 18s 340us/step - loss: 1.8038 - val_loss: 2.5757\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 2.54449\n",
      "Epoch 147/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.8021 - val_loss: 2.5783\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 2.54449\n",
      "Epoch 148/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.8058 - val_loss: 2.5675\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 2.54449\n",
      "Epoch 149/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.8003 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 2.54449\n",
      "Epoch 150/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7932 - val_loss: 2.5616\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 2.54449\n",
      "Epoch 151/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7971 - val_loss: 2.5725\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 2.54449\n",
      "Epoch 152/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7913 - val_loss: 2.5686\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 2.54449\n",
      "Epoch 153/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7991 - val_loss: 2.5654\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 2.54449\n",
      "Epoch 154/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8009 - val_loss: 2.5820\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 2.54449\n",
      "Epoch 155/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7936 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 2.54449\n",
      "Epoch 156/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7989 - val_loss: 2.5732\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 2.54449\n",
      "Epoch 157/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7968 - val_loss: 2.5732\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 2.54449\n",
      "Epoch 158/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.8087 - val_loss: 2.5799\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 2.54449\n",
      "Epoch 159/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7986 - val_loss: 2.5636\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 2.54449\n",
      "Epoch 160/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.8003 - val_loss: 2.5627\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 2.54449\n",
      "Epoch 161/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7916 - val_loss: 2.5670\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 2.54449\n",
      "Epoch 162/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.8001 - val_loss: 2.5707\n",
      "\n",
      "Epoch 00162: val_loss did not improve from 2.54449\n",
      "Epoch 163/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8085 - val_loss: 2.5682\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 2.54449\n",
      "Epoch 164/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7947 - val_loss: 2.5629\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 2.54449\n",
      "Epoch 165/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.8008 - val_loss: 2.5619\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 2.54449\n",
      "Epoch 166/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7969 - val_loss: 2.5763\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 2.54449\n",
      "Epoch 167/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.8136 - val_loss: 2.5673\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 2.54449\n",
      "Epoch 168/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.8000 - val_loss: 2.5826\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 2.54449\n",
      "Epoch 169/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.8005 - val_loss: 2.5716\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 2.54449\n",
      "Epoch 170/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7984 - val_loss: 2.5882\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 2.54449\n",
      "Epoch 171/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.8036 - val_loss: 2.5761\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 2.54449\n",
      "Epoch 172/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7983 - val_loss: 2.5769\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 2.54449\n",
      "Epoch 173/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.8045 - val_loss: 2.5593\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 2.54449\n",
      "Epoch 174/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7910 - val_loss: 2.5672\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 2.54449\n",
      "Epoch 175/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.8095 - val_loss: 2.5680\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 2.54449\n",
      "Epoch 176/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.8082 - val_loss: 2.5740\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 2.54449\n",
      "Epoch 177/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7918 - val_loss: 2.5713\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 2.54449\n",
      "Epoch 178/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8011 - val_loss: 2.5745\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 2.54449\n",
      "Epoch 179/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7941 - val_loss: 2.5824\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 2.54449\n",
      "Epoch 180/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.8035 - val_loss: 2.5812\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 2.54449\n",
      "Epoch 181/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7955 - val_loss: 2.5633\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 2.54449\n",
      "Epoch 182/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7938 - val_loss: 2.5672\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 2.54449\n",
      "Epoch 183/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7963 - val_loss: 2.5744\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 2.54449\n",
      "Epoch 184/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7928 - val_loss: 2.5656\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 2.54449\n",
      "Epoch 185/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7973 - val_loss: 2.5770\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 2.54449\n",
      "Epoch 186/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.7955 - val_loss: 2.5716\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 2.54449\n",
      "Epoch 187/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7962 - val_loss: 2.5865\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 2.54449\n",
      "Epoch 188/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8039 - val_loss: 2.5645\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 2.54449\n",
      "Epoch 189/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8125 - val_loss: 2.5740\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 2.54449\n",
      "Epoch 190/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7970 - val_loss: 2.5700\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 2.54449\n",
      "Epoch 191/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8058 - val_loss: 2.5678\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 2.54449\n",
      "Epoch 192/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7986 - val_loss: 2.5761\n",
      "\n",
      "Epoch 00192: val_loss did not improve from 2.54449\n",
      "Epoch 193/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.8024 - val_loss: 2.5796\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 2.54449\n",
      "Epoch 194/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.8050 - val_loss: 2.5735\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 2.54449\n",
      "Epoch 195/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8011 - val_loss: 2.5689\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 2.54449\n",
      "Epoch 196/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.8057 - val_loss: 2.5727\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 2.54449\n",
      "Epoch 197/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.8046 - val_loss: 2.5815\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 2.54449\n",
      "Epoch 198/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7935 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 2.54449\n",
      "Epoch 199/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7980 - val_loss: 2.5677\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 2.54449\n",
      "Epoch 200/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7973 - val_loss: 2.5652\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 2.54449\n",
      "Epoch 201/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7950 - val_loss: 2.5671\n",
      "\n",
      "Epoch 00201: val_loss did not improve from 2.54449\n",
      "Epoch 202/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7960 - val_loss: 2.5860\n",
      "\n",
      "Epoch 00202: val_loss did not improve from 2.54449\n",
      "Epoch 203/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8018 - val_loss: 2.5773\n",
      "\n",
      "Epoch 00203: val_loss did not improve from 2.54449\n",
      "Epoch 204/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7993 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00204: val_loss did not improve from 2.54449\n",
      "Epoch 205/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7996 - val_loss: 2.5762\n",
      "\n",
      "Epoch 00205: val_loss did not improve from 2.54449\n",
      "Epoch 206/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.8025 - val_loss: 2.5722\n",
      "\n",
      "Epoch 00206: val_loss did not improve from 2.54449\n",
      "Epoch 207/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.8013 - val_loss: 2.5639\n",
      "\n",
      "Epoch 00207: val_loss did not improve from 2.54449\n",
      "Epoch 208/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7917 - val_loss: 2.5766\n",
      "\n",
      "Epoch 00208: val_loss did not improve from 2.54449\n",
      "Epoch 209/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7914 - val_loss: 2.5692\n",
      "\n",
      "Epoch 00209: val_loss did not improve from 2.54449\n",
      "Epoch 210/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7983 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00210: val_loss did not improve from 2.54449\n",
      "Epoch 211/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.8059 - val_loss: 2.5799\n",
      "\n",
      "Epoch 00211: val_loss did not improve from 2.54449\n",
      "Epoch 212/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7999 - val_loss: 2.5737\n",
      "\n",
      "Epoch 00212: val_loss did not improve from 2.54449\n",
      "Epoch 213/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7903 - val_loss: 2.5834\n",
      "\n",
      "Epoch 00213: val_loss did not improve from 2.54449\n",
      "Epoch 214/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.8175 - val_loss: 2.5704\n",
      "\n",
      "Epoch 00214: val_loss did not improve from 2.54449\n",
      "Epoch 215/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7866 - val_loss: 2.5651\n",
      "\n",
      "Epoch 00215: val_loss did not improve from 2.54449\n",
      "Epoch 216/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7940 - val_loss: 2.5807\n",
      "\n",
      "Epoch 00216: val_loss did not improve from 2.54449\n",
      "Epoch 217/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.8026 - val_loss: 2.5794\n",
      "\n",
      "Epoch 00217: val_loss did not improve from 2.54449\n",
      "Epoch 218/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7957 - val_loss: 2.5670\n",
      "\n",
      "Epoch 00218: val_loss did not improve from 2.54449\n",
      "Epoch 219/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7886 - val_loss: 2.5866\n",
      "\n",
      "Epoch 00219: val_loss did not improve from 2.54449\n",
      "Epoch 220/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.8065 - val_loss: 2.5803\n",
      "\n",
      "Epoch 00220: val_loss did not improve from 2.54449\n",
      "Epoch 221/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7988 - val_loss: 2.5914\n",
      "\n",
      "Epoch 00221: val_loss did not improve from 2.54449\n",
      "Epoch 222/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7921 - val_loss: 2.5852\n",
      "\n",
      "Epoch 00222: val_loss did not improve from 2.54449\n",
      "Epoch 223/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.8004 - val_loss: 2.5702\n",
      "\n",
      "Epoch 00223: val_loss did not improve from 2.54449\n",
      "Epoch 224/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.8020 - val_loss: 2.5654\n",
      "\n",
      "Epoch 00224: val_loss did not improve from 2.54449\n",
      "Epoch 225/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7943 - val_loss: 2.5724\n",
      "\n",
      "Epoch 00225: val_loss did not improve from 2.54449\n",
      "Epoch 226/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7980 - val_loss: 2.5712\n",
      "\n",
      "Epoch 00226: val_loss did not improve from 2.54449\n",
      "Epoch 227/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7951 - val_loss: 2.5662\n",
      "\n",
      "Epoch 00227: val_loss did not improve from 2.54449\n",
      "Epoch 228/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.8049 - val_loss: 2.5668\n",
      "\n",
      "Epoch 00228: val_loss did not improve from 2.54449\n",
      "Epoch 229/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.8024 - val_loss: 2.5550\n",
      "\n",
      "Epoch 00229: val_loss did not improve from 2.54449\n",
      "Epoch 230/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7930 - val_loss: 2.5586\n",
      "\n",
      "Epoch 00230: val_loss did not improve from 2.54449\n",
      "Epoch 231/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7978 - val_loss: 2.5636\n",
      "\n",
      "Epoch 00231: val_loss did not improve from 2.54449\n",
      "Epoch 232/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7921 - val_loss: 2.5801\n",
      "\n",
      "Epoch 00232: val_loss did not improve from 2.54449\n",
      "Epoch 233/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.8011 - val_loss: 2.5745\n",
      "\n",
      "Epoch 00233: val_loss did not improve from 2.54449\n",
      "Epoch 234/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.8048 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00234: val_loss did not improve from 2.54449\n",
      "Epoch 235/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7943 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00235: val_loss did not improve from 2.54449\n",
      "Epoch 236/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7935 - val_loss: 2.5674\n",
      "\n",
      "Epoch 00236: val_loss did not improve from 2.54449\n",
      "Epoch 237/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7999 - val_loss: 2.5722\n",
      "\n",
      "Epoch 00237: val_loss did not improve from 2.54449\n",
      "Epoch 238/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7987 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00238: val_loss did not improve from 2.54449\n",
      "Epoch 239/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7974 - val_loss: 2.5790\n",
      "\n",
      "Epoch 00239: val_loss did not improve from 2.54449\n",
      "Epoch 240/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.8011 - val_loss: 2.5674\n",
      "\n",
      "Epoch 00240: val_loss did not improve from 2.54449\n",
      "Epoch 241/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.8010 - val_loss: 2.5665\n",
      "\n",
      "Epoch 00241: val_loss did not improve from 2.54449\n",
      "Epoch 242/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7907 - val_loss: 2.5735\n",
      "\n",
      "Epoch 00242: val_loss did not improve from 2.54449\n",
      "Epoch 243/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7981 - val_loss: 2.5768\n",
      "\n",
      "Epoch 00243: val_loss did not improve from 2.54449\n",
      "Epoch 244/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7944 - val_loss: 2.5689\n",
      "\n",
      "Epoch 00244: val_loss did not improve from 2.54449\n",
      "Epoch 245/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7957 - val_loss: 2.5791\n",
      "\n",
      "Epoch 00245: val_loss did not improve from 2.54449\n",
      "Epoch 246/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7909 - val_loss: 2.5785\n",
      "\n",
      "Epoch 00246: val_loss did not improve from 2.54449\n",
      "Epoch 247/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8011 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00247: val_loss did not improve from 2.54449\n",
      "Epoch 248/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7911 - val_loss: 2.5892\n",
      "\n",
      "Epoch 00248: val_loss did not improve from 2.54449\n",
      "Epoch 249/3000\n",
      "51530/51530 [==============================] - 17s 338us/step - loss: 1.7925 - val_loss: 2.5712\n",
      "\n",
      "Epoch 00249: val_loss did not improve from 2.54449\n",
      "Epoch 250/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8014 - val_loss: 2.5840\n",
      "\n",
      "Epoch 00250: val_loss did not improve from 2.54449\n",
      "Epoch 251/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7882 - val_loss: 2.5695\n",
      "\n",
      "Epoch 00251: val_loss did not improve from 2.54449\n",
      "Epoch 252/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7888 - val_loss: 2.5642\n",
      "\n",
      "Epoch 00252: val_loss did not improve from 2.54449\n",
      "Epoch 253/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.8015 - val_loss: 2.5816\n",
      "\n",
      "Epoch 00253: val_loss did not improve from 2.54449\n",
      "Epoch 254/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7911 - val_loss: 2.5758\n",
      "\n",
      "Epoch 00254: val_loss did not improve from 2.54449\n",
      "Epoch 255/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.8009 - val_loss: 2.5660\n",
      "\n",
      "Epoch 00255: val_loss did not improve from 2.54449\n",
      "Epoch 256/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.8053 - val_loss: 2.5728\n",
      "\n",
      "Epoch 00256: val_loss did not improve from 2.54449\n",
      "Epoch 257/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7924 - val_loss: 2.5762\n",
      "\n",
      "Epoch 00257: val_loss did not improve from 2.54449\n",
      "Epoch 258/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7934 - val_loss: 2.5685\n",
      "\n",
      "Epoch 00258: val_loss did not improve from 2.54449\n",
      "Epoch 259/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7995 - val_loss: 2.5749\n",
      "\n",
      "Epoch 00259: val_loss did not improve from 2.54449\n",
      "Epoch 260/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7932 - val_loss: 2.5691\n",
      "\n",
      "Epoch 00260: val_loss did not improve from 2.54449\n",
      "Epoch 261/3000\n",
      "51530/51530 [==============================] - 18s 346us/step - loss: 1.7959 - val_loss: 2.5764\n",
      "\n",
      "Epoch 00261: val_loss did not improve from 2.54449\n",
      "Epoch 262/3000\n",
      "51530/51530 [==============================] - 19s 363us/step - loss: 1.7925 - val_loss: 2.5762\n",
      "\n",
      "Epoch 00262: val_loss did not improve from 2.54449\n",
      "Epoch 263/3000\n",
      "51530/51530 [==============================] - 21s 404us/step - loss: 1.8038 - val_loss: 2.5658\n",
      "\n",
      "Epoch 00263: val_loss did not improve from 2.54449\n",
      "Epoch 264/3000\n",
      "51530/51530 [==============================] - 18s 344us/step - loss: 1.8051 - val_loss: 2.5645\n",
      "\n",
      "Epoch 00264: val_loss did not improve from 2.54449\n",
      "Epoch 265/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7888 - val_loss: 2.5713\n",
      "\n",
      "Epoch 00265: val_loss did not improve from 2.54449\n",
      "Epoch 266/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7904 - val_loss: 2.5636\n",
      "\n",
      "Epoch 00266: val_loss did not improve from 2.54449\n",
      "Epoch 267/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7935 - val_loss: 2.5689\n",
      "\n",
      "Epoch 00267: val_loss did not improve from 2.54449\n",
      "Epoch 268/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.8021 - val_loss: 2.5785\n",
      "\n",
      "Epoch 00268: val_loss did not improve from 2.54449\n",
      "Epoch 269/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7957 - val_loss: 2.5884\n",
      "\n",
      "Epoch 00269: val_loss did not improve from 2.54449\n",
      "Epoch 270/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.8015 - val_loss: 2.5637\n",
      "\n",
      "Epoch 00270: val_loss did not improve from 2.54449\n",
      "Epoch 271/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7910 - val_loss: 2.5745\n",
      "\n",
      "Epoch 00271: val_loss did not improve from 2.54449\n",
      "Epoch 272/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.8009 - val_loss: 2.5816\n",
      "\n",
      "Epoch 00272: val_loss did not improve from 2.54449\n",
      "Epoch 273/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7988 - val_loss: 2.5775\n",
      "\n",
      "Epoch 00273: val_loss did not improve from 2.54449\n",
      "Epoch 274/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7981 - val_loss: 2.5810\n",
      "\n",
      "Epoch 00274: val_loss did not improve from 2.54449\n",
      "Epoch 275/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8000 - val_loss: 2.5823\n",
      "\n",
      "Epoch 00275: val_loss did not improve from 2.54449\n",
      "Epoch 276/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7971 - val_loss: 2.5835\n",
      "\n",
      "Epoch 00276: val_loss did not improve from 2.54449\n",
      "Epoch 277/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7986 - val_loss: 2.5919\n",
      "\n",
      "Epoch 00277: val_loss did not improve from 2.54449\n",
      "Epoch 278/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7938 - val_loss: 2.5723\n",
      "\n",
      "Epoch 00278: val_loss did not improve from 2.54449\n",
      "Epoch 279/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8055 - val_loss: 2.5838\n",
      "\n",
      "Epoch 00279: val_loss did not improve from 2.54449\n",
      "Epoch 280/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7973 - val_loss: 2.5760\n",
      "\n",
      "Epoch 00280: val_loss did not improve from 2.54449\n",
      "Epoch 281/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7983 - val_loss: 2.5767\n",
      "\n",
      "Epoch 00281: val_loss did not improve from 2.54449\n",
      "Epoch 282/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7985 - val_loss: 2.5867\n",
      "\n",
      "Epoch 00282: val_loss did not improve from 2.54449\n",
      "Epoch 283/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8003 - val_loss: 2.5714\n",
      "\n",
      "Epoch 00283: val_loss did not improve from 2.54449\n",
      "Epoch 284/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7879 - val_loss: 2.5830\n",
      "\n",
      "Epoch 00284: val_loss did not improve from 2.54449\n",
      "Epoch 285/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7915 - val_loss: 2.5701\n",
      "\n",
      "Epoch 00285: val_loss did not improve from 2.54449\n",
      "Epoch 286/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8046 - val_loss: 2.5810\n",
      "\n",
      "Epoch 00286: val_loss did not improve from 2.54449\n",
      "Epoch 287/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7897 - val_loss: 2.5840\n",
      "\n",
      "Epoch 00287: val_loss did not improve from 2.54449\n",
      "Epoch 288/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7944 - val_loss: 2.5941\n",
      "\n",
      "Epoch 00288: val_loss did not improve from 2.54449\n",
      "Epoch 289/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7764 - val_loss: 2.5789\n",
      "\n",
      "Epoch 00289: val_loss did not improve from 2.54449\n",
      "Epoch 290/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7826 - val_loss: 2.5760\n",
      "\n",
      "Epoch 00290: val_loss did not improve from 2.54449\n",
      "Epoch 291/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7951 - val_loss: 2.5874\n",
      "\n",
      "Epoch 00291: val_loss did not improve from 2.54449\n",
      "Epoch 292/3000\n",
      "51530/51530 [==============================] - 17s 337us/step - loss: 1.8075 - val_loss: 2.5749\n",
      "\n",
      "Epoch 00292: val_loss did not improve from 2.54449\n",
      "Epoch 293/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7917 - val_loss: 2.5841\n",
      "\n",
      "Epoch 00293: val_loss did not improve from 2.54449\n",
      "Epoch 294/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7923 - val_loss: 2.5711\n",
      "\n",
      "Epoch 00294: val_loss did not improve from 2.54449\n",
      "Epoch 295/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.8015 - val_loss: 2.5639\n",
      "\n",
      "Epoch 00295: val_loss did not improve from 2.54449\n",
      "Epoch 296/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.8010 - val_loss: 2.5760\n",
      "\n",
      "Epoch 00296: val_loss did not improve from 2.54449\n",
      "Epoch 297/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7990 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00297: val_loss did not improve from 2.54449\n",
      "Epoch 298/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7937 - val_loss: 2.5720\n",
      "\n",
      "Epoch 00298: val_loss did not improve from 2.54449\n",
      "Epoch 299/3000\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 1.7921 - val_loss: 2.5756\n",
      "\n",
      "Epoch 00299: val_loss did not improve from 2.54449\n",
      "Epoch 300/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7978 - val_loss: 2.5777\n",
      "\n",
      "Epoch 00300: val_loss did not improve from 2.54449\n",
      "Epoch 301/3000\n",
      "51530/51530 [==============================] - 20s 386us/step - loss: 1.8081 - val_loss: 2.5883\n",
      "\n",
      "Epoch 00301: val_loss did not improve from 2.54449\n",
      "Epoch 302/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7914 - val_loss: 2.5679\n",
      "\n",
      "Epoch 00302: val_loss did not improve from 2.54449\n",
      "Epoch 303/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7949 - val_loss: 2.5674\n",
      "\n",
      "Epoch 00303: val_loss did not improve from 2.54449\n",
      "Epoch 304/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8031 - val_loss: 2.5868\n",
      "\n",
      "Epoch 00304: val_loss did not improve from 2.54449\n",
      "Epoch 305/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7864 - val_loss: 2.5970\n",
      "\n",
      "Epoch 00305: val_loss did not improve from 2.54449\n",
      "Epoch 306/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7856 - val_loss: 2.5796\n",
      "\n",
      "Epoch 00306: val_loss did not improve from 2.54449\n",
      "Epoch 307/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7923 - val_loss: 2.5858\n",
      "\n",
      "Epoch 00307: val_loss did not improve from 2.54449\n",
      "Epoch 308/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8027 - val_loss: 2.5851\n",
      "\n",
      "Epoch 00308: val_loss did not improve from 2.54449\n",
      "Epoch 309/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7954 - val_loss: 2.5754\n",
      "\n",
      "Epoch 00309: val_loss did not improve from 2.54449\n",
      "Epoch 310/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8016 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00310: val_loss did not improve from 2.54449\n",
      "Epoch 311/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7882 - val_loss: 2.5762\n",
      "\n",
      "Epoch 00311: val_loss did not improve from 2.54449\n",
      "Epoch 312/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.8033 - val_loss: 2.5780\n",
      "\n",
      "Epoch 00312: val_loss did not improve from 2.54449\n",
      "Epoch 313/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7907 - val_loss: 2.5773\n",
      "\n",
      "Epoch 00313: val_loss did not improve from 2.54449\n",
      "Epoch 314/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7983 - val_loss: 2.5628\n",
      "\n",
      "Epoch 00314: val_loss did not improve from 2.54449\n",
      "Epoch 315/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7914 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00315: val_loss did not improve from 2.54449\n",
      "Epoch 316/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7976 - val_loss: 2.5748\n",
      "\n",
      "Epoch 00316: val_loss did not improve from 2.54449\n",
      "Epoch 317/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7928 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00317: val_loss did not improve from 2.54449\n",
      "Epoch 318/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7870 - val_loss: 2.5782\n",
      "\n",
      "Epoch 00318: val_loss did not improve from 2.54449\n",
      "Epoch 319/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7928 - val_loss: 2.5838\n",
      "\n",
      "Epoch 00319: val_loss did not improve from 2.54449\n",
      "Epoch 320/3000\n",
      "51530/51530 [==============================] - 18s 341us/step - loss: 1.7893 - val_loss: 2.5643\n",
      "\n",
      "Epoch 00320: val_loss did not improve from 2.54449\n",
      "Epoch 321/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.8052 - val_loss: 2.5564\n",
      "\n",
      "Epoch 00321: val_loss did not improve from 2.54449\n",
      "Epoch 322/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7969 - val_loss: 2.5771\n",
      "\n",
      "Epoch 00322: val_loss did not improve from 2.54449\n",
      "Epoch 323/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7957 - val_loss: 2.5768\n",
      "\n",
      "Epoch 00323: val_loss did not improve from 2.54449\n",
      "Epoch 324/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7970 - val_loss: 2.5815\n",
      "\n",
      "Epoch 00324: val_loss did not improve from 2.54449\n",
      "Epoch 325/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7884 - val_loss: 2.5752\n",
      "\n",
      "Epoch 00325: val_loss did not improve from 2.54449\n",
      "Epoch 326/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7904 - val_loss: 2.5816\n",
      "\n",
      "Epoch 00326: val_loss did not improve from 2.54449\n",
      "Epoch 327/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7970 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00327: val_loss did not improve from 2.54449\n",
      "Epoch 328/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7972 - val_loss: 2.5857\n",
      "\n",
      "Epoch 00328: val_loss did not improve from 2.54449\n",
      "Epoch 329/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7953 - val_loss: 2.5869\n",
      "\n",
      "Epoch 00329: val_loss did not improve from 2.54449\n",
      "Epoch 330/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7962 - val_loss: 2.5742\n",
      "\n",
      "Epoch 00330: val_loss did not improve from 2.54449\n",
      "Epoch 331/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7933 - val_loss: 2.5647\n",
      "\n",
      "Epoch 00331: val_loss did not improve from 2.54449\n",
      "Epoch 332/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7962 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00332: val_loss did not improve from 2.54449\n",
      "Epoch 333/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7907 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00333: val_loss did not improve from 2.54449\n",
      "Epoch 334/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.8018 - val_loss: 2.5838\n",
      "\n",
      "Epoch 00334: val_loss did not improve from 2.54449\n",
      "Epoch 335/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7893 - val_loss: 2.5890\n",
      "\n",
      "Epoch 00335: val_loss did not improve from 2.54449\n",
      "Epoch 336/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7936 - val_loss: 2.5861\n",
      "\n",
      "Epoch 00336: val_loss did not improve from 2.54449\n",
      "Epoch 337/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7911 - val_loss: 2.5831\n",
      "\n",
      "Epoch 00337: val_loss did not improve from 2.54449\n",
      "Epoch 338/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7944 - val_loss: 2.5834\n",
      "\n",
      "Epoch 00338: val_loss did not improve from 2.54449\n",
      "Epoch 339/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.8036 - val_loss: 2.5756\n",
      "\n",
      "Epoch 00339: val_loss did not improve from 2.54449\n",
      "Epoch 340/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7910 - val_loss: 2.5752\n",
      "\n",
      "Epoch 00340: val_loss did not improve from 2.54449\n",
      "Epoch 341/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7915 - val_loss: 2.5817\n",
      "\n",
      "Epoch 00341: val_loss did not improve from 2.54449\n",
      "Epoch 342/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.8026 - val_loss: 2.5822\n",
      "\n",
      "Epoch 00342: val_loss did not improve from 2.54449\n",
      "Epoch 343/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7909 - val_loss: 2.5701\n",
      "\n",
      "Epoch 00343: val_loss did not improve from 2.54449\n",
      "Epoch 344/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.8037 - val_loss: 2.5835\n",
      "\n",
      "Epoch 00344: val_loss did not improve from 2.54449\n",
      "Epoch 345/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7861 - val_loss: 2.5848\n",
      "\n",
      "Epoch 00345: val_loss did not improve from 2.54449\n",
      "Epoch 346/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7970 - val_loss: 2.5743\n",
      "\n",
      "Epoch 00346: val_loss did not improve from 2.54449\n",
      "Epoch 347/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7928 - val_loss: 2.5872\n",
      "\n",
      "Epoch 00347: val_loss did not improve from 2.54449\n",
      "Epoch 348/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7948 - val_loss: 2.5899\n",
      "\n",
      "Epoch 00348: val_loss did not improve from 2.54449\n",
      "Epoch 349/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7986 - val_loss: 2.5864\n",
      "\n",
      "Epoch 00349: val_loss did not improve from 2.54449\n",
      "Epoch 350/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7943 - val_loss: 2.5733\n",
      "\n",
      "Epoch 00350: val_loss did not improve from 2.54449\n",
      "Epoch 351/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7941 - val_loss: 2.5661\n",
      "\n",
      "Epoch 00351: val_loss did not improve from 2.54449\n",
      "Epoch 352/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7848 - val_loss: 2.5677\n",
      "\n",
      "Epoch 00352: val_loss did not improve from 2.54449\n",
      "Epoch 353/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7978 - val_loss: 2.5739\n",
      "\n",
      "Epoch 00353: val_loss did not improve from 2.54449\n",
      "Epoch 354/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7919 - val_loss: 2.5742\n",
      "\n",
      "Epoch 00354: val_loss did not improve from 2.54449\n",
      "Epoch 355/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7883 - val_loss: 2.5711\n",
      "\n",
      "Epoch 00355: val_loss did not improve from 2.54449\n",
      "Epoch 356/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7981 - val_loss: 2.5853\n",
      "\n",
      "Epoch 00356: val_loss did not improve from 2.54449\n",
      "Epoch 357/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7961 - val_loss: 2.5835\n",
      "\n",
      "Epoch 00357: val_loss did not improve from 2.54449\n",
      "Epoch 358/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.8051 - val_loss: 2.5819\n",
      "\n",
      "Epoch 00358: val_loss did not improve from 2.54449\n",
      "Epoch 359/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7919 - val_loss: 2.5756\n",
      "\n",
      "Epoch 00359: val_loss did not improve from 2.54449\n",
      "Epoch 360/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.8042 - val_loss: 2.5697\n",
      "\n",
      "Epoch 00360: val_loss did not improve from 2.54449\n",
      "Epoch 361/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7928 - val_loss: 2.5750\n",
      "\n",
      "Epoch 00361: val_loss did not improve from 2.54449\n",
      "Epoch 362/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7991 - val_loss: 2.5636\n",
      "\n",
      "Epoch 00362: val_loss did not improve from 2.54449\n",
      "Epoch 363/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7962 - val_loss: 2.5834\n",
      "\n",
      "Epoch 00363: val_loss did not improve from 2.54449\n",
      "Epoch 364/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.8024 - val_loss: 2.5753\n",
      "\n",
      "Epoch 00364: val_loss did not improve from 2.54449\n",
      "Epoch 365/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7947 - val_loss: 2.5666\n",
      "\n",
      "Epoch 00365: val_loss did not improve from 2.54449\n",
      "Epoch 366/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7836 - val_loss: 2.5610\n",
      "\n",
      "Epoch 00366: val_loss did not improve from 2.54449\n",
      "Epoch 367/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7980 - val_loss: 2.5572\n",
      "\n",
      "Epoch 00367: val_loss did not improve from 2.54449\n",
      "Epoch 368/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7940 - val_loss: 2.5600\n",
      "\n",
      "Epoch 00368: val_loss did not improve from 2.54449\n",
      "Epoch 369/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7937 - val_loss: 2.5612\n",
      "\n",
      "Epoch 00369: val_loss did not improve from 2.54449\n",
      "Epoch 370/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7945 - val_loss: 2.5589\n",
      "\n",
      "Epoch 00370: val_loss did not improve from 2.54449\n",
      "Epoch 371/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7957 - val_loss: 2.5668\n",
      "\n",
      "Epoch 00371: val_loss did not improve from 2.54449\n",
      "Epoch 372/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7941 - val_loss: 2.5673\n",
      "\n",
      "Epoch 00372: val_loss did not improve from 2.54449\n",
      "Epoch 373/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7918 - val_loss: 2.5637\n",
      "\n",
      "Epoch 00373: val_loss did not improve from 2.54449\n",
      "Epoch 374/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7965 - val_loss: 2.5710\n",
      "\n",
      "Epoch 00374: val_loss did not improve from 2.54449\n",
      "Epoch 375/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7913 - val_loss: 2.5717\n",
      "\n",
      "Epoch 00375: val_loss did not improve from 2.54449\n",
      "Epoch 376/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.8007 - val_loss: 2.5662\n",
      "\n",
      "Epoch 00376: val_loss did not improve from 2.54449\n",
      "Epoch 377/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7903 - val_loss: 2.5703\n",
      "\n",
      "Epoch 00377: val_loss did not improve from 2.54449\n",
      "Epoch 378/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.8022 - val_loss: 2.5731\n",
      "\n",
      "Epoch 00378: val_loss did not improve from 2.54449\n",
      "Epoch 379/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.8090 - val_loss: 2.5701\n",
      "\n",
      "Epoch 00379: val_loss did not improve from 2.54449\n",
      "Epoch 380/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7945 - val_loss: 2.5683\n",
      "\n",
      "Epoch 00380: val_loss did not improve from 2.54449\n",
      "Epoch 381/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7944 - val_loss: 2.5882\n",
      "\n",
      "Epoch 00381: val_loss did not improve from 2.54449\n",
      "Epoch 382/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8037 - val_loss: 2.5759\n",
      "\n",
      "Epoch 00382: val_loss did not improve from 2.54449\n",
      "Epoch 383/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7864 - val_loss: 2.5726\n",
      "\n",
      "Epoch 00383: val_loss did not improve from 2.54449\n",
      "Epoch 384/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7864 - val_loss: 2.5855\n",
      "\n",
      "Epoch 00384: val_loss did not improve from 2.54449\n",
      "Epoch 385/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7961 - val_loss: 2.5673\n",
      "\n",
      "Epoch 00385: val_loss did not improve from 2.54449\n",
      "Epoch 386/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7994 - val_loss: 2.5890\n",
      "\n",
      "Epoch 00386: val_loss did not improve from 2.54449\n",
      "Epoch 387/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7981 - val_loss: 2.5690\n",
      "\n",
      "Epoch 00387: val_loss did not improve from 2.54449\n",
      "Epoch 388/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7802 - val_loss: 2.5554\n",
      "\n",
      "Epoch 00388: val_loss did not improve from 2.54449\n",
      "Epoch 389/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7914 - val_loss: 2.5675\n",
      "\n",
      "Epoch 00389: val_loss did not improve from 2.54449\n",
      "Epoch 390/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7976 - val_loss: 2.5689\n",
      "\n",
      "Epoch 00390: val_loss did not improve from 2.54449\n",
      "Epoch 391/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7967 - val_loss: 2.5908\n",
      "\n",
      "Epoch 00391: val_loss did not improve from 2.54449\n",
      "Epoch 392/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7988 - val_loss: 2.5797\n",
      "\n",
      "Epoch 00392: val_loss did not improve from 2.54449\n",
      "Epoch 393/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7994 - val_loss: 2.5649\n",
      "\n",
      "Epoch 00393: val_loss did not improve from 2.54449\n",
      "Epoch 394/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7919 - val_loss: 2.5793\n",
      "\n",
      "Epoch 00394: val_loss did not improve from 2.54449\n",
      "Epoch 395/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7928 - val_loss: 2.5794\n",
      "\n",
      "Epoch 00395: val_loss did not improve from 2.54449\n",
      "Epoch 396/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7928 - val_loss: 2.5769\n",
      "\n",
      "Epoch 00396: val_loss did not improve from 2.54449\n",
      "Epoch 397/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.8109 - val_loss: 2.5830\n",
      "\n",
      "Epoch 00397: val_loss did not improve from 2.54449\n",
      "Epoch 398/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7899 - val_loss: 2.5821\n",
      "\n",
      "Epoch 00398: val_loss did not improve from 2.54449\n",
      "Epoch 399/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7966 - val_loss: 2.5771\n",
      "\n",
      "Epoch 00399: val_loss did not improve from 2.54449\n",
      "Epoch 400/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8029 - val_loss: 2.5774\n",
      "\n",
      "Epoch 00400: val_loss did not improve from 2.54449\n",
      "Epoch 401/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7870 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00401: val_loss did not improve from 2.54449\n",
      "Epoch 402/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7961 - val_loss: 2.5787\n",
      "\n",
      "Epoch 00402: val_loss did not improve from 2.54449\n",
      "Epoch 403/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7998 - val_loss: 2.5744\n",
      "\n",
      "Epoch 00403: val_loss did not improve from 2.54449\n",
      "Epoch 404/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7956 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00404: val_loss did not improve from 2.54449\n",
      "Epoch 405/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7938 - val_loss: 2.5775\n",
      "\n",
      "Epoch 00405: val_loss did not improve from 2.54449\n",
      "Epoch 406/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7925 - val_loss: 2.5714\n",
      "\n",
      "Epoch 00406: val_loss did not improve from 2.54449\n",
      "Epoch 407/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7762 - val_loss: 2.5738\n",
      "\n",
      "Epoch 00407: val_loss did not improve from 2.54449\n",
      "Epoch 408/3000\n",
      "51530/51530 [==============================] - 22s 418us/step - loss: 1.7935 - val_loss: 2.5759\n",
      "\n",
      "Epoch 00408: val_loss did not improve from 2.54449\n",
      "Epoch 409/3000\n",
      "51530/51530 [==============================] - 18s 345us/step - loss: 1.7999 - val_loss: 2.5801\n",
      "\n",
      "Epoch 00409: val_loss did not improve from 2.54449\n",
      "Epoch 410/3000\n",
      "51530/51530 [==============================] - 18s 344us/step - loss: 1.7970 - val_loss: 2.5815\n",
      "\n",
      "Epoch 00410: val_loss did not improve from 2.54449\n",
      "Epoch 411/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7977 - val_loss: 2.5745\n",
      "\n",
      "Epoch 00411: val_loss did not improve from 2.54449\n",
      "Epoch 412/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7827 - val_loss: 2.5741\n",
      "\n",
      "Epoch 00412: val_loss did not improve from 2.54449\n",
      "Epoch 413/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7801 - val_loss: 2.5850\n",
      "\n",
      "Epoch 00413: val_loss did not improve from 2.54449\n",
      "Epoch 414/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7865 - val_loss: 2.5738\n",
      "\n",
      "Epoch 00414: val_loss did not improve from 2.54449\n",
      "Epoch 415/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7848 - val_loss: 2.5725\n",
      "\n",
      "Epoch 00415: val_loss did not improve from 2.54449\n",
      "Epoch 416/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7995 - val_loss: 2.5888\n",
      "\n",
      "Epoch 00416: val_loss did not improve from 2.54449\n",
      "Epoch 417/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7872 - val_loss: 2.5755\n",
      "\n",
      "Epoch 00417: val_loss did not improve from 2.54449\n",
      "Epoch 418/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7975 - val_loss: 2.5899\n",
      "\n",
      "Epoch 00418: val_loss did not improve from 2.54449\n",
      "Epoch 419/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7874 - val_loss: 2.5794\n",
      "\n",
      "Epoch 00419: val_loss did not improve from 2.54449\n",
      "Epoch 420/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7962 - val_loss: 2.5725\n",
      "\n",
      "Epoch 00420: val_loss did not improve from 2.54449\n",
      "Epoch 421/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7934 - val_loss: 2.5671\n",
      "\n",
      "Epoch 00421: val_loss did not improve from 2.54449\n",
      "Epoch 422/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7855 - val_loss: 2.5722\n",
      "\n",
      "Epoch 00422: val_loss did not improve from 2.54449\n",
      "Epoch 423/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7937 - val_loss: 2.5831\n",
      "\n",
      "Epoch 00423: val_loss did not improve from 2.54449\n",
      "Epoch 424/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.8025 - val_loss: 2.5689\n",
      "\n",
      "Epoch 00424: val_loss did not improve from 2.54449\n",
      "Epoch 425/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7871 - val_loss: 2.5900\n",
      "\n",
      "Epoch 00425: val_loss did not improve from 2.54449\n",
      "Epoch 426/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7957 - val_loss: 2.5843\n",
      "\n",
      "Epoch 00426: val_loss did not improve from 2.54449\n",
      "Epoch 427/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7866 - val_loss: 2.5782\n",
      "\n",
      "Epoch 00427: val_loss did not improve from 2.54449\n",
      "Epoch 428/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7918 - val_loss: 2.5835\n",
      "\n",
      "Epoch 00428: val_loss did not improve from 2.54449\n",
      "Epoch 429/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.7893 - val_loss: 2.5808\n",
      "\n",
      "Epoch 00429: val_loss did not improve from 2.54449\n",
      "Epoch 430/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.7948 - val_loss: 2.5842\n",
      "\n",
      "Epoch 00430: val_loss did not improve from 2.54449\n",
      "Epoch 431/3000\n",
      "51530/51530 [==============================] - 17s 338us/step - loss: 1.7800 - val_loss: 2.5749\n",
      "\n",
      "Epoch 00431: val_loss did not improve from 2.54449\n",
      "Epoch 432/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7917 - val_loss: 2.5722\n",
      "\n",
      "Epoch 00432: val_loss did not improve from 2.54449\n",
      "Epoch 433/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.7968 - val_loss: 2.5732\n",
      "\n",
      "Epoch 00433: val_loss did not improve from 2.54449\n",
      "Epoch 434/3000\n",
      "51530/51530 [==============================] - 17s 338us/step - loss: 1.7841 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00434: val_loss did not improve from 2.54449\n",
      "Epoch 435/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7910 - val_loss: 2.5621\n",
      "\n",
      "Epoch 00435: val_loss did not improve from 2.54449\n",
      "Epoch 436/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7926 - val_loss: 2.5727\n",
      "\n",
      "Epoch 00436: val_loss did not improve from 2.54449\n",
      "Epoch 437/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7875 - val_loss: 2.5766\n",
      "\n",
      "Epoch 00437: val_loss did not improve from 2.54449\n",
      "Epoch 438/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7959 - val_loss: 2.5888\n",
      "\n",
      "Epoch 00438: val_loss did not improve from 2.54449\n",
      "Epoch 439/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7825 - val_loss: 2.5788\n",
      "\n",
      "Epoch 00439: val_loss did not improve from 2.54449\n",
      "Epoch 440/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7973 - val_loss: 2.5802\n",
      "\n",
      "Epoch 00440: val_loss did not improve from 2.54449\n",
      "Epoch 441/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7971 - val_loss: 2.5915\n",
      "\n",
      "Epoch 00441: val_loss did not improve from 2.54449\n",
      "Epoch 442/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7937 - val_loss: 2.5831\n",
      "\n",
      "Epoch 00442: val_loss did not improve from 2.54449\n",
      "Epoch 443/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7902 - val_loss: 2.5686\n",
      "\n",
      "Epoch 00443: val_loss did not improve from 2.54449\n",
      "Epoch 444/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7927 - val_loss: 2.5745\n",
      "\n",
      "Epoch 00444: val_loss did not improve from 2.54449\n",
      "Epoch 445/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7972 - val_loss: 2.5705\n",
      "\n",
      "Epoch 00445: val_loss did not improve from 2.54449\n",
      "Epoch 446/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7954 - val_loss: 2.5692\n",
      "\n",
      "Epoch 00446: val_loss did not improve from 2.54449\n",
      "Epoch 447/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7912 - val_loss: 2.5755\n",
      "\n",
      "Epoch 00447: val_loss did not improve from 2.54449\n",
      "Epoch 448/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7984 - val_loss: 2.5736\n",
      "\n",
      "Epoch 00448: val_loss did not improve from 2.54449\n",
      "Epoch 449/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7866 - val_loss: 2.5761\n",
      "\n",
      "Epoch 00449: val_loss did not improve from 2.54449\n",
      "Epoch 450/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7877 - val_loss: 2.5866\n",
      "\n",
      "Epoch 00450: val_loss did not improve from 2.54449\n",
      "Epoch 451/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.8045 - val_loss: 2.5784\n",
      "\n",
      "Epoch 00451: val_loss did not improve from 2.54449\n",
      "Epoch 452/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7916 - val_loss: 2.5745\n",
      "\n",
      "Epoch 00452: val_loss did not improve from 2.54449\n",
      "Epoch 453/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7932 - val_loss: 2.5812\n",
      "\n",
      "Epoch 00453: val_loss did not improve from 2.54449\n",
      "Epoch 454/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7900 - val_loss: 2.5801\n",
      "\n",
      "Epoch 00454: val_loss did not improve from 2.54449\n",
      "Epoch 455/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7925 - val_loss: 2.5727\n",
      "\n",
      "Epoch 00455: val_loss did not improve from 2.54449\n",
      "Epoch 456/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7825 - val_loss: 2.5772\n",
      "\n",
      "Epoch 00456: val_loss did not improve from 2.54449\n",
      "Epoch 457/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7848 - val_loss: 2.5722\n",
      "\n",
      "Epoch 00457: val_loss did not improve from 2.54449\n",
      "Epoch 458/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7885 - val_loss: 2.5876\n",
      "\n",
      "Epoch 00458: val_loss did not improve from 2.54449\n",
      "Epoch 459/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7889 - val_loss: 2.5789\n",
      "\n",
      "Epoch 00459: val_loss did not improve from 2.54449\n",
      "Epoch 460/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7930 - val_loss: 2.5920\n",
      "\n",
      "Epoch 00460: val_loss did not improve from 2.54449\n",
      "Epoch 461/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7877 - val_loss: 2.5828\n",
      "\n",
      "Epoch 00461: val_loss did not improve from 2.54449\n",
      "Epoch 462/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7950 - val_loss: 2.5909\n",
      "\n",
      "Epoch 00462: val_loss did not improve from 2.54449\n",
      "Epoch 463/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7912 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00463: val_loss did not improve from 2.54449\n",
      "Epoch 464/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7964 - val_loss: 2.5832\n",
      "\n",
      "Epoch 00464: val_loss did not improve from 2.54449\n",
      "Epoch 465/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7900 - val_loss: 2.5883\n",
      "\n",
      "Epoch 00465: val_loss did not improve from 2.54449\n",
      "Epoch 466/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7946 - val_loss: 2.5708\n",
      "\n",
      "Epoch 00466: val_loss did not improve from 2.54449\n",
      "Epoch 467/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7916 - val_loss: 2.5874\n",
      "\n",
      "Epoch 00467: val_loss did not improve from 2.54449\n",
      "Epoch 468/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7886 - val_loss: 2.5809\n",
      "\n",
      "Epoch 00468: val_loss did not improve from 2.54449\n",
      "Epoch 469/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8008 - val_loss: 2.5779\n",
      "\n",
      "Epoch 00469: val_loss did not improve from 2.54449\n",
      "Epoch 470/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7825 - val_loss: 2.5864\n",
      "\n",
      "Epoch 00470: val_loss did not improve from 2.54449\n",
      "Epoch 471/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7893 - val_loss: 2.5842\n",
      "\n",
      "Epoch 00471: val_loss did not improve from 2.54449\n",
      "Epoch 472/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7892 - val_loss: 2.5877\n",
      "\n",
      "Epoch 00472: val_loss did not improve from 2.54449\n",
      "Epoch 473/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7947 - val_loss: 2.5765\n",
      "\n",
      "Epoch 00473: val_loss did not improve from 2.54449\n",
      "Epoch 474/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7866 - val_loss: 2.5942\n",
      "\n",
      "Epoch 00474: val_loss did not improve from 2.54449\n",
      "Epoch 475/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7820 - val_loss: 2.5833\n",
      "\n",
      "Epoch 00475: val_loss did not improve from 2.54449\n",
      "Epoch 476/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7935 - val_loss: 2.5785\n",
      "\n",
      "Epoch 00476: val_loss did not improve from 2.54449\n",
      "Epoch 477/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7996 - val_loss: 2.5914\n",
      "\n",
      "Epoch 00477: val_loss did not improve from 2.54449\n",
      "Epoch 478/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7830 - val_loss: 2.5781\n",
      "\n",
      "Epoch 00478: val_loss did not improve from 2.54449\n",
      "Epoch 479/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7937 - val_loss: 2.5854\n",
      "\n",
      "Epoch 00479: val_loss did not improve from 2.54449\n",
      "Epoch 480/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7874 - val_loss: 2.5789\n",
      "\n",
      "Epoch 00480: val_loss did not improve from 2.54449\n",
      "Epoch 481/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7938 - val_loss: 2.5739\n",
      "\n",
      "Epoch 00481: val_loss did not improve from 2.54449\n",
      "Epoch 482/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.8098 - val_loss: 2.5760\n",
      "\n",
      "Epoch 00482: val_loss did not improve from 2.54449\n",
      "Epoch 483/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7866 - val_loss: 2.5811\n",
      "\n",
      "Epoch 00483: val_loss did not improve from 2.54449\n",
      "Epoch 484/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7844 - val_loss: 2.5837\n",
      "\n",
      "Epoch 00484: val_loss did not improve from 2.54449\n",
      "Epoch 485/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7947 - val_loss: 2.5909\n",
      "\n",
      "Epoch 00485: val_loss did not improve from 2.54449\n",
      "Epoch 486/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7904 - val_loss: 2.5817\n",
      "\n",
      "Epoch 00486: val_loss did not improve from 2.54449\n",
      "Epoch 487/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7936 - val_loss: 2.5807\n",
      "\n",
      "Epoch 00487: val_loss did not improve from 2.54449\n",
      "Epoch 488/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7860 - val_loss: 2.5732\n",
      "\n",
      "Epoch 00488: val_loss did not improve from 2.54449\n",
      "Epoch 489/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7974 - val_loss: 2.5922\n",
      "\n",
      "Epoch 00489: val_loss did not improve from 2.54449\n",
      "Epoch 490/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7943 - val_loss: 2.5835\n",
      "\n",
      "Epoch 00490: val_loss did not improve from 2.54449\n",
      "Epoch 491/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7952 - val_loss: 2.5767\n",
      "\n",
      "Epoch 00491: val_loss did not improve from 2.54449\n",
      "Epoch 492/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7974 - val_loss: 2.5885\n",
      "\n",
      "Epoch 00492: val_loss did not improve from 2.54449\n",
      "Epoch 493/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7851 - val_loss: 2.5931\n",
      "\n",
      "Epoch 00493: val_loss did not improve from 2.54449\n",
      "Epoch 494/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7912 - val_loss: 2.5971\n",
      "\n",
      "Epoch 00494: val_loss did not improve from 2.54449\n",
      "Epoch 495/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7878 - val_loss: 2.5900\n",
      "\n",
      "Epoch 00495: val_loss did not improve from 2.54449\n",
      "Epoch 496/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7947 - val_loss: 2.5746\n",
      "\n",
      "Epoch 00496: val_loss did not improve from 2.54449\n",
      "Epoch 497/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7824 - val_loss: 2.5857\n",
      "\n",
      "Epoch 00497: val_loss did not improve from 2.54449\n",
      "Epoch 498/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7870 - val_loss: 2.5768\n",
      "\n",
      "Epoch 00498: val_loss did not improve from 2.54449\n",
      "Epoch 499/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7876 - val_loss: 2.5680\n",
      "\n",
      "Epoch 00499: val_loss did not improve from 2.54449\n",
      "Epoch 500/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.8000 - val_loss: 2.5879\n",
      "\n",
      "Epoch 00500: val_loss did not improve from 2.54449\n",
      "Epoch 501/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7936 - val_loss: 2.5700\n",
      "\n",
      "Epoch 00501: val_loss did not improve from 2.54449\n",
      "Epoch 502/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7948 - val_loss: 2.5914\n",
      "\n",
      "Epoch 00502: val_loss did not improve from 2.54449\n",
      "Epoch 503/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7864 - val_loss: 2.5730\n",
      "\n",
      "Epoch 00503: val_loss did not improve from 2.54449\n",
      "Epoch 504/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7851 - val_loss: 2.5633\n",
      "\n",
      "Epoch 00504: val_loss did not improve from 2.54449\n",
      "Epoch 505/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7856 - val_loss: 2.5702\n",
      "\n",
      "Epoch 00505: val_loss did not improve from 2.54449\n",
      "Epoch 506/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7863 - val_loss: 2.5692\n",
      "\n",
      "Epoch 00506: val_loss did not improve from 2.54449\n",
      "Epoch 507/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7842 - val_loss: 2.5750\n",
      "\n",
      "Epoch 00507: val_loss did not improve from 2.54449\n",
      "Epoch 508/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7936 - val_loss: 2.5705\n",
      "\n",
      "Epoch 00508: val_loss did not improve from 2.54449\n",
      "Epoch 509/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7985 - val_loss: 2.5773\n",
      "\n",
      "Epoch 00509: val_loss did not improve from 2.54449\n",
      "Epoch 510/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7846 - val_loss: 2.5776\n",
      "\n",
      "Epoch 00510: val_loss did not improve from 2.54449\n",
      "Epoch 511/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7925 - val_loss: 2.5627\n",
      "\n",
      "Epoch 00511: val_loss did not improve from 2.54449\n",
      "Epoch 512/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7918 - val_loss: 2.5784\n",
      "\n",
      "Epoch 00512: val_loss did not improve from 2.54449\n",
      "Epoch 513/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7959 - val_loss: 2.5896\n",
      "\n",
      "Epoch 00513: val_loss did not improve from 2.54449\n",
      "Epoch 514/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7910 - val_loss: 2.5704\n",
      "\n",
      "Epoch 00514: val_loss did not improve from 2.54449\n",
      "Epoch 515/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7928 - val_loss: 2.5670\n",
      "\n",
      "Epoch 00515: val_loss did not improve from 2.54449\n",
      "Epoch 516/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7740 - val_loss: 2.5772\n",
      "\n",
      "Epoch 00516: val_loss did not improve from 2.54449\n",
      "Epoch 517/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7966 - val_loss: 2.5836\n",
      "\n",
      "Epoch 00517: val_loss did not improve from 2.54449\n",
      "Epoch 518/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7820 - val_loss: 2.5842\n",
      "\n",
      "Epoch 00518: val_loss did not improve from 2.54449\n",
      "Epoch 519/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7941 - val_loss: 2.5573\n",
      "\n",
      "Epoch 00519: val_loss did not improve from 2.54449\n",
      "Epoch 520/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7969 - val_loss: 2.5766\n",
      "\n",
      "Epoch 00520: val_loss did not improve from 2.54449\n",
      "Epoch 521/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7872 - val_loss: 2.5730\n",
      "\n",
      "Epoch 00521: val_loss did not improve from 2.54449\n",
      "Epoch 522/3000\n",
      "51530/51530 [==============================] - 21s 406us/step - loss: 1.7920 - val_loss: 2.5782\n",
      "\n",
      "Epoch 00522: val_loss did not improve from 2.54449\n",
      "Epoch 523/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.7840 - val_loss: 2.5741\n",
      "\n",
      "Epoch 00523: val_loss did not improve from 2.54449\n",
      "Epoch 524/3000\n",
      "51530/51530 [==============================] - 18s 348us/step - loss: 1.7845 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00524: val_loss did not improve from 2.54449\n",
      "Epoch 525/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7803 - val_loss: 2.5773\n",
      "\n",
      "Epoch 00525: val_loss did not improve from 2.54449\n",
      "Epoch 526/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7898 - val_loss: 2.5810\n",
      "\n",
      "Epoch 00526: val_loss did not improve from 2.54449\n",
      "Epoch 527/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7965 - val_loss: 2.5853\n",
      "\n",
      "Epoch 00527: val_loss did not improve from 2.54449\n",
      "Epoch 528/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7937 - val_loss: 2.5829\n",
      "\n",
      "Epoch 00528: val_loss did not improve from 2.54449\n",
      "Epoch 529/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7823 - val_loss: 2.5890\n",
      "\n",
      "Epoch 00529: val_loss did not improve from 2.54449\n",
      "Epoch 530/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7955 - val_loss: 2.5779\n",
      "\n",
      "Epoch 00530: val_loss did not improve from 2.54449\n",
      "Epoch 531/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7946 - val_loss: 2.5678\n",
      "\n",
      "Epoch 00531: val_loss did not improve from 2.54449\n",
      "Epoch 532/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7865 - val_loss: 2.5751\n",
      "\n",
      "Epoch 00532: val_loss did not improve from 2.54449\n",
      "Epoch 533/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7902 - val_loss: 2.5731\n",
      "\n",
      "Epoch 00533: val_loss did not improve from 2.54449\n",
      "Epoch 534/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7900 - val_loss: 2.5788\n",
      "\n",
      "Epoch 00534: val_loss did not improve from 2.54449\n",
      "Epoch 535/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7892 - val_loss: 2.5830\n",
      "\n",
      "Epoch 00535: val_loss did not improve from 2.54449\n",
      "Epoch 536/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7924 - val_loss: 2.5791\n",
      "\n",
      "Epoch 00536: val_loss did not improve from 2.54449\n",
      "Epoch 537/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7886 - val_loss: 2.5839\n",
      "\n",
      "Epoch 00537: val_loss did not improve from 2.54449\n",
      "Epoch 538/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7983 - val_loss: 2.5861\n",
      "\n",
      "Epoch 00538: val_loss did not improve from 2.54449\n",
      "Epoch 539/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7929 - val_loss: 2.5923\n",
      "\n",
      "Epoch 00539: val_loss did not improve from 2.54449\n",
      "Epoch 540/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7894 - val_loss: 2.5978\n",
      "\n",
      "Epoch 00540: val_loss did not improve from 2.54449\n",
      "Epoch 541/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7991 - val_loss: 2.5831\n",
      "\n",
      "Epoch 00541: val_loss did not improve from 2.54449\n",
      "Epoch 542/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7939 - val_loss: 2.5839\n",
      "\n",
      "Epoch 00542: val_loss did not improve from 2.54449\n",
      "Epoch 543/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7887 - val_loss: 2.5858\n",
      "\n",
      "Epoch 00543: val_loss did not improve from 2.54449\n",
      "Epoch 544/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7802 - val_loss: 2.5851\n",
      "\n",
      "Epoch 00544: val_loss did not improve from 2.54449\n",
      "Epoch 545/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7845 - val_loss: 2.5745\n",
      "\n",
      "Epoch 00545: val_loss did not improve from 2.54449\n",
      "Epoch 546/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7825 - val_loss: 2.5779\n",
      "\n",
      "Epoch 00546: val_loss did not improve from 2.54449\n",
      "Epoch 547/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7883 - val_loss: 2.5803\n",
      "\n",
      "Epoch 00547: val_loss did not improve from 2.54449\n",
      "Epoch 548/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7916 - val_loss: 2.5864\n",
      "\n",
      "Epoch 00548: val_loss did not improve from 2.54449\n",
      "Epoch 549/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7910 - val_loss: 2.5793\n",
      "\n",
      "Epoch 00549: val_loss did not improve from 2.54449\n",
      "Epoch 550/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7879 - val_loss: 2.5962\n",
      "\n",
      "Epoch 00550: val_loss did not improve from 2.54449\n",
      "Epoch 551/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7937 - val_loss: 2.5844\n",
      "\n",
      "Epoch 00551: val_loss did not improve from 2.54449\n",
      "Epoch 552/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7903 - val_loss: 2.5802\n",
      "\n",
      "Epoch 00552: val_loss did not improve from 2.54449\n",
      "Epoch 553/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7966 - val_loss: 2.5694\n",
      "\n",
      "Epoch 00553: val_loss did not improve from 2.54449\n",
      "Epoch 554/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7909 - val_loss: 2.5826\n",
      "\n",
      "Epoch 00554: val_loss did not improve from 2.54449\n",
      "Epoch 555/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7898 - val_loss: 2.5796\n",
      "\n",
      "Epoch 00555: val_loss did not improve from 2.54449\n",
      "Epoch 556/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7732 - val_loss: 2.5715\n",
      "\n",
      "Epoch 00556: val_loss did not improve from 2.54449\n",
      "Epoch 557/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7862 - val_loss: 2.5748\n",
      "\n",
      "Epoch 00557: val_loss did not improve from 2.54449\n",
      "Epoch 558/3000\n",
      "51530/51530 [==============================] - 17s 338us/step - loss: 1.7874 - val_loss: 2.5837\n",
      "\n",
      "Epoch 00558: val_loss did not improve from 2.54449\n",
      "Epoch 559/3000\n",
      "51530/51530 [==============================] - 17s 339us/step - loss: 1.7836 - val_loss: 2.5890\n",
      "\n",
      "Epoch 00559: val_loss did not improve from 2.54449\n",
      "Epoch 560/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7923 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00560: val_loss did not improve from 2.54449\n",
      "Epoch 561/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7907 - val_loss: 2.5777\n",
      "\n",
      "Epoch 00561: val_loss did not improve from 2.54449\n",
      "Epoch 562/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7881 - val_loss: 2.5854\n",
      "\n",
      "Epoch 00562: val_loss did not improve from 2.54449\n",
      "Epoch 563/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7850 - val_loss: 2.5868\n",
      "\n",
      "Epoch 00563: val_loss did not improve from 2.54449\n",
      "Epoch 564/3000\n",
      "51530/51530 [==============================] - 19s 372us/step - loss: 1.7931 - val_loss: 2.5830\n",
      "\n",
      "Epoch 00564: val_loss did not improve from 2.54449\n",
      "Epoch 565/3000\n",
      "51530/51530 [==============================] - 20s 386us/step - loss: 1.7994 - val_loss: 2.5784\n",
      "\n",
      "Epoch 00565: val_loss did not improve from 2.54449\n",
      "Epoch 566/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7942 - val_loss: 2.5801\n",
      "\n",
      "Epoch 00566: val_loss did not improve from 2.54449\n",
      "Epoch 567/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7867 - val_loss: 2.5841\n",
      "\n",
      "Epoch 00567: val_loss did not improve from 2.54449\n",
      "Epoch 568/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7936 - val_loss: 2.5866\n",
      "\n",
      "Epoch 00568: val_loss did not improve from 2.54449\n",
      "Epoch 569/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7942 - val_loss: 2.5768\n",
      "\n",
      "Epoch 00569: val_loss did not improve from 2.54449\n",
      "Epoch 570/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7932 - val_loss: 2.5802\n",
      "\n",
      "Epoch 00570: val_loss did not improve from 2.54449\n",
      "Epoch 571/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7829 - val_loss: 2.5749\n",
      "\n",
      "Epoch 00571: val_loss did not improve from 2.54449\n",
      "Epoch 572/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7926 - val_loss: 2.5735\n",
      "\n",
      "Epoch 00572: val_loss did not improve from 2.54449\n",
      "Epoch 573/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7734 - val_loss: 2.5794\n",
      "\n",
      "Epoch 00573: val_loss did not improve from 2.54449\n",
      "Epoch 574/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7941 - val_loss: 2.5888\n",
      "\n",
      "Epoch 00574: val_loss did not improve from 2.54449\n",
      "Epoch 575/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7840 - val_loss: 2.5892\n",
      "\n",
      "Epoch 00575: val_loss did not improve from 2.54449\n",
      "Epoch 576/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7880 - val_loss: 2.5876\n",
      "\n",
      "Epoch 00576: val_loss did not improve from 2.54449\n",
      "Epoch 577/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7966 - val_loss: 2.5942\n",
      "\n",
      "Epoch 00577: val_loss did not improve from 2.54449\n",
      "Epoch 578/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7939 - val_loss: 2.6007\n",
      "\n",
      "Epoch 00578: val_loss did not improve from 2.54449\n",
      "Epoch 579/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7881 - val_loss: 2.5878\n",
      "\n",
      "Epoch 00579: val_loss did not improve from 2.54449\n",
      "Epoch 580/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8010 - val_loss: 2.5793\n",
      "\n",
      "Epoch 00580: val_loss did not improve from 2.54449\n",
      "Epoch 581/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7964 - val_loss: 2.5783\n",
      "\n",
      "Epoch 00581: val_loss did not improve from 2.54449\n",
      "Epoch 582/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7911 - val_loss: 2.5854\n",
      "\n",
      "Epoch 00582: val_loss did not improve from 2.54449\n",
      "Epoch 583/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7843 - val_loss: 2.5817\n",
      "\n",
      "Epoch 00583: val_loss did not improve from 2.54449\n",
      "Epoch 584/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7934 - val_loss: 2.5769\n",
      "\n",
      "Epoch 00584: val_loss did not improve from 2.54449\n",
      "Epoch 585/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7950 - val_loss: 2.5935\n",
      "\n",
      "Epoch 00585: val_loss did not improve from 2.54449\n",
      "Epoch 586/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7963 - val_loss: 2.5878\n",
      "\n",
      "Epoch 00586: val_loss did not improve from 2.54449\n",
      "Epoch 587/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.8000 - val_loss: 2.5887\n",
      "\n",
      "Epoch 00587: val_loss did not improve from 2.54449\n",
      "Epoch 588/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7961 - val_loss: 2.5763\n",
      "\n",
      "Epoch 00588: val_loss did not improve from 2.54449\n",
      "Epoch 589/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7904 - val_loss: 2.5923\n",
      "\n",
      "Epoch 00589: val_loss did not improve from 2.54449\n",
      "Epoch 590/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7826 - val_loss: 2.5798\n",
      "\n",
      "Epoch 00590: val_loss did not improve from 2.54449\n",
      "Epoch 591/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7832 - val_loss: 2.5675\n",
      "\n",
      "Epoch 00591: val_loss did not improve from 2.54449\n",
      "Epoch 592/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7800 - val_loss: 2.5795\n",
      "\n",
      "Epoch 00592: val_loss did not improve from 2.54449\n",
      "Epoch 593/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7920 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00593: val_loss did not improve from 2.54449\n",
      "Epoch 594/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7889 - val_loss: 2.5914\n",
      "\n",
      "Epoch 00594: val_loss did not improve from 2.54449\n",
      "Epoch 595/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7954 - val_loss: 2.5878\n",
      "\n",
      "Epoch 00595: val_loss did not improve from 2.54449\n",
      "Epoch 596/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7888 - val_loss: 2.5881\n",
      "\n",
      "Epoch 00596: val_loss did not improve from 2.54449\n",
      "Epoch 597/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7993 - val_loss: 2.5723\n",
      "\n",
      "Epoch 00597: val_loss did not improve from 2.54449\n",
      "Epoch 598/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.8040 - val_loss: 2.5827\n",
      "\n",
      "Epoch 00598: val_loss did not improve from 2.54449\n",
      "Epoch 599/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.7865 - val_loss: 2.5867\n",
      "\n",
      "Epoch 00599: val_loss did not improve from 2.54449\n",
      "Epoch 600/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7888 - val_loss: 2.5845\n",
      "\n",
      "Epoch 00600: val_loss did not improve from 2.54449\n",
      "Epoch 601/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7828 - val_loss: 2.5802\n",
      "\n",
      "Epoch 00601: val_loss did not improve from 2.54449\n",
      "Epoch 602/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7949 - val_loss: 2.6023\n",
      "\n",
      "Epoch 00602: val_loss did not improve from 2.54449\n",
      "Epoch 603/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.8051 - val_loss: 2.5931\n",
      "\n",
      "Epoch 00603: val_loss did not improve from 2.54449\n",
      "Epoch 604/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.7927 - val_loss: 2.5859\n",
      "\n",
      "Epoch 00604: val_loss did not improve from 2.54449\n",
      "Epoch 605/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7889 - val_loss: 2.5723\n",
      "\n",
      "Epoch 00605: val_loss did not improve from 2.54449\n",
      "Epoch 606/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7808 - val_loss: 2.5784\n",
      "\n",
      "Epoch 00606: val_loss did not improve from 2.54449\n",
      "Epoch 607/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7921 - val_loss: 2.5920\n",
      "\n",
      "Epoch 00607: val_loss did not improve from 2.54449\n",
      "Epoch 608/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7838 - val_loss: 2.5913\n",
      "\n",
      "Epoch 00608: val_loss did not improve from 2.54449\n",
      "Epoch 609/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7817 - val_loss: 2.5826\n",
      "\n",
      "Epoch 00609: val_loss did not improve from 2.54449\n",
      "Epoch 610/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7837 - val_loss: 2.5916\n",
      "\n",
      "Epoch 00610: val_loss did not improve from 2.54449\n",
      "Epoch 611/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7937 - val_loss: 2.5798\n",
      "\n",
      "Epoch 00611: val_loss did not improve from 2.54449\n",
      "Epoch 612/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7887 - val_loss: 2.5806\n",
      "\n",
      "Epoch 00612: val_loss did not improve from 2.54449\n",
      "Epoch 613/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7897 - val_loss: 2.5866\n",
      "\n",
      "Epoch 00613: val_loss did not improve from 2.54449\n",
      "Epoch 614/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7743 - val_loss: 2.5968\n",
      "\n",
      "Epoch 00614: val_loss did not improve from 2.54449\n",
      "Epoch 615/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7896 - val_loss: 2.5867\n",
      "\n",
      "Epoch 00615: val_loss did not improve from 2.54449\n",
      "Epoch 616/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7853 - val_loss: 2.5822\n",
      "\n",
      "Epoch 00616: val_loss did not improve from 2.54449\n",
      "Epoch 617/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7824 - val_loss: 2.5743\n",
      "\n",
      "Epoch 00617: val_loss did not improve from 2.54449\n",
      "Epoch 618/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7890 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00618: val_loss did not improve from 2.54449\n",
      "Epoch 619/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7830 - val_loss: 2.5834\n",
      "\n",
      "Epoch 00619: val_loss did not improve from 2.54449\n",
      "Epoch 620/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7957 - val_loss: 2.5877\n",
      "\n",
      "Epoch 00620: val_loss did not improve from 2.54449\n",
      "Epoch 621/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7879 - val_loss: 2.5711\n",
      "\n",
      "Epoch 00621: val_loss did not improve from 2.54449\n",
      "Epoch 622/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7838 - val_loss: 2.5873\n",
      "\n",
      "Epoch 00622: val_loss did not improve from 2.54449\n",
      "Epoch 623/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7860 - val_loss: 2.5748\n",
      "\n",
      "Epoch 00623: val_loss did not improve from 2.54449\n",
      "Epoch 624/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7949 - val_loss: 2.5841\n",
      "\n",
      "Epoch 00624: val_loss did not improve from 2.54449\n",
      "Epoch 625/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7887 - val_loss: 2.5708\n",
      "\n",
      "Epoch 00625: val_loss did not improve from 2.54449\n",
      "Epoch 626/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7962 - val_loss: 2.5755\n",
      "\n",
      "Epoch 00626: val_loss did not improve from 2.54449\n",
      "Epoch 627/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7827 - val_loss: 2.5833\n",
      "\n",
      "Epoch 00627: val_loss did not improve from 2.54449\n",
      "Epoch 628/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7894 - val_loss: 2.5804\n",
      "\n",
      "Epoch 00628: val_loss did not improve from 2.54449\n",
      "Epoch 629/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7859 - val_loss: 2.5739\n",
      "\n",
      "Epoch 00629: val_loss did not improve from 2.54449\n",
      "Epoch 630/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7892 - val_loss: 2.5783\n",
      "\n",
      "Epoch 00630: val_loss did not improve from 2.54449\n",
      "Epoch 631/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7881 - val_loss: 2.5818\n",
      "\n",
      "Epoch 00631: val_loss did not improve from 2.54449\n",
      "Epoch 632/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7847 - val_loss: 2.5809\n",
      "\n",
      "Epoch 00632: val_loss did not improve from 2.54449\n",
      "Epoch 633/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7939 - val_loss: 2.5845\n",
      "\n",
      "Epoch 00633: val_loss did not improve from 2.54449\n",
      "Epoch 634/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7861 - val_loss: 2.5845\n",
      "\n",
      "Epoch 00634: val_loss did not improve from 2.54449\n",
      "Epoch 635/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7844 - val_loss: 2.5813\n",
      "\n",
      "Epoch 00635: val_loss did not improve from 2.54449\n",
      "Epoch 636/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7864 - val_loss: 2.5779\n",
      "\n",
      "Epoch 00636: val_loss did not improve from 2.54449\n",
      "Epoch 637/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7907 - val_loss: 2.5737\n",
      "\n",
      "Epoch 00637: val_loss did not improve from 2.54449\n",
      "Epoch 638/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7922 - val_loss: 2.5817\n",
      "\n",
      "Epoch 00638: val_loss did not improve from 2.54449\n",
      "Epoch 639/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7888 - val_loss: 2.6024\n",
      "\n",
      "Epoch 00639: val_loss did not improve from 2.54449\n",
      "Epoch 640/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7895 - val_loss: 2.5708\n",
      "\n",
      "Epoch 00640: val_loss did not improve from 2.54449\n",
      "Epoch 641/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7916 - val_loss: 2.5724\n",
      "\n",
      "Epoch 00641: val_loss did not improve from 2.54449\n",
      "Epoch 642/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7977 - val_loss: 2.5815\n",
      "\n",
      "Epoch 00642: val_loss did not improve from 2.54449\n",
      "Epoch 643/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7877 - val_loss: 2.5778\n",
      "\n",
      "Epoch 00643: val_loss did not improve from 2.54449\n",
      "Epoch 644/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7786 - val_loss: 2.5960\n",
      "\n",
      "Epoch 00644: val_loss did not improve from 2.54449\n",
      "Epoch 645/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7853 - val_loss: 2.5864\n",
      "\n",
      "Epoch 00645: val_loss did not improve from 2.54449\n",
      "Epoch 646/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.8022 - val_loss: 2.5834\n",
      "\n",
      "Epoch 00646: val_loss did not improve from 2.54449\n",
      "Epoch 647/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7873 - val_loss: 2.5725\n",
      "\n",
      "Epoch 00647: val_loss did not improve from 2.54449\n",
      "Epoch 648/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7915 - val_loss: 2.5761\n",
      "\n",
      "Epoch 00648: val_loss did not improve from 2.54449\n",
      "Epoch 649/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7884 - val_loss: 2.5797\n",
      "\n",
      "Epoch 00649: val_loss did not improve from 2.54449\n",
      "Epoch 650/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.8020 - val_loss: 2.5790\n",
      "\n",
      "Epoch 00650: val_loss did not improve from 2.54449\n",
      "Epoch 651/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7826 - val_loss: 2.5906\n",
      "\n",
      "Epoch 00651: val_loss did not improve from 2.54449\n",
      "Epoch 652/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7875 - val_loss: 2.5828\n",
      "\n",
      "Epoch 00652: val_loss did not improve from 2.54449\n",
      "Epoch 653/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7969 - val_loss: 2.5804\n",
      "\n",
      "Epoch 00653: val_loss did not improve from 2.54449\n",
      "Epoch 654/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7820 - val_loss: 2.5791\n",
      "\n",
      "Epoch 00654: val_loss did not improve from 2.54449\n",
      "Epoch 655/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7905 - val_loss: 2.5827\n",
      "\n",
      "Epoch 00655: val_loss did not improve from 2.54449\n",
      "Epoch 656/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7915 - val_loss: 2.5875\n",
      "\n",
      "Epoch 00656: val_loss did not improve from 2.54449\n",
      "Epoch 657/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7826 - val_loss: 2.5970\n",
      "\n",
      "Epoch 00657: val_loss did not improve from 2.54449\n",
      "Epoch 658/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7727 - val_loss: 2.6060\n",
      "\n",
      "Epoch 00658: val_loss did not improve from 2.54449\n",
      "Epoch 659/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7874 - val_loss: 2.5742\n",
      "\n",
      "Epoch 00659: val_loss did not improve from 2.54449\n",
      "Epoch 660/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7943 - val_loss: 2.5837\n",
      "\n",
      "Epoch 00660: val_loss did not improve from 2.54449\n",
      "Epoch 661/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7846 - val_loss: 2.5822\n",
      "\n",
      "Epoch 00661: val_loss did not improve from 2.54449\n",
      "Epoch 662/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7811 - val_loss: 2.5943\n",
      "\n",
      "Epoch 00662: val_loss did not improve from 2.54449\n",
      "Epoch 663/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7899 - val_loss: 2.5788\n",
      "\n",
      "Epoch 00663: val_loss did not improve from 2.54449\n",
      "Epoch 664/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.8001 - val_loss: 2.5781\n",
      "\n",
      "Epoch 00664: val_loss did not improve from 2.54449\n",
      "Epoch 665/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7907 - val_loss: 2.5901\n",
      "\n",
      "Epoch 00665: val_loss did not improve from 2.54449\n",
      "Epoch 666/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7857 - val_loss: 2.5763\n",
      "\n",
      "Epoch 00666: val_loss did not improve from 2.54449\n",
      "Epoch 667/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7864 - val_loss: 2.5857\n",
      "\n",
      "Epoch 00667: val_loss did not improve from 2.54449\n",
      "Epoch 668/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7806 - val_loss: 2.5819\n",
      "\n",
      "Epoch 00668: val_loss did not improve from 2.54449\n",
      "Epoch 669/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7750 - val_loss: 2.5938\n",
      "\n",
      "Epoch 00669: val_loss did not improve from 2.54449\n",
      "Epoch 670/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7931 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00670: val_loss did not improve from 2.54449\n",
      "Epoch 671/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7870 - val_loss: 2.5852\n",
      "\n",
      "Epoch 00671: val_loss did not improve from 2.54449\n",
      "Epoch 672/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7832 - val_loss: 2.5798\n",
      "\n",
      "Epoch 00672: val_loss did not improve from 2.54449\n",
      "Epoch 673/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7919 - val_loss: 2.5935\n",
      "\n",
      "Epoch 00673: val_loss did not improve from 2.54449\n",
      "Epoch 674/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7842 - val_loss: 2.5900\n",
      "\n",
      "Epoch 00674: val_loss did not improve from 2.54449\n",
      "Epoch 675/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7912 - val_loss: 2.5919\n",
      "\n",
      "Epoch 00675: val_loss did not improve from 2.54449\n",
      "Epoch 676/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.8030 - val_loss: 2.5936\n",
      "\n",
      "Epoch 00676: val_loss did not improve from 2.54449\n",
      "Epoch 677/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7864 - val_loss: 2.5927\n",
      "\n",
      "Epoch 00677: val_loss did not improve from 2.54449\n",
      "Epoch 678/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7856 - val_loss: 2.5829\n",
      "\n",
      "Epoch 00678: val_loss did not improve from 2.54449\n",
      "Epoch 679/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7949 - val_loss: 2.5875\n",
      "\n",
      "Epoch 00679: val_loss did not improve from 2.54449\n",
      "Epoch 680/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7835 - val_loss: 2.5822\n",
      "\n",
      "Epoch 00680: val_loss did not improve from 2.54449\n",
      "Epoch 681/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7946 - val_loss: 2.5809\n",
      "\n",
      "Epoch 00681: val_loss did not improve from 2.54449\n",
      "Epoch 682/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7942 - val_loss: 2.5869\n",
      "\n",
      "Epoch 00682: val_loss did not improve from 2.54449\n",
      "Epoch 683/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7861 - val_loss: 2.5878\n",
      "\n",
      "Epoch 00683: val_loss did not improve from 2.54449\n",
      "Epoch 684/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7872 - val_loss: 2.5762\n",
      "\n",
      "Epoch 00684: val_loss did not improve from 2.54449\n",
      "Epoch 685/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7974 - val_loss: 2.5963\n",
      "\n",
      "Epoch 00685: val_loss did not improve from 2.54449\n",
      "Epoch 686/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7873 - val_loss: 2.5934\n",
      "\n",
      "Epoch 00686: val_loss did not improve from 2.54449\n",
      "Epoch 687/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7904 - val_loss: 2.5882\n",
      "\n",
      "Epoch 00687: val_loss did not improve from 2.54449\n",
      "Epoch 688/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7911 - val_loss: 2.5907\n",
      "\n",
      "Epoch 00688: val_loss did not improve from 2.54449\n",
      "Epoch 689/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7744 - val_loss: 2.6018\n",
      "\n",
      "Epoch 00689: val_loss did not improve from 2.54449\n",
      "Epoch 690/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7855 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00690: val_loss did not improve from 2.54449\n",
      "Epoch 691/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7809 - val_loss: 2.5781\n",
      "\n",
      "Epoch 00691: val_loss did not improve from 2.54449\n",
      "Epoch 692/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7922 - val_loss: 2.5929\n",
      "\n",
      "Epoch 00692: val_loss did not improve from 2.54449\n",
      "Epoch 693/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7999 - val_loss: 2.5831\n",
      "\n",
      "Epoch 00693: val_loss did not improve from 2.54449\n",
      "Epoch 694/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7825 - val_loss: 2.5760\n",
      "\n",
      "Epoch 00694: val_loss did not improve from 2.54449\n",
      "Epoch 695/3000\n",
      "51530/51530 [==============================] - 17s 338us/step - loss: 1.7980 - val_loss: 2.5811\n",
      "\n",
      "Epoch 00695: val_loss did not improve from 2.54449\n",
      "Epoch 696/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7838 - val_loss: 2.5913\n",
      "\n",
      "Epoch 00696: val_loss did not improve from 2.54449\n",
      "Epoch 697/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7907 - val_loss: 2.5983\n",
      "\n",
      "Epoch 00697: val_loss did not improve from 2.54449\n",
      "Epoch 698/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7987 - val_loss: 2.5855\n",
      "\n",
      "Epoch 00698: val_loss did not improve from 2.54449\n",
      "Epoch 699/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7862 - val_loss: 2.5759\n",
      "\n",
      "Epoch 00699: val_loss did not improve from 2.54449\n",
      "Epoch 700/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.8042 - val_loss: 2.5743\n",
      "\n",
      "Epoch 00700: val_loss did not improve from 2.54449\n",
      "Epoch 701/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7844 - val_loss: 2.5890\n",
      "\n",
      "Epoch 00701: val_loss did not improve from 2.54449\n",
      "Epoch 702/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7891 - val_loss: 2.5752\n",
      "\n",
      "Epoch 00702: val_loss did not improve from 2.54449\n",
      "Epoch 703/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7928 - val_loss: 2.5935\n",
      "\n",
      "Epoch 00703: val_loss did not improve from 2.54449\n",
      "Epoch 704/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7942 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00704: val_loss did not improve from 2.54449\n",
      "Epoch 705/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7757 - val_loss: 2.5637\n",
      "\n",
      "Epoch 00705: val_loss did not improve from 2.54449\n",
      "Epoch 706/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7894 - val_loss: 2.5860\n",
      "\n",
      "Epoch 00706: val_loss did not improve from 2.54449\n",
      "Epoch 707/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7879 - val_loss: 2.5830\n",
      "\n",
      "Epoch 00707: val_loss did not improve from 2.54449\n",
      "Epoch 708/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7899 - val_loss: 2.5804\n",
      "\n",
      "Epoch 00708: val_loss did not improve from 2.54449\n",
      "Epoch 709/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7943 - val_loss: 2.5861\n",
      "\n",
      "Epoch 00709: val_loss did not improve from 2.54449\n",
      "Epoch 710/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7934 - val_loss: 2.5803\n",
      "\n",
      "Epoch 00710: val_loss did not improve from 2.54449\n",
      "Epoch 711/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7945 - val_loss: 2.5838\n",
      "\n",
      "Epoch 00711: val_loss did not improve from 2.54449\n",
      "Epoch 712/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7880 - val_loss: 2.5845\n",
      "\n",
      "Epoch 00712: val_loss did not improve from 2.54449\n",
      "Epoch 713/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7754 - val_loss: 2.5820\n",
      "\n",
      "Epoch 00713: val_loss did not improve from 2.54449\n",
      "Epoch 714/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7899 - val_loss: 2.5905\n",
      "\n",
      "Epoch 00714: val_loss did not improve from 2.54449\n",
      "Epoch 715/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7873 - val_loss: 2.5919\n",
      "\n",
      "Epoch 00715: val_loss did not improve from 2.54449\n",
      "Epoch 716/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7886 - val_loss: 2.5858\n",
      "\n",
      "Epoch 00716: val_loss did not improve from 2.54449\n",
      "Epoch 717/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7945 - val_loss: 2.5866\n",
      "\n",
      "Epoch 00717: val_loss did not improve from 2.54449\n",
      "Epoch 718/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7933 - val_loss: 2.5849\n",
      "\n",
      "Epoch 00718: val_loss did not improve from 2.54449\n",
      "Epoch 719/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7776 - val_loss: 2.5756\n",
      "\n",
      "Epoch 00719: val_loss did not improve from 2.54449\n",
      "Epoch 720/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7873 - val_loss: 2.5775\n",
      "\n",
      "Epoch 00720: val_loss did not improve from 2.54449\n",
      "Epoch 721/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7898 - val_loss: 2.5733\n",
      "\n",
      "Epoch 00721: val_loss did not improve from 2.54449\n",
      "Epoch 722/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.8016 - val_loss: 2.5759\n",
      "\n",
      "Epoch 00722: val_loss did not improve from 2.54449\n",
      "Epoch 723/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7924 - val_loss: 2.5709\n",
      "\n",
      "Epoch 00723: val_loss did not improve from 2.54449\n",
      "Epoch 724/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7945 - val_loss: 2.5895\n",
      "\n",
      "Epoch 00724: val_loss did not improve from 2.54449\n",
      "Epoch 725/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7905 - val_loss: 2.5898\n",
      "\n",
      "Epoch 00725: val_loss did not improve from 2.54449\n",
      "Epoch 726/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7833 - val_loss: 2.5929\n",
      "\n",
      "Epoch 00726: val_loss did not improve from 2.54449\n",
      "Epoch 727/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7925 - val_loss: 2.5959\n",
      "\n",
      "Epoch 00727: val_loss did not improve from 2.54449\n",
      "Epoch 728/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7815 - val_loss: 2.5910\n",
      "\n",
      "Epoch 00728: val_loss did not improve from 2.54449\n",
      "Epoch 729/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7909 - val_loss: 2.5768\n",
      "\n",
      "Epoch 00729: val_loss did not improve from 2.54449\n",
      "Epoch 730/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8147 - val_loss: 2.6034\n",
      "\n",
      "Epoch 00730: val_loss did not improve from 2.54449\n",
      "Epoch 731/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7863 - val_loss: 2.5838\n",
      "\n",
      "Epoch 00731: val_loss did not improve from 2.54449\n",
      "Epoch 732/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7893 - val_loss: 2.5833\n",
      "\n",
      "Epoch 00732: val_loss did not improve from 2.54449\n",
      "Epoch 733/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7916 - val_loss: 2.5872\n",
      "\n",
      "Epoch 00733: val_loss did not improve from 2.54449\n",
      "Epoch 734/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7958 - val_loss: 2.5687\n",
      "\n",
      "Epoch 00734: val_loss did not improve from 2.54449\n",
      "Epoch 735/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7812 - val_loss: 2.5932\n",
      "\n",
      "Epoch 00735: val_loss did not improve from 2.54449\n",
      "Epoch 736/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7840 - val_loss: 2.5821\n",
      "\n",
      "Epoch 00736: val_loss did not improve from 2.54449\n",
      "Epoch 737/3000\n",
      "51530/51530 [==============================] - 19s 364us/step - loss: 1.7770 - val_loss: 2.5820\n",
      "\n",
      "Epoch 00737: val_loss did not improve from 2.54449\n",
      "Epoch 738/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7791 - val_loss: 2.5932\n",
      "\n",
      "Epoch 00738: val_loss did not improve from 2.54449\n",
      "Epoch 739/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7862 - val_loss: 2.5895\n",
      "\n",
      "Epoch 00739: val_loss did not improve from 2.54449\n",
      "Epoch 740/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7908 - val_loss: 2.5879\n",
      "\n",
      "Epoch 00740: val_loss did not improve from 2.54449\n",
      "Epoch 741/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7940 - val_loss: 2.5934\n",
      "\n",
      "Epoch 00741: val_loss did not improve from 2.54449\n",
      "Epoch 742/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7946 - val_loss: 2.5883\n",
      "\n",
      "Epoch 00742: val_loss did not improve from 2.54449\n",
      "Epoch 743/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7973 - val_loss: 2.6048\n",
      "\n",
      "Epoch 00743: val_loss did not improve from 2.54449\n",
      "Epoch 744/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7962 - val_loss: 2.5857\n",
      "\n",
      "Epoch 00744: val_loss did not improve from 2.54449\n",
      "Epoch 745/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7870 - val_loss: 2.5841\n",
      "\n",
      "Epoch 00745: val_loss did not improve from 2.54449\n",
      "Epoch 746/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7909 - val_loss: 2.5833\n",
      "\n",
      "Epoch 00746: val_loss did not improve from 2.54449\n",
      "Epoch 747/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7923 - val_loss: 2.5801\n",
      "\n",
      "Epoch 00747: val_loss did not improve from 2.54449\n",
      "Epoch 748/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7834 - val_loss: 2.5803\n",
      "\n",
      "Epoch 00748: val_loss did not improve from 2.54449\n",
      "Epoch 749/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7888 - val_loss: 2.5872\n",
      "\n",
      "Epoch 00749: val_loss did not improve from 2.54449\n",
      "Epoch 750/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7822 - val_loss: 2.5878\n",
      "\n",
      "Epoch 00750: val_loss did not improve from 2.54449\n",
      "Epoch 751/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7981 - val_loss: 2.5814\n",
      "\n",
      "Epoch 00751: val_loss did not improve from 2.54449\n",
      "Epoch 752/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7917 - val_loss: 2.5811\n",
      "\n",
      "Epoch 00752: val_loss did not improve from 2.54449\n",
      "Epoch 753/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7934 - val_loss: 2.5863\n",
      "\n",
      "Epoch 00753: val_loss did not improve from 2.54449\n",
      "Epoch 754/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7856 - val_loss: 2.5746\n",
      "\n",
      "Epoch 00754: val_loss did not improve from 2.54449\n",
      "Epoch 755/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7920 - val_loss: 2.5831\n",
      "\n",
      "Epoch 00755: val_loss did not improve from 2.54449\n",
      "Epoch 756/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7917 - val_loss: 2.5823\n",
      "\n",
      "Epoch 00756: val_loss did not improve from 2.54449\n",
      "Epoch 757/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7962 - val_loss: 2.5841\n",
      "\n",
      "Epoch 00757: val_loss did not improve from 2.54449\n",
      "Epoch 758/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7821 - val_loss: 2.5771\n",
      "\n",
      "Epoch 00758: val_loss did not improve from 2.54449\n",
      "Epoch 759/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7752 - val_loss: 2.5850\n",
      "\n",
      "Epoch 00759: val_loss did not improve from 2.54449\n",
      "Epoch 760/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7859 - val_loss: 2.5941\n",
      "\n",
      "Epoch 00760: val_loss did not improve from 2.54449\n",
      "Epoch 761/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7794 - val_loss: 2.5875\n",
      "\n",
      "Epoch 00761: val_loss did not improve from 2.54449\n",
      "Epoch 762/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7959 - val_loss: 2.5787\n",
      "\n",
      "Epoch 00762: val_loss did not improve from 2.54449\n",
      "Epoch 763/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7895 - val_loss: 2.5756\n",
      "\n",
      "Epoch 00763: val_loss did not improve from 2.54449\n",
      "Epoch 764/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7921 - val_loss: 2.5765\n",
      "\n",
      "Epoch 00764: val_loss did not improve from 2.54449\n",
      "Epoch 765/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.8002 - val_loss: 2.5795\n",
      "\n",
      "Epoch 00765: val_loss did not improve from 2.54449\n",
      "Epoch 766/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7954 - val_loss: 2.5841\n",
      "\n",
      "Epoch 00766: val_loss did not improve from 2.54449\n",
      "Epoch 767/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7846 - val_loss: 2.5945\n",
      "\n",
      "Epoch 00767: val_loss did not improve from 2.54449\n",
      "Epoch 768/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7956 - val_loss: 2.5834\n",
      "\n",
      "Epoch 00768: val_loss did not improve from 2.54449\n",
      "Epoch 769/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7875 - val_loss: 2.5779\n",
      "\n",
      "Epoch 00769: val_loss did not improve from 2.54449\n",
      "Epoch 770/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7854 - val_loss: 2.5965\n",
      "\n",
      "Epoch 00770: val_loss did not improve from 2.54449\n",
      "Epoch 771/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.7876 - val_loss: 2.5756\n",
      "\n",
      "Epoch 00771: val_loss did not improve from 2.54449\n",
      "Epoch 772/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7906 - val_loss: 2.5975\n",
      "\n",
      "Epoch 00772: val_loss did not improve from 2.54449\n",
      "Epoch 773/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7872 - val_loss: 2.5855\n",
      "\n",
      "Epoch 00773: val_loss did not improve from 2.54449\n",
      "Epoch 774/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7937 - val_loss: 2.6121\n",
      "\n",
      "Epoch 00774: val_loss did not improve from 2.54449\n",
      "Epoch 775/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7889 - val_loss: 2.6061\n",
      "\n",
      "Epoch 00775: val_loss did not improve from 2.54449\n",
      "Epoch 776/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7825 - val_loss: 2.5840\n",
      "\n",
      "Epoch 00776: val_loss did not improve from 2.54449\n",
      "Epoch 777/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7864 - val_loss: 2.5875\n",
      "\n",
      "Epoch 00777: val_loss did not improve from 2.54449\n",
      "Epoch 778/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7846 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00778: val_loss did not improve from 2.54449\n",
      "Epoch 779/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7940 - val_loss: 2.6085\n",
      "\n",
      "Epoch 00779: val_loss did not improve from 2.54449\n",
      "Epoch 780/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7920 - val_loss: 2.5801\n",
      "\n",
      "Epoch 00780: val_loss did not improve from 2.54449\n",
      "Epoch 781/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7995 - val_loss: 2.5982\n",
      "\n",
      "Epoch 00781: val_loss did not improve from 2.54449\n",
      "Epoch 782/3000\n",
      "51530/51530 [==============================] - 18s 356us/step - loss: 1.7857 - val_loss: 2.5796\n",
      "\n",
      "Epoch 00782: val_loss did not improve from 2.54449\n",
      "Epoch 783/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7817 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00783: val_loss did not improve from 2.54449\n",
      "Epoch 784/3000\n",
      "51530/51530 [==============================] - 18s 353us/step - loss: 1.7896 - val_loss: 2.5812\n",
      "\n",
      "Epoch 00784: val_loss did not improve from 2.54449\n",
      "Epoch 785/3000\n",
      "51530/51530 [==============================] - 19s 375us/step - loss: 1.7833 - val_loss: 2.5899\n",
      "\n",
      "Epoch 00785: val_loss did not improve from 2.54449\n",
      "Epoch 786/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7911 - val_loss: 2.5836\n",
      "\n",
      "Epoch 00786: val_loss did not improve from 2.54449\n",
      "Epoch 787/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7925 - val_loss: 2.5802\n",
      "\n",
      "Epoch 00787: val_loss did not improve from 2.54449\n",
      "Epoch 788/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7949 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00788: val_loss did not improve from 2.54449\n",
      "Epoch 789/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8001 - val_loss: 2.5918\n",
      "\n",
      "Epoch 00789: val_loss did not improve from 2.54449\n",
      "Epoch 790/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7835 - val_loss: 2.6014\n",
      "\n",
      "Epoch 00790: val_loss did not improve from 2.54449\n",
      "Epoch 791/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7879 - val_loss: 2.6013\n",
      "\n",
      "Epoch 00791: val_loss did not improve from 2.54449\n",
      "Epoch 792/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7919 - val_loss: 2.5930\n",
      "\n",
      "Epoch 00792: val_loss did not improve from 2.54449\n",
      "Epoch 793/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7837 - val_loss: 2.5806\n",
      "\n",
      "Epoch 00793: val_loss did not improve from 2.54449\n",
      "Epoch 794/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7849 - val_loss: 2.5854\n",
      "\n",
      "Epoch 00794: val_loss did not improve from 2.54449\n",
      "Epoch 795/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7793 - val_loss: 2.5832\n",
      "\n",
      "Epoch 00795: val_loss did not improve from 2.54449\n",
      "Epoch 796/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7907 - val_loss: 2.6103\n",
      "\n",
      "Epoch 00796: val_loss did not improve from 2.54449\n",
      "Epoch 797/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7844 - val_loss: 2.5911\n",
      "\n",
      "Epoch 00797: val_loss did not improve from 2.54449\n",
      "Epoch 798/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7894 - val_loss: 2.5849\n",
      "\n",
      "Epoch 00798: val_loss did not improve from 2.54449\n",
      "Epoch 799/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7889 - val_loss: 2.5798\n",
      "\n",
      "Epoch 00799: val_loss did not improve from 2.54449\n",
      "Epoch 800/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7843 - val_loss: 2.5946\n",
      "\n",
      "Epoch 00800: val_loss did not improve from 2.54449\n",
      "Epoch 801/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7762 - val_loss: 2.5855\n",
      "\n",
      "Epoch 00801: val_loss did not improve from 2.54449\n",
      "Epoch 802/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7835 - val_loss: 2.5837\n",
      "\n",
      "Epoch 00802: val_loss did not improve from 2.54449\n",
      "Epoch 803/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7870 - val_loss: 2.5986\n",
      "\n",
      "Epoch 00803: val_loss did not improve from 2.54449\n",
      "Epoch 804/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.8004 - val_loss: 2.5992\n",
      "\n",
      "Epoch 00804: val_loss did not improve from 2.54449\n",
      "Epoch 805/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7857 - val_loss: 2.5874\n",
      "\n",
      "Epoch 00805: val_loss did not improve from 2.54449\n",
      "Epoch 806/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7884 - val_loss: 2.5957\n",
      "\n",
      "Epoch 00806: val_loss did not improve from 2.54449\n",
      "Epoch 807/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7873 - val_loss: 2.6002\n",
      "\n",
      "Epoch 00807: val_loss did not improve from 2.54449\n",
      "Epoch 808/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7848 - val_loss: 2.6074\n",
      "\n",
      "Epoch 00808: val_loss did not improve from 2.54449\n",
      "Epoch 809/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7863 - val_loss: 2.5915\n",
      "\n",
      "Epoch 00809: val_loss did not improve from 2.54449\n",
      "Epoch 810/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7897 - val_loss: 2.5906\n",
      "\n",
      "Epoch 00810: val_loss did not improve from 2.54449\n",
      "Epoch 811/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7958 - val_loss: 2.5974\n",
      "\n",
      "Epoch 00811: val_loss did not improve from 2.54449\n",
      "Epoch 812/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7836 - val_loss: 2.6014\n",
      "\n",
      "Epoch 00812: val_loss did not improve from 2.54449\n",
      "Epoch 813/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.8004 - val_loss: 2.5895\n",
      "\n",
      "Epoch 00813: val_loss did not improve from 2.54449\n",
      "Epoch 814/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7861 - val_loss: 2.5818\n",
      "\n",
      "Epoch 00814: val_loss did not improve from 2.54449\n",
      "Epoch 815/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7954 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00815: val_loss did not improve from 2.54449\n",
      "Epoch 816/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7860 - val_loss: 2.5766\n",
      "\n",
      "Epoch 00816: val_loss did not improve from 2.54449\n",
      "Epoch 817/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7939 - val_loss: 2.5799\n",
      "\n",
      "Epoch 00817: val_loss did not improve from 2.54449\n",
      "Epoch 818/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7920 - val_loss: 2.5903\n",
      "\n",
      "Epoch 00818: val_loss did not improve from 2.54449\n",
      "Epoch 819/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7942 - val_loss: 2.5852\n",
      "\n",
      "Epoch 00819: val_loss did not improve from 2.54449\n",
      "Epoch 820/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7836 - val_loss: 2.5873\n",
      "\n",
      "Epoch 00820: val_loss did not improve from 2.54449\n",
      "Epoch 821/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7838 - val_loss: 2.5867\n",
      "\n",
      "Epoch 00821: val_loss did not improve from 2.54449\n",
      "Epoch 822/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7872 - val_loss: 2.5790\n",
      "\n",
      "Epoch 00822: val_loss did not improve from 2.54449\n",
      "Epoch 823/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7797 - val_loss: 2.5934\n",
      "\n",
      "Epoch 00823: val_loss did not improve from 2.54449\n",
      "Epoch 824/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7952 - val_loss: 2.5953\n",
      "\n",
      "Epoch 00824: val_loss did not improve from 2.54449\n",
      "Epoch 825/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7830 - val_loss: 2.5939\n",
      "\n",
      "Epoch 00825: val_loss did not improve from 2.54449\n",
      "Epoch 826/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7941 - val_loss: 2.5968\n",
      "\n",
      "Epoch 00826: val_loss did not improve from 2.54449\n",
      "Epoch 827/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7934 - val_loss: 2.5862\n",
      "\n",
      "Epoch 00827: val_loss did not improve from 2.54449\n",
      "Epoch 828/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7830 - val_loss: 2.5916\n",
      "\n",
      "Epoch 00828: val_loss did not improve from 2.54449\n",
      "Epoch 829/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7869 - val_loss: 2.5726\n",
      "\n",
      "Epoch 00829: val_loss did not improve from 2.54449\n",
      "Epoch 830/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7904 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00830: val_loss did not improve from 2.54449\n",
      "Epoch 831/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7913 - val_loss: 2.5842\n",
      "\n",
      "Epoch 00831: val_loss did not improve from 2.54449\n",
      "Epoch 832/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7917 - val_loss: 2.5761\n",
      "\n",
      "Epoch 00832: val_loss did not improve from 2.54449\n",
      "Epoch 833/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7892 - val_loss: 2.5768\n",
      "\n",
      "Epoch 00833: val_loss did not improve from 2.54449\n",
      "Epoch 834/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7854 - val_loss: 2.5841\n",
      "\n",
      "Epoch 00834: val_loss did not improve from 2.54449\n",
      "Epoch 835/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7963 - val_loss: 2.5909\n",
      "\n",
      "Epoch 00835: val_loss did not improve from 2.54449\n",
      "Epoch 836/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7839 - val_loss: 2.6010\n",
      "\n",
      "Epoch 00836: val_loss did not improve from 2.54449\n",
      "Epoch 837/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7992 - val_loss: 2.5965\n",
      "\n",
      "Epoch 00837: val_loss did not improve from 2.54449\n",
      "Epoch 838/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7853 - val_loss: 2.5818\n",
      "\n",
      "Epoch 00838: val_loss did not improve from 2.54449\n",
      "Epoch 839/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7947 - val_loss: 2.5946\n",
      "\n",
      "Epoch 00839: val_loss did not improve from 2.54449\n",
      "Epoch 840/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7844 - val_loss: 2.5916\n",
      "\n",
      "Epoch 00840: val_loss did not improve from 2.54449\n",
      "Epoch 841/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7908 - val_loss: 2.5896\n",
      "\n",
      "Epoch 00841: val_loss did not improve from 2.54449\n",
      "Epoch 842/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7957 - val_loss: 2.5975\n",
      "\n",
      "Epoch 00842: val_loss did not improve from 2.54449\n",
      "Epoch 843/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7895 - val_loss: 2.5707\n",
      "\n",
      "Epoch 00843: val_loss did not improve from 2.54449\n",
      "Epoch 844/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7841 - val_loss: 2.5945\n",
      "\n",
      "Epoch 00844: val_loss did not improve from 2.54449\n",
      "Epoch 845/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7875 - val_loss: 2.5777\n",
      "\n",
      "Epoch 00845: val_loss did not improve from 2.54449\n",
      "Epoch 846/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7887 - val_loss: 2.5959\n",
      "\n",
      "Epoch 00846: val_loss did not improve from 2.54449\n",
      "Epoch 847/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7882 - val_loss: 2.5766\n",
      "\n",
      "Epoch 00847: val_loss did not improve from 2.54449\n",
      "Epoch 848/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7785 - val_loss: 2.5934\n",
      "\n",
      "Epoch 00848: val_loss did not improve from 2.54449\n",
      "Epoch 849/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7927 - val_loss: 2.5997\n",
      "\n",
      "Epoch 00849: val_loss did not improve from 2.54449\n",
      "Epoch 850/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7910 - val_loss: 2.5888\n",
      "\n",
      "Epoch 00850: val_loss did not improve from 2.54449\n",
      "Epoch 851/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7927 - val_loss: 2.5792\n",
      "\n",
      "Epoch 00851: val_loss did not improve from 2.54449\n",
      "Epoch 852/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7920 - val_loss: 2.5810\n",
      "\n",
      "Epoch 00852: val_loss did not improve from 2.54449\n",
      "Epoch 853/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7850 - val_loss: 2.5856\n",
      "\n",
      "Epoch 00853: val_loss did not improve from 2.54449\n",
      "Epoch 854/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7933 - val_loss: 2.5924\n",
      "\n",
      "Epoch 00854: val_loss did not improve from 2.54449\n",
      "Epoch 855/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7961 - val_loss: 2.5740\n",
      "\n",
      "Epoch 00855: val_loss did not improve from 2.54449\n",
      "Epoch 856/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7913 - val_loss: 2.5836\n",
      "\n",
      "Epoch 00856: val_loss did not improve from 2.54449\n",
      "Epoch 857/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7918 - val_loss: 2.5915\n",
      "\n",
      "Epoch 00857: val_loss did not improve from 2.54449\n",
      "Epoch 858/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7866 - val_loss: 2.6008\n",
      "\n",
      "Epoch 00858: val_loss did not improve from 2.54449\n",
      "Epoch 859/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7895 - val_loss: 2.5844\n",
      "\n",
      "Epoch 00859: val_loss did not improve from 2.54449\n",
      "Epoch 860/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7944 - val_loss: 2.5900\n",
      "\n",
      "Epoch 00860: val_loss did not improve from 2.54449\n",
      "Epoch 861/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7938 - val_loss: 2.5900\n",
      "\n",
      "Epoch 00861: val_loss did not improve from 2.54449\n",
      "Epoch 862/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7929 - val_loss: 2.5889\n",
      "\n",
      "Epoch 00862: val_loss did not improve from 2.54449\n",
      "Epoch 863/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7957 - val_loss: 2.5812\n",
      "\n",
      "Epoch 00863: val_loss did not improve from 2.54449\n",
      "Epoch 864/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7782 - val_loss: 2.5874\n",
      "\n",
      "Epoch 00864: val_loss did not improve from 2.54449\n",
      "Epoch 865/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7845 - val_loss: 2.5852\n",
      "\n",
      "Epoch 00865: val_loss did not improve from 2.54449\n",
      "Epoch 866/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7840 - val_loss: 2.5865\n",
      "\n",
      "Epoch 00866: val_loss did not improve from 2.54449\n",
      "Epoch 867/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7950 - val_loss: 2.5850\n",
      "\n",
      "Epoch 00867: val_loss did not improve from 2.54449\n",
      "Epoch 868/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7846 - val_loss: 2.5852\n",
      "\n",
      "Epoch 00868: val_loss did not improve from 2.54449\n",
      "Epoch 869/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7825 - val_loss: 2.5869\n",
      "\n",
      "Epoch 00869: val_loss did not improve from 2.54449\n",
      "Epoch 870/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7890 - val_loss: 2.5940\n",
      "\n",
      "Epoch 00870: val_loss did not improve from 2.54449\n",
      "Epoch 871/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.8056 - val_loss: 2.5833\n",
      "\n",
      "Epoch 00871: val_loss did not improve from 2.54449\n",
      "Epoch 872/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7937 - val_loss: 2.5806\n",
      "\n",
      "Epoch 00872: val_loss did not improve from 2.54449\n",
      "Epoch 873/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7876 - val_loss: 2.5756\n",
      "\n",
      "Epoch 00873: val_loss did not improve from 2.54449\n",
      "Epoch 874/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7874 - val_loss: 2.5861\n",
      "\n",
      "Epoch 00874: val_loss did not improve from 2.54449\n",
      "Epoch 875/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7807 - val_loss: 2.5876\n",
      "\n",
      "Epoch 00875: val_loss did not improve from 2.54449\n",
      "Epoch 876/3000\n",
      "51530/51530 [==============================] - 20s 393us/step - loss: 1.7805 - val_loss: 2.5961\n",
      "\n",
      "Epoch 00876: val_loss did not improve from 2.54449\n",
      "Epoch 877/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7964 - val_loss: 2.5927\n",
      "\n",
      "Epoch 00877: val_loss did not improve from 2.54449\n",
      "Epoch 878/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7887 - val_loss: 2.5881\n",
      "\n",
      "Epoch 00878: val_loss did not improve from 2.54449\n",
      "Epoch 879/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7945 - val_loss: 2.5860\n",
      "\n",
      "Epoch 00879: val_loss did not improve from 2.54449\n",
      "Epoch 880/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7907 - val_loss: 2.5893\n",
      "\n",
      "Epoch 00880: val_loss did not improve from 2.54449\n",
      "Epoch 881/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7883 - val_loss: 2.5941\n",
      "\n",
      "Epoch 00881: val_loss did not improve from 2.54449\n",
      "Epoch 882/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7944 - val_loss: 2.5936\n",
      "\n",
      "Epoch 00882: val_loss did not improve from 2.54449\n",
      "Epoch 883/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7927 - val_loss: 2.5890\n",
      "\n",
      "Epoch 00883: val_loss did not improve from 2.54449\n",
      "Epoch 884/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7937 - val_loss: 2.5865\n",
      "\n",
      "Epoch 00884: val_loss did not improve from 2.54449\n",
      "Epoch 885/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7865 - val_loss: 2.5758\n",
      "\n",
      "Epoch 00885: val_loss did not improve from 2.54449\n",
      "Epoch 886/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7934 - val_loss: 2.5977\n",
      "\n",
      "Epoch 00886: val_loss did not improve from 2.54449\n",
      "Epoch 887/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7785 - val_loss: 2.5798\n",
      "\n",
      "Epoch 00887: val_loss did not improve from 2.54449\n",
      "Epoch 888/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7813 - val_loss: 2.5817\n",
      "\n",
      "Epoch 00888: val_loss did not improve from 2.54449\n",
      "Epoch 889/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7831 - val_loss: 2.5820\n",
      "\n",
      "Epoch 00889: val_loss did not improve from 2.54449\n",
      "Epoch 890/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7756 - val_loss: 2.5787\n",
      "\n",
      "Epoch 00890: val_loss did not improve from 2.54449\n",
      "Epoch 891/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7827 - val_loss: 2.5913\n",
      "\n",
      "Epoch 00891: val_loss did not improve from 2.54449\n",
      "Epoch 892/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7856 - val_loss: 2.5761\n",
      "\n",
      "Epoch 00892: val_loss did not improve from 2.54449\n",
      "Epoch 893/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7888 - val_loss: 2.5823\n",
      "\n",
      "Epoch 00893: val_loss did not improve from 2.54449\n",
      "Epoch 894/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7940 - val_loss: 2.5992\n",
      "\n",
      "Epoch 00894: val_loss did not improve from 2.54449\n",
      "Epoch 895/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8008 - val_loss: 2.5831\n",
      "\n",
      "Epoch 00895: val_loss did not improve from 2.54449\n",
      "Epoch 896/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7909 - val_loss: 2.5977\n",
      "\n",
      "Epoch 00896: val_loss did not improve from 2.54449\n",
      "Epoch 897/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7905 - val_loss: 2.5876\n",
      "\n",
      "Epoch 00897: val_loss did not improve from 2.54449\n",
      "Epoch 898/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7884 - val_loss: 2.5795\n",
      "\n",
      "Epoch 00898: val_loss did not improve from 2.54449\n",
      "Epoch 899/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7917 - val_loss: 2.5788\n",
      "\n",
      "Epoch 00899: val_loss did not improve from 2.54449\n",
      "Epoch 900/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7852 - val_loss: 2.5771\n",
      "\n",
      "Epoch 00900: val_loss did not improve from 2.54449\n",
      "Epoch 901/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7963 - val_loss: 2.5896\n",
      "\n",
      "Epoch 00901: val_loss did not improve from 2.54449\n",
      "Epoch 902/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7922 - val_loss: 2.5902\n",
      "\n",
      "Epoch 00902: val_loss did not improve from 2.54449\n",
      "Epoch 903/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7919 - val_loss: 2.5813\n",
      "\n",
      "Epoch 00903: val_loss did not improve from 2.54449\n",
      "Epoch 904/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7735 - val_loss: 2.5748\n",
      "\n",
      "Epoch 00904: val_loss did not improve from 2.54449\n",
      "Epoch 905/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7834 - val_loss: 2.5801\n",
      "\n",
      "Epoch 00905: val_loss did not improve from 2.54449\n",
      "Epoch 906/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7921 - val_loss: 2.5820\n",
      "\n",
      "Epoch 00906: val_loss did not improve from 2.54449\n",
      "Epoch 907/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7938 - val_loss: 2.5842\n",
      "\n",
      "Epoch 00907: val_loss did not improve from 2.54449\n",
      "Epoch 908/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7866 - val_loss: 2.5865\n",
      "\n",
      "Epoch 00908: val_loss did not improve from 2.54449\n",
      "Epoch 909/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7802 - val_loss: 2.5925\n",
      "\n",
      "Epoch 00909: val_loss did not improve from 2.54449\n",
      "Epoch 910/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7904 - val_loss: 2.5911\n",
      "\n",
      "Epoch 00910: val_loss did not improve from 2.54449\n",
      "Epoch 911/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7841 - val_loss: 2.5969\n",
      "\n",
      "Epoch 00911: val_loss did not improve from 2.54449\n",
      "Epoch 912/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7964 - val_loss: 2.5806\n",
      "\n",
      "Epoch 00912: val_loss did not improve from 2.54449\n",
      "Epoch 913/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7915 - val_loss: 2.5837\n",
      "\n",
      "Epoch 00913: val_loss did not improve from 2.54449\n",
      "Epoch 914/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7890 - val_loss: 2.5932\n",
      "\n",
      "Epoch 00914: val_loss did not improve from 2.54449\n",
      "Epoch 915/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7957 - val_loss: 2.6047\n",
      "\n",
      "Epoch 00915: val_loss did not improve from 2.54449\n",
      "Epoch 916/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7735 - val_loss: 2.5901\n",
      "\n",
      "Epoch 00916: val_loss did not improve from 2.54449\n",
      "Epoch 917/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7972 - val_loss: 2.5813\n",
      "\n",
      "Epoch 00917: val_loss did not improve from 2.54449\n",
      "Epoch 918/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7835 - val_loss: 2.5737\n",
      "\n",
      "Epoch 00918: val_loss did not improve from 2.54449\n",
      "Epoch 919/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7872 - val_loss: 2.5860\n",
      "\n",
      "Epoch 00919: val_loss did not improve from 2.54449\n",
      "Epoch 920/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7857 - val_loss: 2.5818\n",
      "\n",
      "Epoch 00920: val_loss did not improve from 2.54449\n",
      "Epoch 921/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7849 - val_loss: 2.5844\n",
      "\n",
      "Epoch 00921: val_loss did not improve from 2.54449\n",
      "Epoch 922/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7925 - val_loss: 2.5679\n",
      "\n",
      "Epoch 00922: val_loss did not improve from 2.54449\n",
      "Epoch 923/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7882 - val_loss: 2.5685\n",
      "\n",
      "Epoch 00923: val_loss did not improve from 2.54449\n",
      "Epoch 924/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.7839 - val_loss: 2.5751\n",
      "\n",
      "Epoch 00924: val_loss did not improve from 2.54449\n",
      "Epoch 925/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7905 - val_loss: 2.5753\n",
      "\n",
      "Epoch 00925: val_loss did not improve from 2.54449\n",
      "Epoch 926/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7901 - val_loss: 2.5903\n",
      "\n",
      "Epoch 00926: val_loss did not improve from 2.54449\n",
      "Epoch 927/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7800 - val_loss: 2.5694\n",
      "\n",
      "Epoch 00927: val_loss did not improve from 2.54449\n",
      "Epoch 928/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7741 - val_loss: 2.5857\n",
      "\n",
      "Epoch 00928: val_loss did not improve from 2.54449\n",
      "Epoch 929/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.8008 - val_loss: 2.5959\n",
      "\n",
      "Epoch 00929: val_loss did not improve from 2.54449\n",
      "Epoch 930/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.7942 - val_loss: 2.5670\n",
      "\n",
      "Epoch 00930: val_loss did not improve from 2.54449\n",
      "Epoch 931/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7830 - val_loss: 2.5901\n",
      "\n",
      "Epoch 00931: val_loss did not improve from 2.54449\n",
      "Epoch 932/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7813 - val_loss: 2.5803\n",
      "\n",
      "Epoch 00932: val_loss did not improve from 2.54449\n",
      "Epoch 933/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7876 - val_loss: 2.5940\n",
      "\n",
      "Epoch 00933: val_loss did not improve from 2.54449\n",
      "Epoch 934/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7856 - val_loss: 2.5935\n",
      "\n",
      "Epoch 00934: val_loss did not improve from 2.54449\n",
      "Epoch 935/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7905 - val_loss: 2.5760\n",
      "\n",
      "Epoch 00935: val_loss did not improve from 2.54449\n",
      "Epoch 936/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7802 - val_loss: 2.5871\n",
      "\n",
      "Epoch 00936: val_loss did not improve from 2.54449\n",
      "Epoch 937/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7892 - val_loss: 2.5784\n",
      "\n",
      "Epoch 00937: val_loss did not improve from 2.54449\n",
      "Epoch 938/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7841 - val_loss: 2.5854\n",
      "\n",
      "Epoch 00938: val_loss did not improve from 2.54449\n",
      "Epoch 939/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7848 - val_loss: 2.5860\n",
      "\n",
      "Epoch 00939: val_loss did not improve from 2.54449\n",
      "Epoch 940/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7765 - val_loss: 2.5779\n",
      "\n",
      "Epoch 00940: val_loss did not improve from 2.54449\n",
      "Epoch 941/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7771 - val_loss: 2.5849\n",
      "\n",
      "Epoch 00941: val_loss did not improve from 2.54449\n",
      "Epoch 942/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7820 - val_loss: 2.5934\n",
      "\n",
      "Epoch 00942: val_loss did not improve from 2.54449\n",
      "Epoch 943/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7926 - val_loss: 2.5849\n",
      "\n",
      "Epoch 00943: val_loss did not improve from 2.54449\n",
      "Epoch 944/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7881 - val_loss: 2.5842\n",
      "\n",
      "Epoch 00944: val_loss did not improve from 2.54449\n",
      "Epoch 945/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7936 - val_loss: 2.5809\n",
      "\n",
      "Epoch 00945: val_loss did not improve from 2.54449\n",
      "Epoch 946/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7791 - val_loss: 2.5814\n",
      "\n",
      "Epoch 00946: val_loss did not improve from 2.54449\n",
      "Epoch 947/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7917 - val_loss: 2.5855\n",
      "\n",
      "Epoch 00947: val_loss did not improve from 2.54449\n",
      "Epoch 948/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7877 - val_loss: 2.5795\n",
      "\n",
      "Epoch 00948: val_loss did not improve from 2.54449\n",
      "Epoch 949/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7854 - val_loss: 2.5732\n",
      "\n",
      "Epoch 00949: val_loss did not improve from 2.54449\n",
      "Epoch 950/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7748 - val_loss: 2.5748\n",
      "\n",
      "Epoch 00950: val_loss did not improve from 2.54449\n",
      "Epoch 951/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7779 - val_loss: 2.5880\n",
      "\n",
      "Epoch 00951: val_loss did not improve from 2.54449\n",
      "Epoch 952/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7892 - val_loss: 2.5957\n",
      "\n",
      "Epoch 00952: val_loss did not improve from 2.54449\n",
      "Epoch 953/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7891 - val_loss: 2.5931\n",
      "\n",
      "Epoch 00953: val_loss did not improve from 2.54449\n",
      "Epoch 954/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7893 - val_loss: 2.5753\n",
      "\n",
      "Epoch 00954: val_loss did not improve from 2.54449\n",
      "Epoch 955/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7931 - val_loss: 2.5899\n",
      "\n",
      "Epoch 00955: val_loss did not improve from 2.54449\n",
      "Epoch 956/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7887 - val_loss: 2.5867\n",
      "\n",
      "Epoch 00956: val_loss did not improve from 2.54449\n",
      "Epoch 957/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7708 - val_loss: 2.5834\n",
      "\n",
      "Epoch 00957: val_loss did not improve from 2.54449\n",
      "Epoch 958/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7841 - val_loss: 2.5799\n",
      "\n",
      "Epoch 00958: val_loss did not improve from 2.54449\n",
      "Epoch 959/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7964 - val_loss: 2.5874\n",
      "\n",
      "Epoch 00959: val_loss did not improve from 2.54449\n",
      "Epoch 960/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7950 - val_loss: 2.5868\n",
      "\n",
      "Epoch 00960: val_loss did not improve from 2.54449\n",
      "Epoch 961/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7850 - val_loss: 2.5893\n",
      "\n",
      "Epoch 00961: val_loss did not improve from 2.54449\n",
      "Epoch 962/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7851 - val_loss: 2.5945\n",
      "\n",
      "Epoch 00962: val_loss did not improve from 2.54449\n",
      "Epoch 963/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7968 - val_loss: 2.6058\n",
      "\n",
      "Epoch 00963: val_loss did not improve from 2.54449\n",
      "Epoch 964/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7865 - val_loss: 2.5766\n",
      "\n",
      "Epoch 00964: val_loss did not improve from 2.54449\n",
      "Epoch 965/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7833 - val_loss: 2.5926\n",
      "\n",
      "Epoch 00965: val_loss did not improve from 2.54449\n",
      "Epoch 966/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7885 - val_loss: 2.5931\n",
      "\n",
      "Epoch 00966: val_loss did not improve from 2.54449\n",
      "Epoch 967/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7948 - val_loss: 2.5951\n",
      "\n",
      "Epoch 00967: val_loss did not improve from 2.54449\n",
      "Epoch 968/3000\n",
      "51530/51530 [==============================] - 17s 324us/step - loss: 1.7701 - val_loss: 2.5774\n",
      "\n",
      "Epoch 00968: val_loss did not improve from 2.54449\n",
      "Epoch 969/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7940 - val_loss: 2.5948\n",
      "\n",
      "Epoch 00969: val_loss did not improve from 2.54449\n",
      "Epoch 970/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7898 - val_loss: 2.5872\n",
      "\n",
      "Epoch 00970: val_loss did not improve from 2.54449\n",
      "Epoch 971/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7944 - val_loss: 2.5812\n",
      "\n",
      "Epoch 00971: val_loss did not improve from 2.54449\n",
      "Epoch 972/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7904 - val_loss: 2.5931\n",
      "\n",
      "Epoch 00972: val_loss did not improve from 2.54449\n",
      "Epoch 973/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7837 - val_loss: 2.5921\n",
      "\n",
      "Epoch 00973: val_loss did not improve from 2.54449\n",
      "Epoch 974/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7875 - val_loss: 2.6033\n",
      "\n",
      "Epoch 00974: val_loss did not improve from 2.54449\n",
      "Epoch 975/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7872 - val_loss: 2.5878\n",
      "\n",
      "Epoch 00975: val_loss did not improve from 2.54449\n",
      "Epoch 976/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7926 - val_loss: 2.6026\n",
      "\n",
      "Epoch 00976: val_loss did not improve from 2.54449\n",
      "Epoch 977/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7856 - val_loss: 2.5800\n",
      "\n",
      "Epoch 00977: val_loss did not improve from 2.54449\n",
      "Epoch 978/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8065 - val_loss: 2.5823\n",
      "\n",
      "Epoch 00978: val_loss did not improve from 2.54449\n",
      "Epoch 979/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7970 - val_loss: 2.5889\n",
      "\n",
      "Epoch 00979: val_loss did not improve from 2.54449\n",
      "Epoch 980/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7848 - val_loss: 2.5905\n",
      "\n",
      "Epoch 00980: val_loss did not improve from 2.54449\n",
      "Epoch 981/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7891 - val_loss: 2.5822\n",
      "\n",
      "Epoch 00981: val_loss did not improve from 2.54449\n",
      "Epoch 982/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7844 - val_loss: 2.5887\n",
      "\n",
      "Epoch 00982: val_loss did not improve from 2.54449\n",
      "Epoch 983/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7860 - val_loss: 2.6049\n",
      "\n",
      "Epoch 00983: val_loss did not improve from 2.54449\n",
      "Epoch 984/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7962 - val_loss: 2.5857\n",
      "\n",
      "Epoch 00984: val_loss did not improve from 2.54449\n",
      "Epoch 985/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7810 - val_loss: 2.5793\n",
      "\n",
      "Epoch 00985: val_loss did not improve from 2.54449\n",
      "Epoch 986/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7926 - val_loss: 2.5872\n",
      "\n",
      "Epoch 00986: val_loss did not improve from 2.54449\n",
      "Epoch 987/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7952 - val_loss: 2.5873\n",
      "\n",
      "Epoch 00987: val_loss did not improve from 2.54449\n",
      "Epoch 988/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7898 - val_loss: 2.5854\n",
      "\n",
      "Epoch 00988: val_loss did not improve from 2.54449\n",
      "Epoch 989/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7799 - val_loss: 2.5826\n",
      "\n",
      "Epoch 00989: val_loss did not improve from 2.54449\n",
      "Epoch 990/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7906 - val_loss: 2.5938\n",
      "\n",
      "Epoch 00990: val_loss did not improve from 2.54449\n",
      "Epoch 991/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.8000 - val_loss: 2.5948\n",
      "\n",
      "Epoch 00991: val_loss did not improve from 2.54449\n",
      "Epoch 992/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7756 - val_loss: 2.5961\n",
      "\n",
      "Epoch 00992: val_loss did not improve from 2.54449\n",
      "Epoch 993/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7856 - val_loss: 2.5925\n",
      "\n",
      "Epoch 00993: val_loss did not improve from 2.54449\n",
      "Epoch 994/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.8032 - val_loss: 2.5938\n",
      "\n",
      "Epoch 00994: val_loss did not improve from 2.54449\n",
      "Epoch 995/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7887 - val_loss: 2.5894\n",
      "\n",
      "Epoch 00995: val_loss did not improve from 2.54449\n",
      "Epoch 996/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7887 - val_loss: 2.5916\n",
      "\n",
      "Epoch 00996: val_loss did not improve from 2.54449\n",
      "Epoch 997/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7880 - val_loss: 2.5889\n",
      "\n",
      "Epoch 00997: val_loss did not improve from 2.54449\n",
      "Epoch 998/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7997 - val_loss: 2.5758\n",
      "\n",
      "Epoch 00998: val_loss did not improve from 2.54449\n",
      "Epoch 999/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7832 - val_loss: 2.5854\n",
      "\n",
      "Epoch 00999: val_loss did not improve from 2.54449\n",
      "Epoch 1000/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7868 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01000: val_loss did not improve from 2.54449\n",
      "Epoch 1001/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7921 - val_loss: 2.5871\n",
      "\n",
      "Epoch 01001: val_loss did not improve from 2.54449\n",
      "Epoch 1002/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7920 - val_loss: 2.5957\n",
      "\n",
      "Epoch 01002: val_loss did not improve from 2.54449\n",
      "Epoch 1003/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7878 - val_loss: 2.5772\n",
      "\n",
      "Epoch 01003: val_loss did not improve from 2.54449\n",
      "Epoch 1004/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7832 - val_loss: 2.5811\n",
      "\n",
      "Epoch 01004: val_loss did not improve from 2.54449\n",
      "Epoch 1005/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7951 - val_loss: 2.5750\n",
      "\n",
      "Epoch 01005: val_loss did not improve from 2.54449\n",
      "Epoch 1006/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7850 - val_loss: 2.5790\n",
      "\n",
      "Epoch 01006: val_loss did not improve from 2.54449\n",
      "Epoch 1007/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.7893 - val_loss: 2.5783\n",
      "\n",
      "Epoch 01007: val_loss did not improve from 2.54449\n",
      "Epoch 1008/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7909 - val_loss: 2.5813\n",
      "\n",
      "Epoch 01008: val_loss did not improve from 2.54449\n",
      "Epoch 1009/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.7834 - val_loss: 2.5817\n",
      "\n",
      "Epoch 01009: val_loss did not improve from 2.54449\n",
      "Epoch 1010/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7805 - val_loss: 2.6099\n",
      "\n",
      "Epoch 01010: val_loss did not improve from 2.54449\n",
      "Epoch 1011/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7890 - val_loss: 2.5895\n",
      "\n",
      "Epoch 01011: val_loss did not improve from 2.54449\n",
      "Epoch 1012/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7836 - val_loss: 2.5843\n",
      "\n",
      "Epoch 01012: val_loss did not improve from 2.54449\n",
      "Epoch 1013/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7784 - val_loss: 2.5856\n",
      "\n",
      "Epoch 01013: val_loss did not improve from 2.54449\n",
      "Epoch 1014/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7936 - val_loss: 2.6035\n",
      "\n",
      "Epoch 01014: val_loss did not improve from 2.54449\n",
      "Epoch 1015/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7864 - val_loss: 2.5914\n",
      "\n",
      "Epoch 01015: val_loss did not improve from 2.54449\n",
      "Epoch 1016/3000\n",
      "51530/51530 [==============================] - 17s 323us/step - loss: 1.7923 - val_loss: 2.5967\n",
      "\n",
      "Epoch 01016: val_loss did not improve from 2.54449\n",
      "Epoch 1017/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.8010 - val_loss: 2.6059\n",
      "\n",
      "Epoch 01017: val_loss did not improve from 2.54449\n",
      "Epoch 1018/3000\n",
      "51530/51530 [==============================] - 17s 320us/step - loss: 1.7972 - val_loss: 2.5887\n",
      "\n",
      "Epoch 01018: val_loss did not improve from 2.54449\n",
      "Epoch 1019/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7920 - val_loss: 2.5785\n",
      "\n",
      "Epoch 01019: val_loss did not improve from 2.54449\n",
      "Epoch 1020/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7802 - val_loss: 2.5882\n",
      "\n",
      "Epoch 01020: val_loss did not improve from 2.54449\n",
      "Epoch 1021/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7926 - val_loss: 2.5885\n",
      "\n",
      "Epoch 01021: val_loss did not improve from 2.54449\n",
      "Epoch 1022/3000\n",
      "51530/51530 [==============================] - 18s 345us/step - loss: 1.7820 - val_loss: 2.5841\n",
      "\n",
      "Epoch 01022: val_loss did not improve from 2.54449\n",
      "Epoch 1023/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7923 - val_loss: 2.6004\n",
      "\n",
      "Epoch 01023: val_loss did not improve from 2.54449\n",
      "Epoch 1024/3000\n",
      "51530/51530 [==============================] - 20s 383us/step - loss: 1.7745 - val_loss: 2.5980\n",
      "\n",
      "Epoch 01024: val_loss did not improve from 2.54449\n",
      "Epoch 1025/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.7861 - val_loss: 2.5978\n",
      "\n",
      "Epoch 01025: val_loss did not improve from 2.54449\n",
      "Epoch 1026/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7809 - val_loss: 2.5899\n",
      "\n",
      "Epoch 01026: val_loss did not improve from 2.54449\n",
      "Epoch 1027/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7835 - val_loss: 2.6062\n",
      "\n",
      "Epoch 01027: val_loss did not improve from 2.54449\n",
      "Epoch 1028/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.8003 - val_loss: 2.5792\n",
      "\n",
      "Epoch 01028: val_loss did not improve from 2.54449\n",
      "Epoch 1029/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7875 - val_loss: 2.5998\n",
      "\n",
      "Epoch 01029: val_loss did not improve from 2.54449\n",
      "Epoch 1030/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7847 - val_loss: 2.6013\n",
      "\n",
      "Epoch 01030: val_loss did not improve from 2.54449\n",
      "Epoch 1031/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7911 - val_loss: 2.5892\n",
      "\n",
      "Epoch 01031: val_loss did not improve from 2.54449\n",
      "Epoch 1032/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7825 - val_loss: 2.5926\n",
      "\n",
      "Epoch 01032: val_loss did not improve from 2.54449\n",
      "Epoch 1033/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7938 - val_loss: 2.5987\n",
      "\n",
      "Epoch 01033: val_loss did not improve from 2.54449\n",
      "Epoch 1034/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7894 - val_loss: 2.5882\n",
      "\n",
      "Epoch 01034: val_loss did not improve from 2.54449\n",
      "Epoch 1035/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7865 - val_loss: 2.5809\n",
      "\n",
      "Epoch 01035: val_loss did not improve from 2.54449\n",
      "Epoch 1036/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7942 - val_loss: 2.5927\n",
      "\n",
      "Epoch 01036: val_loss did not improve from 2.54449\n",
      "Epoch 1037/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7810 - val_loss: 2.5814\n",
      "\n",
      "Epoch 01037: val_loss did not improve from 2.54449\n",
      "Epoch 1038/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7846 - val_loss: 2.5947\n",
      "\n",
      "Epoch 01038: val_loss did not improve from 2.54449\n",
      "Epoch 1039/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7955 - val_loss: 2.5939\n",
      "\n",
      "Epoch 01039: val_loss did not improve from 2.54449\n",
      "Epoch 1040/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7844 - val_loss: 2.5955\n",
      "\n",
      "Epoch 01040: val_loss did not improve from 2.54449\n",
      "Epoch 1041/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7899 - val_loss: 2.5789\n",
      "\n",
      "Epoch 01041: val_loss did not improve from 2.54449\n",
      "Epoch 1042/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.7859 - val_loss: 2.5828\n",
      "\n",
      "Epoch 01042: val_loss did not improve from 2.54449\n",
      "Epoch 1043/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7922 - val_loss: 2.6019\n",
      "\n",
      "Epoch 01043: val_loss did not improve from 2.54449\n",
      "Epoch 1044/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7885 - val_loss: 2.5813\n",
      "\n",
      "Epoch 01044: val_loss did not improve from 2.54449\n",
      "Epoch 1045/3000\n",
      "51530/51530 [==============================] - 19s 370us/step - loss: 1.7838 - val_loss: 2.5867\n",
      "\n",
      "Epoch 01045: val_loss did not improve from 2.54449\n",
      "Epoch 1046/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7873 - val_loss: 2.5810\n",
      "\n",
      "Epoch 01046: val_loss did not improve from 2.54449\n",
      "Epoch 1047/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.7911 - val_loss: 2.5873\n",
      "\n",
      "Epoch 01047: val_loss did not improve from 2.54449\n",
      "Epoch 1048/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7821 - val_loss: 2.5894\n",
      "\n",
      "Epoch 01048: val_loss did not improve from 2.54449\n",
      "Epoch 1049/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7872 - val_loss: 2.5732\n",
      "\n",
      "Epoch 01049: val_loss did not improve from 2.54449\n",
      "Epoch 1050/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7897 - val_loss: 2.5848\n",
      "\n",
      "Epoch 01050: val_loss did not improve from 2.54449\n",
      "Epoch 1051/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7867 - val_loss: 2.6027\n",
      "\n",
      "Epoch 01051: val_loss did not improve from 2.54449\n",
      "Epoch 1052/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7843 - val_loss: 2.5910\n",
      "\n",
      "Epoch 01052: val_loss did not improve from 2.54449\n",
      "Epoch 1053/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7744 - val_loss: 2.5925\n",
      "\n",
      "Epoch 01053: val_loss did not improve from 2.54449\n",
      "Epoch 1054/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7867 - val_loss: 2.5783\n",
      "\n",
      "Epoch 01054: val_loss did not improve from 2.54449\n",
      "Epoch 1055/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7864 - val_loss: 2.5976\n",
      "\n",
      "Epoch 01055: val_loss did not improve from 2.54449\n",
      "Epoch 1056/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7813 - val_loss: 2.5905\n",
      "\n",
      "Epoch 01056: val_loss did not improve from 2.54449\n",
      "Epoch 1057/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7856 - val_loss: 2.5851\n",
      "\n",
      "Epoch 01057: val_loss did not improve from 2.54449\n",
      "Epoch 1058/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7836 - val_loss: 2.5873\n",
      "\n",
      "Epoch 01058: val_loss did not improve from 2.54449\n",
      "Epoch 1059/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7823 - val_loss: 2.5787\n",
      "\n",
      "Epoch 01059: val_loss did not improve from 2.54449\n",
      "Epoch 1060/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7912 - val_loss: 2.5891\n",
      "\n",
      "Epoch 01060: val_loss did not improve from 2.54449\n",
      "Epoch 1061/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7828 - val_loss: 2.5813\n",
      "\n",
      "Epoch 01061: val_loss did not improve from 2.54449\n",
      "Epoch 1062/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7861 - val_loss: 2.5984\n",
      "\n",
      "Epoch 01062: val_loss did not improve from 2.54449\n",
      "Epoch 1063/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7775 - val_loss: 2.5903\n",
      "\n",
      "Epoch 01063: val_loss did not improve from 2.54449\n",
      "Epoch 1064/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7764 - val_loss: 2.5912\n",
      "\n",
      "Epoch 01064: val_loss did not improve from 2.54449\n",
      "Epoch 1065/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7875 - val_loss: 2.5862\n",
      "\n",
      "Epoch 01065: val_loss did not improve from 2.54449\n",
      "Epoch 1066/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7884 - val_loss: 2.5907\n",
      "\n",
      "Epoch 01066: val_loss did not improve from 2.54449\n",
      "Epoch 1067/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7934 - val_loss: 2.5819\n",
      "\n",
      "Epoch 01067: val_loss did not improve from 2.54449\n",
      "Epoch 1068/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7861 - val_loss: 2.5879\n",
      "\n",
      "Epoch 01068: val_loss did not improve from 2.54449\n",
      "Epoch 1069/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7786 - val_loss: 2.5840\n",
      "\n",
      "Epoch 01069: val_loss did not improve from 2.54449\n",
      "Epoch 1070/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7806 - val_loss: 2.5919\n",
      "\n",
      "Epoch 01070: val_loss did not improve from 2.54449\n",
      "Epoch 1071/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7970 - val_loss: 2.5984\n",
      "\n",
      "Epoch 01071: val_loss did not improve from 2.54449\n",
      "Epoch 1072/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7825 - val_loss: 2.5876\n",
      "\n",
      "Epoch 01072: val_loss did not improve from 2.54449\n",
      "Epoch 1073/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7895 - val_loss: 2.5898\n",
      "\n",
      "Epoch 01073: val_loss did not improve from 2.54449\n",
      "Epoch 1074/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7847 - val_loss: 2.5915\n",
      "\n",
      "Epoch 01074: val_loss did not improve from 2.54449\n",
      "Epoch 1075/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7826 - val_loss: 2.5927\n",
      "\n",
      "Epoch 01075: val_loss did not improve from 2.54449\n",
      "Epoch 1076/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7813 - val_loss: 2.5925\n",
      "\n",
      "Epoch 01076: val_loss did not improve from 2.54449\n",
      "Epoch 1077/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7920 - val_loss: 2.5834\n",
      "\n",
      "Epoch 01077: val_loss did not improve from 2.54449\n",
      "Epoch 1078/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7873 - val_loss: 2.5819\n",
      "\n",
      "Epoch 01078: val_loss did not improve from 2.54449\n",
      "Epoch 1079/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7848 - val_loss: 2.5963\n",
      "\n",
      "Epoch 01079: val_loss did not improve from 2.54449\n",
      "Epoch 1080/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7771 - val_loss: 2.5927\n",
      "\n",
      "Epoch 01080: val_loss did not improve from 2.54449\n",
      "Epoch 1081/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7854 - val_loss: 2.5962\n",
      "\n",
      "Epoch 01081: val_loss did not improve from 2.54449\n",
      "Epoch 1082/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7934 - val_loss: 2.5863\n",
      "\n",
      "Epoch 01082: val_loss did not improve from 2.54449\n",
      "Epoch 1083/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7872 - val_loss: 2.5867\n",
      "\n",
      "Epoch 01083: val_loss did not improve from 2.54449\n",
      "Epoch 1084/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7839 - val_loss: 2.5887\n",
      "\n",
      "Epoch 01084: val_loss did not improve from 2.54449\n",
      "Epoch 1085/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7884 - val_loss: 2.5935\n",
      "\n",
      "Epoch 01085: val_loss did not improve from 2.54449\n",
      "Epoch 1086/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7940 - val_loss: 2.5939\n",
      "\n",
      "Epoch 01086: val_loss did not improve from 2.54449\n",
      "Epoch 1087/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7834 - val_loss: 2.5833\n",
      "\n",
      "Epoch 01087: val_loss did not improve from 2.54449\n",
      "Epoch 1088/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7886 - val_loss: 2.5958\n",
      "\n",
      "Epoch 01088: val_loss did not improve from 2.54449\n",
      "Epoch 1089/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7863 - val_loss: 2.5876\n",
      "\n",
      "Epoch 01089: val_loss did not improve from 2.54449\n",
      "Epoch 1090/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7875 - val_loss: 2.5814\n",
      "\n",
      "Epoch 01090: val_loss did not improve from 2.54449\n",
      "Epoch 1091/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7987 - val_loss: 2.5954\n",
      "\n",
      "Epoch 01091: val_loss did not improve from 2.54449\n",
      "Epoch 1092/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7859 - val_loss: 2.5821\n",
      "\n",
      "Epoch 01092: val_loss did not improve from 2.54449\n",
      "Epoch 1093/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.8002 - val_loss: 2.5948\n",
      "\n",
      "Epoch 01093: val_loss did not improve from 2.54449\n",
      "Epoch 1094/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7877 - val_loss: 2.5968\n",
      "\n",
      "Epoch 01094: val_loss did not improve from 2.54449\n",
      "Epoch 1095/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7838 - val_loss: 2.5889\n",
      "\n",
      "Epoch 01095: val_loss did not improve from 2.54449\n",
      "Epoch 1096/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7752 - val_loss: 2.5877\n",
      "\n",
      "Epoch 01096: val_loss did not improve from 2.54449\n",
      "Epoch 1097/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7839 - val_loss: 2.5935\n",
      "\n",
      "Epoch 01097: val_loss did not improve from 2.54449\n",
      "Epoch 1098/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7889 - val_loss: 2.5821\n",
      "\n",
      "Epoch 01098: val_loss did not improve from 2.54449\n",
      "Epoch 1099/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7812 - val_loss: 2.5968\n",
      "\n",
      "Epoch 01099: val_loss did not improve from 2.54449\n",
      "Epoch 1100/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7859 - val_loss: 2.5783\n",
      "\n",
      "Epoch 01100: val_loss did not improve from 2.54449\n",
      "Epoch 1101/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7826 - val_loss: 2.5929\n",
      "\n",
      "Epoch 01101: val_loss did not improve from 2.54449\n",
      "Epoch 1102/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7930 - val_loss: 2.5964\n",
      "\n",
      "Epoch 01102: val_loss did not improve from 2.54449\n",
      "Epoch 1103/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7853 - val_loss: 2.5891\n",
      "\n",
      "Epoch 01103: val_loss did not improve from 2.54449\n",
      "Epoch 1104/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7864 - val_loss: 2.5816\n",
      "\n",
      "Epoch 01104: val_loss did not improve from 2.54449\n",
      "Epoch 1105/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7876 - val_loss: 2.5945\n",
      "\n",
      "Epoch 01105: val_loss did not improve from 2.54449\n",
      "Epoch 1106/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7828 - val_loss: 2.5962\n",
      "\n",
      "Epoch 01106: val_loss did not improve from 2.54449\n",
      "Epoch 1107/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7987 - val_loss: 2.5919\n",
      "\n",
      "Epoch 01107: val_loss did not improve from 2.54449\n",
      "Epoch 1108/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7875 - val_loss: 2.5859\n",
      "\n",
      "Epoch 01108: val_loss did not improve from 2.54449\n",
      "Epoch 1109/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7771 - val_loss: 2.5830\n",
      "\n",
      "Epoch 01109: val_loss did not improve from 2.54449\n",
      "Epoch 1110/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7810 - val_loss: 2.5884\n",
      "\n",
      "Epoch 01110: val_loss did not improve from 2.54449\n",
      "Epoch 1111/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7866 - val_loss: 2.5872\n",
      "\n",
      "Epoch 01111: val_loss did not improve from 2.54449\n",
      "Epoch 1112/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7787 - val_loss: 2.5815\n",
      "\n",
      "Epoch 01112: val_loss did not improve from 2.54449\n",
      "Epoch 1113/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7886 - val_loss: 2.5902\n",
      "\n",
      "Epoch 01113: val_loss did not improve from 2.54449\n",
      "Epoch 1114/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7903 - val_loss: 2.5896\n",
      "\n",
      "Epoch 01114: val_loss did not improve from 2.54449\n",
      "Epoch 1115/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7832 - val_loss: 2.5919\n",
      "\n",
      "Epoch 01115: val_loss did not improve from 2.54449\n",
      "Epoch 1116/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7819 - val_loss: 2.5992\n",
      "\n",
      "Epoch 01116: val_loss did not improve from 2.54449\n",
      "Epoch 1117/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7843 - val_loss: 2.6015\n",
      "\n",
      "Epoch 01117: val_loss did not improve from 2.54449\n",
      "Epoch 1118/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7815 - val_loss: 2.5866\n",
      "\n",
      "Epoch 01118: val_loss did not improve from 2.54449\n",
      "Epoch 1119/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7950 - val_loss: 2.5964\n",
      "\n",
      "Epoch 01119: val_loss did not improve from 2.54449\n",
      "Epoch 1120/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7916 - val_loss: 2.5954\n",
      "\n",
      "Epoch 01120: val_loss did not improve from 2.54449\n",
      "Epoch 1121/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7924 - val_loss: 2.5937\n",
      "\n",
      "Epoch 01121: val_loss did not improve from 2.54449\n",
      "Epoch 1122/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7906 - val_loss: 2.5931\n",
      "\n",
      "Epoch 01122: val_loss did not improve from 2.54449\n",
      "Epoch 1123/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7825 - val_loss: 2.5785\n",
      "\n",
      "Epoch 01123: val_loss did not improve from 2.54449\n",
      "Epoch 1124/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7857 - val_loss: 2.6035\n",
      "\n",
      "Epoch 01124: val_loss did not improve from 2.54449\n",
      "Epoch 1125/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.8064 - val_loss: 2.5834\n",
      "\n",
      "Epoch 01125: val_loss did not improve from 2.54449\n",
      "Epoch 1126/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7961 - val_loss: 2.5896\n",
      "\n",
      "Epoch 01126: val_loss did not improve from 2.54449\n",
      "Epoch 1127/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7874 - val_loss: 2.5867\n",
      "\n",
      "Epoch 01127: val_loss did not improve from 2.54449\n",
      "Epoch 1128/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7819 - val_loss: 2.5879\n",
      "\n",
      "Epoch 01128: val_loss did not improve from 2.54449\n",
      "Epoch 1129/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7829 - val_loss: 2.5913\n",
      "\n",
      "Epoch 01129: val_loss did not improve from 2.54449\n",
      "Epoch 1130/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7811 - val_loss: 2.5976\n",
      "\n",
      "Epoch 01130: val_loss did not improve from 2.54449\n",
      "Epoch 1131/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7840 - val_loss: 2.5969\n",
      "\n",
      "Epoch 01131: val_loss did not improve from 2.54449\n",
      "Epoch 1132/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7816 - val_loss: 2.5951\n",
      "\n",
      "Epoch 01132: val_loss did not improve from 2.54449\n",
      "Epoch 1133/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7851 - val_loss: 2.6039\n",
      "\n",
      "Epoch 01133: val_loss did not improve from 2.54449\n",
      "Epoch 1134/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7933 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01134: val_loss did not improve from 2.54449\n",
      "Epoch 1135/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7810 - val_loss: 2.5979\n",
      "\n",
      "Epoch 01135: val_loss did not improve from 2.54449\n",
      "Epoch 1136/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7824 - val_loss: 2.5943\n",
      "\n",
      "Epoch 01136: val_loss did not improve from 2.54449\n",
      "Epoch 1137/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7934 - val_loss: 2.6046\n",
      "\n",
      "Epoch 01137: val_loss did not improve from 2.54449\n",
      "Epoch 1138/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7828 - val_loss: 2.6082\n",
      "\n",
      "Epoch 01138: val_loss did not improve from 2.54449\n",
      "Epoch 1139/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7920 - val_loss: 2.6093\n",
      "\n",
      "Epoch 01139: val_loss did not improve from 2.54449\n",
      "Epoch 1140/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7851 - val_loss: 2.5900\n",
      "\n",
      "Epoch 01140: val_loss did not improve from 2.54449\n",
      "Epoch 1141/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7859 - val_loss: 2.5827\n",
      "\n",
      "Epoch 01141: val_loss did not improve from 2.54449\n",
      "Epoch 1142/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7868 - val_loss: 2.6050\n",
      "\n",
      "Epoch 01142: val_loss did not improve from 2.54449\n",
      "Epoch 1143/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7702 - val_loss: 2.5999\n",
      "\n",
      "Epoch 01143: val_loss did not improve from 2.54449\n",
      "Epoch 1144/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7835 - val_loss: 2.5978\n",
      "\n",
      "Epoch 01144: val_loss did not improve from 2.54449\n",
      "Epoch 1145/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7783 - val_loss: 2.5921\n",
      "\n",
      "Epoch 01145: val_loss did not improve from 2.54449\n",
      "Epoch 1146/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7905 - val_loss: 2.5856\n",
      "\n",
      "Epoch 01146: val_loss did not improve from 2.54449\n",
      "Epoch 1147/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7768 - val_loss: 2.5873\n",
      "\n",
      "Epoch 01147: val_loss did not improve from 2.54449\n",
      "Epoch 1148/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7783 - val_loss: 2.5858\n",
      "\n",
      "Epoch 01148: val_loss did not improve from 2.54449\n",
      "Epoch 1149/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7768 - val_loss: 2.5971\n",
      "\n",
      "Epoch 01149: val_loss did not improve from 2.54449\n",
      "Epoch 1150/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7923 - val_loss: 2.5965\n",
      "\n",
      "Epoch 01150: val_loss did not improve from 2.54449\n",
      "Epoch 1151/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7847 - val_loss: 2.5960\n",
      "\n",
      "Epoch 01151: val_loss did not improve from 2.54449\n",
      "Epoch 1152/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7782 - val_loss: 2.5899\n",
      "\n",
      "Epoch 01152: val_loss did not improve from 2.54449\n",
      "Epoch 1153/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7781 - val_loss: 2.5587\n",
      "\n",
      "Epoch 01153: val_loss did not improve from 2.54449\n",
      "Epoch 1154/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7804 - val_loss: 2.5707\n",
      "\n",
      "Epoch 01154: val_loss did not improve from 2.54449\n",
      "Epoch 1155/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7886 - val_loss: 2.5946\n",
      "\n",
      "Epoch 01155: val_loss did not improve from 2.54449\n",
      "Epoch 1156/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7850 - val_loss: 2.6026\n",
      "\n",
      "Epoch 01156: val_loss did not improve from 2.54449\n",
      "Epoch 1157/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7947 - val_loss: 2.5796\n",
      "\n",
      "Epoch 01157: val_loss did not improve from 2.54449\n",
      "Epoch 1158/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7862 - val_loss: 2.5896\n",
      "\n",
      "Epoch 01158: val_loss did not improve from 2.54449\n",
      "Epoch 1159/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7799 - val_loss: 2.5981\n",
      "\n",
      "Epoch 01159: val_loss did not improve from 2.54449\n",
      "Epoch 1160/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7870 - val_loss: 2.5832\n",
      "\n",
      "Epoch 01160: val_loss did not improve from 2.54449\n",
      "Epoch 1161/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7888 - val_loss: 2.5848\n",
      "\n",
      "Epoch 01161: val_loss did not improve from 2.54449\n",
      "Epoch 1162/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7873 - val_loss: 2.5801\n",
      "\n",
      "Epoch 01162: val_loss did not improve from 2.54449\n",
      "Epoch 1163/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7815 - val_loss: 2.5981\n",
      "\n",
      "Epoch 01163: val_loss did not improve from 2.54449\n",
      "Epoch 1164/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7877 - val_loss: 2.5788\n",
      "\n",
      "Epoch 01164: val_loss did not improve from 2.54449\n",
      "Epoch 1165/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7898 - val_loss: 2.5912\n",
      "\n",
      "Epoch 01165: val_loss did not improve from 2.54449\n",
      "Epoch 1166/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7952 - val_loss: 2.5947\n",
      "\n",
      "Epoch 01166: val_loss did not improve from 2.54449\n",
      "Epoch 1167/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7813 - val_loss: 2.5947\n",
      "\n",
      "Epoch 01167: val_loss did not improve from 2.54449\n",
      "Epoch 1168/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7877 - val_loss: 2.5902\n",
      "\n",
      "Epoch 01168: val_loss did not improve from 2.54449\n",
      "Epoch 1169/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7833 - val_loss: 2.5809\n",
      "\n",
      "Epoch 01169: val_loss did not improve from 2.54449\n",
      "Epoch 1170/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7756 - val_loss: 2.5814\n",
      "\n",
      "Epoch 01170: val_loss did not improve from 2.54449\n",
      "Epoch 1171/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7876 - val_loss: 2.5835\n",
      "\n",
      "Epoch 01171: val_loss did not improve from 2.54449\n",
      "Epoch 1172/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7798 - val_loss: 2.5980\n",
      "\n",
      "Epoch 01172: val_loss did not improve from 2.54449\n",
      "Epoch 1173/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7853 - val_loss: 2.6015\n",
      "\n",
      "Epoch 01173: val_loss did not improve from 2.54449\n",
      "Epoch 1174/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7896 - val_loss: 2.5967\n",
      "\n",
      "Epoch 01174: val_loss did not improve from 2.54449\n",
      "Epoch 1175/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7862 - val_loss: 2.6004\n",
      "\n",
      "Epoch 01175: val_loss did not improve from 2.54449\n",
      "Epoch 1176/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7894 - val_loss: 2.5968\n",
      "\n",
      "Epoch 01176: val_loss did not improve from 2.54449\n",
      "Epoch 1177/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7854 - val_loss: 2.5965\n",
      "\n",
      "Epoch 01177: val_loss did not improve from 2.54449\n",
      "Epoch 1178/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7896 - val_loss: 2.6024\n",
      "\n",
      "Epoch 01178: val_loss did not improve from 2.54449\n",
      "Epoch 1179/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7822 - val_loss: 2.6003\n",
      "\n",
      "Epoch 01179: val_loss did not improve from 2.54449\n",
      "Epoch 1180/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7874 - val_loss: 2.5931\n",
      "\n",
      "Epoch 01180: val_loss did not improve from 2.54449\n",
      "Epoch 1181/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7777 - val_loss: 2.5903\n",
      "\n",
      "Epoch 01181: val_loss did not improve from 2.54449\n",
      "Epoch 1182/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7830 - val_loss: 2.5830\n",
      "\n",
      "Epoch 01182: val_loss did not improve from 2.54449\n",
      "Epoch 1183/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7935 - val_loss: 2.5939\n",
      "\n",
      "Epoch 01183: val_loss did not improve from 2.54449\n",
      "Epoch 1184/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7920 - val_loss: 2.5980\n",
      "\n",
      "Epoch 01184: val_loss did not improve from 2.54449\n",
      "Epoch 1185/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7761 - val_loss: 2.5928\n",
      "\n",
      "Epoch 01185: val_loss did not improve from 2.54449\n",
      "Epoch 1186/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7966 - val_loss: 2.5850\n",
      "\n",
      "Epoch 01186: val_loss did not improve from 2.54449\n",
      "Epoch 1187/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7945 - val_loss: 2.5950\n",
      "\n",
      "Epoch 01187: val_loss did not improve from 2.54449\n",
      "Epoch 1188/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7839 - val_loss: 2.5929\n",
      "\n",
      "Epoch 01188: val_loss did not improve from 2.54449\n",
      "Epoch 1189/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7902 - val_loss: 2.5911\n",
      "\n",
      "Epoch 01189: val_loss did not improve from 2.54449\n",
      "Epoch 1190/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7848 - val_loss: 2.5838\n",
      "\n",
      "Epoch 01190: val_loss did not improve from 2.54449\n",
      "Epoch 1191/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7899 - val_loss: 2.5800\n",
      "\n",
      "Epoch 01191: val_loss did not improve from 2.54449\n",
      "Epoch 1192/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7916 - val_loss: 2.5870\n",
      "\n",
      "Epoch 01192: val_loss did not improve from 2.54449\n",
      "Epoch 1193/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7750 - val_loss: 2.5850\n",
      "\n",
      "Epoch 01193: val_loss did not improve from 2.54449\n",
      "Epoch 1194/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7864 - val_loss: 2.5989\n",
      "\n",
      "Epoch 01194: val_loss did not improve from 2.54449\n",
      "Epoch 1195/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7874 - val_loss: 2.5911\n",
      "\n",
      "Epoch 01195: val_loss did not improve from 2.54449\n",
      "Epoch 1196/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7892 - val_loss: 2.5798\n",
      "\n",
      "Epoch 01196: val_loss did not improve from 2.54449\n",
      "Epoch 1197/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7796 - val_loss: 2.5876\n",
      "\n",
      "Epoch 01197: val_loss did not improve from 2.54449\n",
      "Epoch 1198/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7796 - val_loss: 2.5907\n",
      "\n",
      "Epoch 01198: val_loss did not improve from 2.54449\n",
      "Epoch 1199/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7948 - val_loss: 2.5882\n",
      "\n",
      "Epoch 01199: val_loss did not improve from 2.54449\n",
      "Epoch 1200/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7939 - val_loss: 2.5984\n",
      "\n",
      "Epoch 01200: val_loss did not improve from 2.54449\n",
      "Epoch 1201/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7860 - val_loss: 2.5877\n",
      "\n",
      "Epoch 01201: val_loss did not improve from 2.54449\n",
      "Epoch 1202/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7792 - val_loss: 2.5949\n",
      "\n",
      "Epoch 01202: val_loss did not improve from 2.54449\n",
      "Epoch 1203/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7843 - val_loss: 2.5925\n",
      "\n",
      "Epoch 01203: val_loss did not improve from 2.54449\n",
      "Epoch 1204/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7831 - val_loss: 2.5789\n",
      "\n",
      "Epoch 01204: val_loss did not improve from 2.54449\n",
      "Epoch 1205/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7861 - val_loss: 2.6017\n",
      "\n",
      "Epoch 01205: val_loss did not improve from 2.54449\n",
      "Epoch 1206/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7912 - val_loss: 2.5975\n",
      "\n",
      "Epoch 01206: val_loss did not improve from 2.54449\n",
      "Epoch 1207/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7798 - val_loss: 2.5874\n",
      "\n",
      "Epoch 01207: val_loss did not improve from 2.54449\n",
      "Epoch 1208/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7862 - val_loss: 2.5879\n",
      "\n",
      "Epoch 01208: val_loss did not improve from 2.54449\n",
      "Epoch 1209/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7853 - val_loss: 2.5909\n",
      "\n",
      "Epoch 01209: val_loss did not improve from 2.54449\n",
      "Epoch 1210/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7820 - val_loss: 2.5851\n",
      "\n",
      "Epoch 01210: val_loss did not improve from 2.54449\n",
      "Epoch 1211/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7826 - val_loss: 2.6050\n",
      "\n",
      "Epoch 01211: val_loss did not improve from 2.54449\n",
      "Epoch 1212/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7949 - val_loss: 2.5917\n",
      "\n",
      "Epoch 01212: val_loss did not improve from 2.54449\n",
      "Epoch 1213/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7893 - val_loss: 2.5888\n",
      "\n",
      "Epoch 01213: val_loss did not improve from 2.54449\n",
      "Epoch 1214/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7960 - val_loss: 2.6023\n",
      "\n",
      "Epoch 01214: val_loss did not improve from 2.54449\n",
      "Epoch 1215/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7739 - val_loss: 2.6060\n",
      "\n",
      "Epoch 01215: val_loss did not improve from 2.54449\n",
      "Epoch 1216/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7870 - val_loss: 2.5898\n",
      "\n",
      "Epoch 01216: val_loss did not improve from 2.54449\n",
      "Epoch 1217/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7811 - val_loss: 2.5950\n",
      "\n",
      "Epoch 01217: val_loss did not improve from 2.54449\n",
      "Epoch 1218/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7907 - val_loss: 2.5900\n",
      "\n",
      "Epoch 01218: val_loss did not improve from 2.54449\n",
      "Epoch 1219/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7856 - val_loss: 2.5868\n",
      "\n",
      "Epoch 01219: val_loss did not improve from 2.54449\n",
      "Epoch 1220/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7779 - val_loss: 2.5770\n",
      "\n",
      "Epoch 01220: val_loss did not improve from 2.54449\n",
      "Epoch 1221/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7862 - val_loss: 2.5938\n",
      "\n",
      "Epoch 01221: val_loss did not improve from 2.54449\n",
      "Epoch 1222/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7908 - val_loss: 2.5955\n",
      "\n",
      "Epoch 01222: val_loss did not improve from 2.54449\n",
      "Epoch 1223/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7862 - val_loss: 2.5992\n",
      "\n",
      "Epoch 01223: val_loss did not improve from 2.54449\n",
      "Epoch 1224/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7817 - val_loss: 2.5887\n",
      "\n",
      "Epoch 01224: val_loss did not improve from 2.54449\n",
      "Epoch 1225/3000\n",
      "51530/51530 [==============================] - 15s 281us/step - loss: 1.7829 - val_loss: 2.5980\n",
      "\n",
      "Epoch 01225: val_loss did not improve from 2.54449\n",
      "Epoch 1226/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7758 - val_loss: 2.6003\n",
      "\n",
      "Epoch 01226: val_loss did not improve from 2.54449\n",
      "Epoch 1227/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7944 - val_loss: 2.5977\n",
      "\n",
      "Epoch 01227: val_loss did not improve from 2.54449\n",
      "Epoch 1228/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7891 - val_loss: 2.5996\n",
      "\n",
      "Epoch 01228: val_loss did not improve from 2.54449\n",
      "Epoch 1229/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7900 - val_loss: 2.6114\n",
      "\n",
      "Epoch 01229: val_loss did not improve from 2.54449\n",
      "Epoch 1230/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7804 - val_loss: 2.5968\n",
      "\n",
      "Epoch 01230: val_loss did not improve from 2.54449\n",
      "Epoch 1231/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7883 - val_loss: 2.6042\n",
      "\n",
      "Epoch 01231: val_loss did not improve from 2.54449\n",
      "Epoch 1232/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.8006 - val_loss: 2.6109\n",
      "\n",
      "Epoch 01232: val_loss did not improve from 2.54449\n",
      "Epoch 1233/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7989 - val_loss: 2.6042\n",
      "\n",
      "Epoch 01233: val_loss did not improve from 2.54449\n",
      "Epoch 1234/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7895 - val_loss: 2.5909\n",
      "\n",
      "Epoch 01234: val_loss did not improve from 2.54449\n",
      "Epoch 1235/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7666 - val_loss: 2.6020\n",
      "\n",
      "Epoch 01235: val_loss did not improve from 2.54449\n",
      "Epoch 1236/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7800 - val_loss: 2.6023\n",
      "\n",
      "Epoch 01236: val_loss did not improve from 2.54449\n",
      "Epoch 1237/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7796 - val_loss: 2.6048\n",
      "\n",
      "Epoch 01237: val_loss did not improve from 2.54449\n",
      "Epoch 1238/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7993 - val_loss: 2.6085\n",
      "\n",
      "Epoch 01238: val_loss did not improve from 2.54449\n",
      "Epoch 1239/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7881 - val_loss: 2.6001\n",
      "\n",
      "Epoch 01239: val_loss did not improve from 2.54449\n",
      "Epoch 1240/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7784 - val_loss: 2.6055\n",
      "\n",
      "Epoch 01240: val_loss did not improve from 2.54449\n",
      "Epoch 1241/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7932 - val_loss: 2.5950\n",
      "\n",
      "Epoch 01241: val_loss did not improve from 2.54449\n",
      "Epoch 1242/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7931 - val_loss: 2.6101\n",
      "\n",
      "Epoch 01242: val_loss did not improve from 2.54449\n",
      "Epoch 1243/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7826 - val_loss: 2.6072\n",
      "\n",
      "Epoch 01243: val_loss did not improve from 2.54449\n",
      "Epoch 1244/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7935 - val_loss: 2.5921\n",
      "\n",
      "Epoch 01244: val_loss did not improve from 2.54449\n",
      "Epoch 1245/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7895 - val_loss: 2.6176\n",
      "\n",
      "Epoch 01245: val_loss did not improve from 2.54449\n",
      "Epoch 1246/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.8003 - val_loss: 2.6106\n",
      "\n",
      "Epoch 01246: val_loss did not improve from 2.54449\n",
      "Epoch 1247/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7934 - val_loss: 2.5959\n",
      "\n",
      "Epoch 01247: val_loss did not improve from 2.54449\n",
      "Epoch 1248/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7849 - val_loss: 2.6034\n",
      "\n",
      "Epoch 01248: val_loss did not improve from 2.54449\n",
      "Epoch 1249/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7703 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01249: val_loss did not improve from 2.54449\n",
      "Epoch 1250/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7762 - val_loss: 2.6058\n",
      "\n",
      "Epoch 01250: val_loss did not improve from 2.54449\n",
      "Epoch 1251/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7855 - val_loss: 2.6068\n",
      "\n",
      "Epoch 01251: val_loss did not improve from 2.54449\n",
      "Epoch 1252/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7802 - val_loss: 2.5882\n",
      "\n",
      "Epoch 01252: val_loss did not improve from 2.54449\n",
      "Epoch 1253/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7903 - val_loss: 2.5960\n",
      "\n",
      "Epoch 01253: val_loss did not improve from 2.54449\n",
      "Epoch 1254/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7949 - val_loss: 2.6112\n",
      "\n",
      "Epoch 01254: val_loss did not improve from 2.54449\n",
      "Epoch 1255/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7974 - val_loss: 2.5979\n",
      "\n",
      "Epoch 01255: val_loss did not improve from 2.54449\n",
      "Epoch 1256/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7885 - val_loss: 2.6071\n",
      "\n",
      "Epoch 01256: val_loss did not improve from 2.54449\n",
      "Epoch 1257/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7941 - val_loss: 2.6061\n",
      "\n",
      "Epoch 01257: val_loss did not improve from 2.54449\n",
      "Epoch 1258/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7928 - val_loss: 2.6024\n",
      "\n",
      "Epoch 01258: val_loss did not improve from 2.54449\n",
      "Epoch 1259/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7901 - val_loss: 2.6041\n",
      "\n",
      "Epoch 01259: val_loss did not improve from 2.54449\n",
      "Epoch 1260/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7835 - val_loss: 2.6063\n",
      "\n",
      "Epoch 01260: val_loss did not improve from 2.54449\n",
      "Epoch 1261/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7974 - val_loss: 2.5914\n",
      "\n",
      "Epoch 01261: val_loss did not improve from 2.54449\n",
      "Epoch 1262/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7900 - val_loss: 2.6191\n",
      "\n",
      "Epoch 01262: val_loss did not improve from 2.54449\n",
      "Epoch 1263/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7897 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01263: val_loss did not improve from 2.54449\n",
      "Epoch 1264/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7837 - val_loss: 2.6123\n",
      "\n",
      "Epoch 01264: val_loss did not improve from 2.54449\n",
      "Epoch 1265/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7891 - val_loss: 2.6148\n",
      "\n",
      "Epoch 01265: val_loss did not improve from 2.54449\n",
      "Epoch 1266/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7915 - val_loss: 2.6139\n",
      "\n",
      "Epoch 01266: val_loss did not improve from 2.54449\n",
      "Epoch 1267/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7883 - val_loss: 2.5961\n",
      "\n",
      "Epoch 01267: val_loss did not improve from 2.54449\n",
      "Epoch 1268/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7861 - val_loss: 2.6014\n",
      "\n",
      "Epoch 01268: val_loss did not improve from 2.54449\n",
      "Epoch 1269/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7753 - val_loss: 2.5902\n",
      "\n",
      "Epoch 01269: val_loss did not improve from 2.54449\n",
      "Epoch 1270/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7898 - val_loss: 2.5976\n",
      "\n",
      "Epoch 01270: val_loss did not improve from 2.54449\n",
      "Epoch 1271/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.7912 - val_loss: 2.6058\n",
      "\n",
      "Epoch 01271: val_loss did not improve from 2.54449\n",
      "Epoch 1272/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7792 - val_loss: 2.5998\n",
      "\n",
      "Epoch 01272: val_loss did not improve from 2.54449\n",
      "Epoch 1273/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7912 - val_loss: 2.6031\n",
      "\n",
      "Epoch 01273: val_loss did not improve from 2.54449\n",
      "Epoch 1274/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7883 - val_loss: 2.6044\n",
      "\n",
      "Epoch 01274: val_loss did not improve from 2.54449\n",
      "Epoch 1275/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7928 - val_loss: 2.5982\n",
      "\n",
      "Epoch 01275: val_loss did not improve from 2.54449\n",
      "Epoch 1276/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7835 - val_loss: 2.6080\n",
      "\n",
      "Epoch 01276: val_loss did not improve from 2.54449\n",
      "Epoch 1277/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7988 - val_loss: 2.6120\n",
      "\n",
      "Epoch 01277: val_loss did not improve from 2.54449\n",
      "Epoch 1278/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7856 - val_loss: 2.6180\n",
      "\n",
      "Epoch 01278: val_loss did not improve from 2.54449\n",
      "Epoch 1279/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7824 - val_loss: 2.5866\n",
      "\n",
      "Epoch 01279: val_loss did not improve from 2.54449\n",
      "Epoch 1280/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7843 - val_loss: 2.6034\n",
      "\n",
      "Epoch 01280: val_loss did not improve from 2.54449\n",
      "Epoch 1281/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7849 - val_loss: 2.6159\n",
      "\n",
      "Epoch 01281: val_loss did not improve from 2.54449\n",
      "Epoch 1282/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7873 - val_loss: 2.6080\n",
      "\n",
      "Epoch 01282: val_loss did not improve from 2.54449\n",
      "Epoch 1283/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7901 - val_loss: 2.6055\n",
      "\n",
      "Epoch 01283: val_loss did not improve from 2.54449\n",
      "Epoch 1284/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7883 - val_loss: 2.6110\n",
      "\n",
      "Epoch 01284: val_loss did not improve from 2.54449\n",
      "Epoch 1285/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7899 - val_loss: 2.6109\n",
      "\n",
      "Epoch 01285: val_loss did not improve from 2.54449\n",
      "Epoch 1286/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7922 - val_loss: 2.5868\n",
      "\n",
      "Epoch 01286: val_loss did not improve from 2.54449\n",
      "Epoch 1287/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7726 - val_loss: 2.6155\n",
      "\n",
      "Epoch 01287: val_loss did not improve from 2.54449\n",
      "Epoch 1288/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7878 - val_loss: 2.6181\n",
      "\n",
      "Epoch 01288: val_loss did not improve from 2.54449\n",
      "Epoch 1289/3000\n",
      "51530/51530 [==============================] - 14s 273us/step - loss: 1.7939 - val_loss: 2.5939\n",
      "\n",
      "Epoch 01289: val_loss did not improve from 2.54449\n",
      "Epoch 1290/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7872 - val_loss: 2.6155\n",
      "\n",
      "Epoch 01290: val_loss did not improve from 2.54449\n",
      "Epoch 1291/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7865 - val_loss: 2.5984\n",
      "\n",
      "Epoch 01291: val_loss did not improve from 2.54449\n",
      "Epoch 1292/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7859 - val_loss: 2.5924\n",
      "\n",
      "Epoch 01292: val_loss did not improve from 2.54449\n",
      "Epoch 1293/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7754 - val_loss: 2.5873\n",
      "\n",
      "Epoch 01293: val_loss did not improve from 2.54449\n",
      "Epoch 1294/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7815 - val_loss: 2.5876\n",
      "\n",
      "Epoch 01294: val_loss did not improve from 2.54449\n",
      "Epoch 1295/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7830 - val_loss: 2.5984\n",
      "\n",
      "Epoch 01295: val_loss did not improve from 2.54449\n",
      "Epoch 1296/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7887 - val_loss: 2.6001\n",
      "\n",
      "Epoch 01296: val_loss did not improve from 2.54449\n",
      "Epoch 1297/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7872 - val_loss: 2.6064\n",
      "\n",
      "Epoch 01297: val_loss did not improve from 2.54449\n",
      "Epoch 1298/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7900 - val_loss: 2.5944\n",
      "\n",
      "Epoch 01298: val_loss did not improve from 2.54449\n",
      "Epoch 1299/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7790 - val_loss: 2.5889\n",
      "\n",
      "Epoch 01299: val_loss did not improve from 2.54449\n",
      "Epoch 1300/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7850 - val_loss: 2.6066\n",
      "\n",
      "Epoch 01300: val_loss did not improve from 2.54449\n",
      "Epoch 1301/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7810 - val_loss: 2.5900\n",
      "\n",
      "Epoch 01301: val_loss did not improve from 2.54449\n",
      "Epoch 1302/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7797 - val_loss: 2.5830\n",
      "\n",
      "Epoch 01302: val_loss did not improve from 2.54449\n",
      "Epoch 1303/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7903 - val_loss: 2.5873\n",
      "\n",
      "Epoch 01303: val_loss did not improve from 2.54449\n",
      "Epoch 1304/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7884 - val_loss: 2.5979\n",
      "\n",
      "Epoch 01304: val_loss did not improve from 2.54449\n",
      "Epoch 1305/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7866 - val_loss: 2.6034\n",
      "\n",
      "Epoch 01305: val_loss did not improve from 2.54449\n",
      "Epoch 1306/3000\n",
      "51530/51530 [==============================] - 14s 271us/step - loss: 1.7822 - val_loss: 2.6135\n",
      "\n",
      "Epoch 01306: val_loss did not improve from 2.54449\n",
      "Epoch 1307/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7842 - val_loss: 2.6046\n",
      "\n",
      "Epoch 01307: val_loss did not improve from 2.54449\n",
      "Epoch 1308/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7859 - val_loss: 2.6058\n",
      "\n",
      "Epoch 01308: val_loss did not improve from 2.54449\n",
      "Epoch 1309/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7846 - val_loss: 2.6123\n",
      "\n",
      "Epoch 01309: val_loss did not improve from 2.54449\n",
      "Epoch 1310/3000\n",
      "51530/51530 [==============================] - 14s 273us/step - loss: 1.7978 - val_loss: 2.6144\n",
      "\n",
      "Epoch 01310: val_loss did not improve from 2.54449\n",
      "Epoch 1311/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7871 - val_loss: 2.5964\n",
      "\n",
      "Epoch 01311: val_loss did not improve from 2.54449\n",
      "Epoch 1312/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7764 - val_loss: 2.5990\n",
      "\n",
      "Epoch 01312: val_loss did not improve from 2.54449\n",
      "Epoch 1313/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7836 - val_loss: 2.5977\n",
      "\n",
      "Epoch 01313: val_loss did not improve from 2.54449\n",
      "Epoch 1314/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7986 - val_loss: 2.6026\n",
      "\n",
      "Epoch 01314: val_loss did not improve from 2.54449\n",
      "Epoch 1315/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7850 - val_loss: 2.5931\n",
      "\n",
      "Epoch 01315: val_loss did not improve from 2.54449\n",
      "Epoch 1316/3000\n",
      "51530/51530 [==============================] - 14s 271us/step - loss: 1.7968 - val_loss: 2.6085\n",
      "\n",
      "Epoch 01316: val_loss did not improve from 2.54449\n",
      "Epoch 1317/3000\n",
      "51530/51530 [==============================] - 14s 273us/step - loss: 1.7941 - val_loss: 2.6074\n",
      "\n",
      "Epoch 01317: val_loss did not improve from 2.54449\n",
      "Epoch 1318/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7803 - val_loss: 2.6164\n",
      "\n",
      "Epoch 01318: val_loss did not improve from 2.54449\n",
      "Epoch 1319/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7866 - val_loss: 2.5983\n",
      "\n",
      "Epoch 01319: val_loss did not improve from 2.54449\n",
      "Epoch 1320/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7834 - val_loss: 2.6047\n",
      "\n",
      "Epoch 01320: val_loss did not improve from 2.54449\n",
      "Epoch 1321/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7874 - val_loss: 2.6106\n",
      "\n",
      "Epoch 01321: val_loss did not improve from 2.54449\n",
      "Epoch 1322/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7947 - val_loss: 2.6011\n",
      "\n",
      "Epoch 01322: val_loss did not improve from 2.54449\n",
      "Epoch 1323/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7842 - val_loss: 2.5980\n",
      "\n",
      "Epoch 01323: val_loss did not improve from 2.54449\n",
      "Epoch 1324/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7966 - val_loss: 2.5893\n",
      "\n",
      "Epoch 01324: val_loss did not improve from 2.54449\n",
      "Epoch 1325/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7824 - val_loss: 2.6114\n",
      "\n",
      "Epoch 01325: val_loss did not improve from 2.54449\n",
      "Epoch 1326/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7869 - val_loss: 2.6016\n",
      "\n",
      "Epoch 01326: val_loss did not improve from 2.54449\n",
      "Epoch 1327/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7899 - val_loss: 2.5927\n",
      "\n",
      "Epoch 01327: val_loss did not improve from 2.54449\n",
      "Epoch 1328/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7881 - val_loss: 2.5932\n",
      "\n",
      "Epoch 01328: val_loss did not improve from 2.54449\n",
      "Epoch 1329/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7769 - val_loss: 2.5868\n",
      "\n",
      "Epoch 01329: val_loss did not improve from 2.54449\n",
      "Epoch 1330/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7799 - val_loss: 2.5967\n",
      "\n",
      "Epoch 01330: val_loss did not improve from 2.54449\n",
      "Epoch 1331/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7858 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01331: val_loss did not improve from 2.54449\n",
      "Epoch 1332/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7777 - val_loss: 2.5934\n",
      "\n",
      "Epoch 01332: val_loss did not improve from 2.54449\n",
      "Epoch 1333/3000\n",
      "51530/51530 [==============================] - 14s 273us/step - loss: 1.8003 - val_loss: 2.5987\n",
      "\n",
      "Epoch 01333: val_loss did not improve from 2.54449\n",
      "Epoch 1334/3000\n",
      "51530/51530 [==============================] - 14s 273us/step - loss: 1.7962 - val_loss: 2.5825\n",
      "\n",
      "Epoch 01334: val_loss did not improve from 2.54449\n",
      "Epoch 1335/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7815 - val_loss: 2.5792\n",
      "\n",
      "Epoch 01335: val_loss did not improve from 2.54449\n",
      "Epoch 1336/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7814 - val_loss: 2.5923\n",
      "\n",
      "Epoch 01336: val_loss did not improve from 2.54449\n",
      "Epoch 1337/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7960 - val_loss: 2.5935\n",
      "\n",
      "Epoch 01337: val_loss did not improve from 2.54449\n",
      "Epoch 1338/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7889 - val_loss: 2.5828\n",
      "\n",
      "Epoch 01338: val_loss did not improve from 2.54449\n",
      "Epoch 1339/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7898 - val_loss: 2.5927\n",
      "\n",
      "Epoch 01339: val_loss did not improve from 2.54449\n",
      "Epoch 1340/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7889 - val_loss: 2.5924\n",
      "\n",
      "Epoch 01340: val_loss did not improve from 2.54449\n",
      "Epoch 1341/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7930 - val_loss: 2.5947\n",
      "\n",
      "Epoch 01341: val_loss did not improve from 2.54449\n",
      "Epoch 1342/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7748 - val_loss: 2.6056\n",
      "\n",
      "Epoch 01342: val_loss did not improve from 2.54449\n",
      "Epoch 1343/3000\n",
      "51530/51530 [==============================] - 14s 272us/step - loss: 1.7837 - val_loss: 2.6111\n",
      "\n",
      "Epoch 01343: val_loss did not improve from 2.54449\n",
      "Epoch 1344/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7842 - val_loss: 2.5986\n",
      "\n",
      "Epoch 01344: val_loss did not improve from 2.54449\n",
      "Epoch 1345/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7915 - val_loss: 2.6049\n",
      "\n",
      "Epoch 01345: val_loss did not improve from 2.54449\n",
      "Epoch 1346/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7758 - val_loss: 2.6017\n",
      "\n",
      "Epoch 01346: val_loss did not improve from 2.54449\n",
      "Epoch 1347/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7821 - val_loss: 2.6031\n",
      "\n",
      "Epoch 01347: val_loss did not improve from 2.54449\n",
      "Epoch 1348/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7800 - val_loss: 2.6113\n",
      "\n",
      "Epoch 01348: val_loss did not improve from 2.54449\n",
      "Epoch 1349/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7971 - val_loss: 2.6011\n",
      "\n",
      "Epoch 01349: val_loss did not improve from 2.54449\n",
      "Epoch 1350/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7861 - val_loss: 2.5967\n",
      "\n",
      "Epoch 01350: val_loss did not improve from 2.54449\n",
      "Epoch 1351/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7878 - val_loss: 2.5932\n",
      "\n",
      "Epoch 01351: val_loss did not improve from 2.54449\n",
      "Epoch 1352/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7960 - val_loss: 2.5906\n",
      "\n",
      "Epoch 01352: val_loss did not improve from 2.54449\n",
      "Epoch 1353/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7868 - val_loss: 2.6094\n",
      "\n",
      "Epoch 01353: val_loss did not improve from 2.54449\n",
      "Epoch 1354/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7890 - val_loss: 2.6061\n",
      "\n",
      "Epoch 01354: val_loss did not improve from 2.54449\n",
      "Epoch 1355/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7878 - val_loss: 2.5982\n",
      "\n",
      "Epoch 01355: val_loss did not improve from 2.54449\n",
      "Epoch 1356/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.8008 - val_loss: 2.5954\n",
      "\n",
      "Epoch 01356: val_loss did not improve from 2.54449\n",
      "Epoch 1357/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7781 - val_loss: 2.6121\n",
      "\n",
      "Epoch 01357: val_loss did not improve from 2.54449\n",
      "Epoch 1358/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7932 - val_loss: 2.6013\n",
      "\n",
      "Epoch 01358: val_loss did not improve from 2.54449\n",
      "Epoch 1359/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7876 - val_loss: 2.6054\n",
      "\n",
      "Epoch 01359: val_loss did not improve from 2.54449\n",
      "Epoch 1360/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7800 - val_loss: 2.6028\n",
      "\n",
      "Epoch 01360: val_loss did not improve from 2.54449\n",
      "Epoch 1361/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7855 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01361: val_loss did not improve from 2.54449\n",
      "Epoch 1362/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7999 - val_loss: 2.6036\n",
      "\n",
      "Epoch 01362: val_loss did not improve from 2.54449\n",
      "Epoch 1363/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7996 - val_loss: 2.6020\n",
      "\n",
      "Epoch 01363: val_loss did not improve from 2.54449\n",
      "Epoch 1364/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7909 - val_loss: 2.6059\n",
      "\n",
      "Epoch 01364: val_loss did not improve from 2.54449\n",
      "Epoch 1365/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7952 - val_loss: 2.5971\n",
      "\n",
      "Epoch 01365: val_loss did not improve from 2.54449\n",
      "Epoch 1366/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7758 - val_loss: 2.5887\n",
      "\n",
      "Epoch 01366: val_loss did not improve from 2.54449\n",
      "Epoch 1367/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7853 - val_loss: 2.5951\n",
      "\n",
      "Epoch 01367: val_loss did not improve from 2.54449\n",
      "Epoch 1368/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7877 - val_loss: 2.5903\n",
      "\n",
      "Epoch 01368: val_loss did not improve from 2.54449\n",
      "Epoch 1369/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7762 - val_loss: 2.5808\n",
      "\n",
      "Epoch 01369: val_loss did not improve from 2.54449\n",
      "Epoch 1370/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7903 - val_loss: 2.5902\n",
      "\n",
      "Epoch 01370: val_loss did not improve from 2.54449\n",
      "Epoch 1371/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7963 - val_loss: 2.5821\n",
      "\n",
      "Epoch 01371: val_loss did not improve from 2.54449\n",
      "Epoch 1372/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7909 - val_loss: 2.6042\n",
      "\n",
      "Epoch 01372: val_loss did not improve from 2.54449\n",
      "Epoch 1373/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7913 - val_loss: 2.6030\n",
      "\n",
      "Epoch 01373: val_loss did not improve from 2.54449\n",
      "Epoch 1374/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7827 - val_loss: 2.6021\n",
      "\n",
      "Epoch 01374: val_loss did not improve from 2.54449\n",
      "Epoch 1375/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7902 - val_loss: 2.6008\n",
      "\n",
      "Epoch 01375: val_loss did not improve from 2.54449\n",
      "Epoch 1376/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7861 - val_loss: 2.5852\n",
      "\n",
      "Epoch 01376: val_loss did not improve from 2.54449\n",
      "Epoch 1377/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7954 - val_loss: 2.5942\n",
      "\n",
      "Epoch 01377: val_loss did not improve from 2.54449\n",
      "Epoch 1378/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7764 - val_loss: 2.6057\n",
      "\n",
      "Epoch 01378: val_loss did not improve from 2.54449\n",
      "Epoch 1379/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7886 - val_loss: 2.6066\n",
      "\n",
      "Epoch 01379: val_loss did not improve from 2.54449\n",
      "Epoch 1380/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.8005 - val_loss: 2.6102\n",
      "\n",
      "Epoch 01380: val_loss did not improve from 2.54449\n",
      "Epoch 1381/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7971 - val_loss: 2.6070\n",
      "\n",
      "Epoch 01381: val_loss did not improve from 2.54449\n",
      "Epoch 1382/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7876 - val_loss: 2.5955\n",
      "\n",
      "Epoch 01382: val_loss did not improve from 2.54449\n",
      "Epoch 1383/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7925 - val_loss: 2.6076\n",
      "\n",
      "Epoch 01383: val_loss did not improve from 2.54449\n",
      "Epoch 1384/3000\n",
      "51530/51530 [==============================] - 18s 355us/step - loss: 1.7900 - val_loss: 2.6111\n",
      "\n",
      "Epoch 01384: val_loss did not improve from 2.54449\n",
      "Epoch 1385/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7864 - val_loss: 2.6068\n",
      "\n",
      "Epoch 01385: val_loss did not improve from 2.54449\n",
      "Epoch 1386/3000\n",
      "51530/51530 [==============================] - 16s 320us/step - loss: 1.7809 - val_loss: 2.6094\n",
      "\n",
      "Epoch 01386: val_loss did not improve from 2.54449\n",
      "Epoch 1387/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7885 - val_loss: 2.6075\n",
      "\n",
      "Epoch 01387: val_loss did not improve from 2.54449\n",
      "Epoch 1388/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7784 - val_loss: 2.5980\n",
      "\n",
      "Epoch 01388: val_loss did not improve from 2.54449\n",
      "Epoch 1389/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7891 - val_loss: 2.5939\n",
      "\n",
      "Epoch 01389: val_loss did not improve from 2.54449\n",
      "Epoch 1390/3000\n",
      "51530/51530 [==============================] - 21s 408us/step - loss: 1.7930 - val_loss: 2.6090\n",
      "\n",
      "Epoch 01390: val_loss did not improve from 2.54449\n",
      "Epoch 1391/3000\n",
      "51530/51530 [==============================] - 20s 388us/step - loss: 1.7817 - val_loss: 2.5998\n",
      "\n",
      "Epoch 01391: val_loss did not improve from 2.54449\n",
      "Epoch 1392/3000\n",
      "51530/51530 [==============================] - 18s 351us/step - loss: 1.7926 - val_loss: 2.6122\n",
      "\n",
      "Epoch 01392: val_loss did not improve from 2.54449\n",
      "Epoch 1393/3000\n",
      "51530/51530 [==============================] - 21s 398us/step - loss: 1.7755 - val_loss: 2.6093\n",
      "\n",
      "Epoch 01393: val_loss did not improve from 2.54449\n",
      "Epoch 1394/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7907 - val_loss: 2.5928\n",
      "\n",
      "Epoch 01394: val_loss did not improve from 2.54449\n",
      "Epoch 1395/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7818 - val_loss: 2.5908\n",
      "\n",
      "Epoch 01395: val_loss did not improve from 2.54449\n",
      "Epoch 1396/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7810 - val_loss: 2.5981\n",
      "\n",
      "Epoch 01396: val_loss did not improve from 2.54449\n",
      "Epoch 1397/3000\n",
      "51530/51530 [==============================] - 17s 334us/step - loss: 1.7970 - val_loss: 2.6050\n",
      "\n",
      "Epoch 01397: val_loss did not improve from 2.54449\n",
      "Epoch 1398/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7864 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01398: val_loss did not improve from 2.54449\n",
      "Epoch 1399/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7951 - val_loss: 2.6010\n",
      "\n",
      "Epoch 01399: val_loss did not improve from 2.54449\n",
      "Epoch 1400/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7793 - val_loss: 2.6013\n",
      "\n",
      "Epoch 01400: val_loss did not improve from 2.54449\n",
      "Epoch 1401/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7695 - val_loss: 2.6008\n",
      "\n",
      "Epoch 01401: val_loss did not improve from 2.54449\n",
      "Epoch 1402/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7921 - val_loss: 2.6025\n",
      "\n",
      "Epoch 01402: val_loss did not improve from 2.54449\n",
      "Epoch 1403/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7756 - val_loss: 2.5936\n",
      "\n",
      "Epoch 01403: val_loss did not improve from 2.54449\n",
      "Epoch 1404/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7858 - val_loss: 2.6018\n",
      "\n",
      "Epoch 01404: val_loss did not improve from 2.54449\n",
      "Epoch 1405/3000\n",
      "51530/51530 [==============================] - 17s 333us/step - loss: 1.8067 - val_loss: 2.6010\n",
      "\n",
      "Epoch 01405: val_loss did not improve from 2.54449\n",
      "Epoch 1406/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7829 - val_loss: 2.5923\n",
      "\n",
      "Epoch 01406: val_loss did not improve from 2.54449\n",
      "Epoch 1407/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7893 - val_loss: 2.6013\n",
      "\n",
      "Epoch 01407: val_loss did not improve from 2.54449\n",
      "Epoch 1408/3000\n",
      "51530/51530 [==============================] - 19s 359us/step - loss: 1.7853 - val_loss: 2.5856\n",
      "\n",
      "Epoch 01408: val_loss did not improve from 2.54449\n",
      "Epoch 1409/3000\n",
      "51530/51530 [==============================] - 19s 364us/step - loss: 1.7886 - val_loss: 2.5917\n",
      "\n",
      "Epoch 01409: val_loss did not improve from 2.54449\n",
      "Epoch 1410/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7880 - val_loss: 2.6011\n",
      "\n",
      "Epoch 01410: val_loss did not improve from 2.54449\n",
      "Epoch 1411/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7902 - val_loss: 2.5918\n",
      "\n",
      "Epoch 01411: val_loss did not improve from 2.54449\n",
      "Epoch 1412/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7902 - val_loss: 2.5933\n",
      "\n",
      "Epoch 01412: val_loss did not improve from 2.54449\n",
      "Epoch 1413/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7907 - val_loss: 2.6032\n",
      "\n",
      "Epoch 01413: val_loss did not improve from 2.54449\n",
      "Epoch 1414/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7894 - val_loss: 2.5801\n",
      "\n",
      "Epoch 01414: val_loss did not improve from 2.54449\n",
      "Epoch 1415/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7830 - val_loss: 2.5894\n",
      "\n",
      "Epoch 01415: val_loss did not improve from 2.54449\n",
      "Epoch 1416/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7844 - val_loss: 2.6151\n",
      "\n",
      "Epoch 01416: val_loss did not improve from 2.54449\n",
      "Epoch 1417/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7940 - val_loss: 2.5944\n",
      "\n",
      "Epoch 01417: val_loss did not improve from 2.54449\n",
      "Epoch 1418/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7892 - val_loss: 2.6006\n",
      "\n",
      "Epoch 01418: val_loss did not improve from 2.54449\n",
      "Epoch 1419/3000\n",
      "51530/51530 [==============================] - 18s 349us/step - loss: 1.7784 - val_loss: 2.5963\n",
      "\n",
      "Epoch 01419: val_loss did not improve from 2.54449\n",
      "Epoch 1420/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7936 - val_loss: 2.6083\n",
      "\n",
      "Epoch 01420: val_loss did not improve from 2.54449\n",
      "Epoch 1421/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7809 - val_loss: 2.6053\n",
      "\n",
      "Epoch 01421: val_loss did not improve from 2.54449\n",
      "Epoch 1422/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7982 - val_loss: 2.5992\n",
      "\n",
      "Epoch 01422: val_loss did not improve from 2.54449\n",
      "Epoch 1423/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7872 - val_loss: 2.5856\n",
      "\n",
      "Epoch 01423: val_loss did not improve from 2.54449\n",
      "Epoch 1424/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7864 - val_loss: 2.6032\n",
      "\n",
      "Epoch 01424: val_loss did not improve from 2.54449\n",
      "Epoch 1425/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7986 - val_loss: 2.5848\n",
      "\n",
      "Epoch 01425: val_loss did not improve from 2.54449\n",
      "Epoch 1426/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7942 - val_loss: 2.5948\n",
      "\n",
      "Epoch 01426: val_loss did not improve from 2.54449\n",
      "Epoch 1427/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7809 - val_loss: 2.5919\n",
      "\n",
      "Epoch 01427: val_loss did not improve from 2.54449\n",
      "Epoch 1428/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7743 - val_loss: 2.5914\n",
      "\n",
      "Epoch 01428: val_loss did not improve from 2.54449\n",
      "Epoch 1429/3000\n",
      "51530/51530 [==============================] - 17s 321us/step - loss: 1.7922 - val_loss: 2.5979\n",
      "\n",
      "Epoch 01429: val_loss did not improve from 2.54449\n",
      "Epoch 1430/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7889 - val_loss: 2.6111\n",
      "\n",
      "Epoch 01430: val_loss did not improve from 2.54449\n",
      "Epoch 1431/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.8004 - val_loss: 2.5916\n",
      "\n",
      "Epoch 01431: val_loss did not improve from 2.54449\n",
      "Epoch 1432/3000\n",
      "51530/51530 [==============================] - 16s 316us/step - loss: 1.7855 - val_loss: 2.6015\n",
      "\n",
      "Epoch 01432: val_loss did not improve from 2.54449\n",
      "Epoch 1433/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7915 - val_loss: 2.5932\n",
      "\n",
      "Epoch 01433: val_loss did not improve from 2.54449\n",
      "Epoch 1434/3000\n",
      "51530/51530 [==============================] - 17s 340us/step - loss: 1.8005 - val_loss: 2.5982\n",
      "\n",
      "Epoch 01434: val_loss did not improve from 2.54449\n",
      "Epoch 1435/3000\n",
      "51530/51530 [==============================] - 18s 345us/step - loss: 1.8081 - val_loss: 2.5880\n",
      "\n",
      "Epoch 01435: val_loss did not improve from 2.54449\n",
      "Epoch 1436/3000\n",
      "51530/51530 [==============================] - 20s 380us/step - loss: 1.7808 - val_loss: 2.5916\n",
      "\n",
      "Epoch 01436: val_loss did not improve from 2.54449\n",
      "Epoch 1437/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7904 - val_loss: 2.5906\n",
      "\n",
      "Epoch 01437: val_loss did not improve from 2.54449\n",
      "Epoch 1438/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7945 - val_loss: 2.5970\n",
      "\n",
      "Epoch 01438: val_loss did not improve from 2.54449\n",
      "Epoch 1439/3000\n",
      "51530/51530 [==============================] - 21s 402us/step - loss: 1.7957 - val_loss: 2.5771\n",
      "\n",
      "Epoch 01439: val_loss did not improve from 2.54449\n",
      "Epoch 1440/3000\n",
      "51530/51530 [==============================] - 19s 367us/step - loss: 1.7936 - val_loss: 2.5861\n",
      "\n",
      "Epoch 01440: val_loss did not improve from 2.54449\n",
      "Epoch 1441/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7993 - val_loss: 2.5928\n",
      "\n",
      "Epoch 01441: val_loss did not improve from 2.54449\n",
      "Epoch 1442/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7933 - val_loss: 2.5896\n",
      "\n",
      "Epoch 01442: val_loss did not improve from 2.54449\n",
      "Epoch 1443/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7805 - val_loss: 2.6002\n",
      "\n",
      "Epoch 01443: val_loss did not improve from 2.54449\n",
      "Epoch 1444/3000\n",
      "51530/51530 [==============================] - 18s 347us/step - loss: 1.7854 - val_loss: 2.5916\n",
      "\n",
      "Epoch 01444: val_loss did not improve from 2.54449\n",
      "Epoch 1445/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7799 - val_loss: 2.5861\n",
      "\n",
      "Epoch 01445: val_loss did not improve from 2.54449\n",
      "Epoch 1446/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7973 - val_loss: 2.6006\n",
      "\n",
      "Epoch 01446: val_loss did not improve from 2.54449\n",
      "Epoch 1447/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7870 - val_loss: 2.6101\n",
      "\n",
      "Epoch 01447: val_loss did not improve from 2.54449\n",
      "Epoch 1448/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7837 - val_loss: 2.6038\n",
      "\n",
      "Epoch 01448: val_loss did not improve from 2.54449\n",
      "Epoch 1449/3000\n",
      "51530/51530 [==============================] - 19s 366us/step - loss: 1.7866 - val_loss: 2.5873\n",
      "\n",
      "Epoch 01449: val_loss did not improve from 2.54449\n",
      "Epoch 1450/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 20s 397us/step - loss: 1.7916 - val_loss: 2.5909\n",
      "\n",
      "Epoch 01450: val_loss did not improve from 2.54449\n",
      "Epoch 1451/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.7778 - val_loss: 2.5881\n",
      "\n",
      "Epoch 01451: val_loss did not improve from 2.54449\n",
      "Epoch 1452/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.8015 - val_loss: 2.5909\n",
      "\n",
      "Epoch 01452: val_loss did not improve from 2.54449\n",
      "Epoch 1453/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7906 - val_loss: 2.5914\n",
      "\n",
      "Epoch 01453: val_loss did not improve from 2.54449\n",
      "Epoch 1454/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7919 - val_loss: 2.5886\n",
      "\n",
      "Epoch 01454: val_loss did not improve from 2.54449\n",
      "Epoch 1455/3000\n",
      "51530/51530 [==============================] - 16s 313us/step - loss: 1.7842 - val_loss: 2.5938\n",
      "\n",
      "Epoch 01455: val_loss did not improve from 2.54449\n",
      "Epoch 1456/3000\n",
      "51530/51530 [==============================] - 17s 328us/step - loss: 1.7894 - val_loss: 2.6013\n",
      "\n",
      "Epoch 01456: val_loss did not improve from 2.54449\n",
      "Epoch 1457/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7906 - val_loss: 2.6042\n",
      "\n",
      "Epoch 01457: val_loss did not improve from 2.54449\n",
      "Epoch 1458/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7875 - val_loss: 2.5929\n",
      "\n",
      "Epoch 01458: val_loss did not improve from 2.54449\n",
      "Epoch 1459/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7906 - val_loss: 2.5960\n",
      "\n",
      "Epoch 01459: val_loss did not improve from 2.54449\n",
      "Epoch 1460/3000\n",
      "51530/51530 [==============================] - 16s 318us/step - loss: 1.7778 - val_loss: 2.5880\n",
      "\n",
      "Epoch 01460: val_loss did not improve from 2.54449\n",
      "Epoch 1461/3000\n",
      "51530/51530 [==============================] - 18s 345us/step - loss: 1.7826 - val_loss: 2.5956\n",
      "\n",
      "Epoch 01461: val_loss did not improve from 2.54449\n",
      "Epoch 1462/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7864 - val_loss: 2.6002\n",
      "\n",
      "Epoch 01462: val_loss did not improve from 2.54449\n",
      "Epoch 1463/3000\n",
      "51530/51530 [==============================] - 18s 343us/step - loss: 1.7770 - val_loss: 2.5938\n",
      "\n",
      "Epoch 01463: val_loss did not improve from 2.54449\n",
      "Epoch 1464/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7833 - val_loss: 2.5881\n",
      "\n",
      "Epoch 01464: val_loss did not improve from 2.54449\n",
      "Epoch 1465/3000\n",
      "51530/51530 [==============================] - 16s 312us/step - loss: 1.7883 - val_loss: 2.6044\n",
      "\n",
      "Epoch 01465: val_loss did not improve from 2.54449\n",
      "Epoch 1466/3000\n",
      "51530/51530 [==============================] - 18s 351us/step - loss: 1.7908 - val_loss: 2.5906\n",
      "\n",
      "Epoch 01466: val_loss did not improve from 2.54449\n",
      "Epoch 1467/3000\n",
      "51530/51530 [==============================] - 20s 383us/step - loss: 1.7948 - val_loss: 2.6156\n",
      "\n",
      "Epoch 01467: val_loss did not improve from 2.54449\n",
      "Epoch 1468/3000\n",
      "51530/51530 [==============================] - 19s 372us/step - loss: 1.7830 - val_loss: 2.5819\n",
      "\n",
      "Epoch 01468: val_loss did not improve from 2.54449\n",
      "Epoch 1469/3000\n",
      "51530/51530 [==============================] - 21s 401us/step - loss: 1.7809 - val_loss: 2.5918\n",
      "\n",
      "Epoch 01469: val_loss did not improve from 2.54449\n",
      "Epoch 1470/3000\n",
      "51530/51530 [==============================] - 19s 366us/step - loss: 1.8056 - val_loss: 2.6088\n",
      "\n",
      "Epoch 01470: val_loss did not improve from 2.54449\n",
      "Epoch 1471/3000\n",
      "51530/51530 [==============================] - 19s 364us/step - loss: 1.7923 - val_loss: 2.6137\n",
      "\n",
      "Epoch 01471: val_loss did not improve from 2.54449\n",
      "Epoch 1472/3000\n",
      "51530/51530 [==============================] - 19s 361us/step - loss: 1.8074 - val_loss: 2.6036\n",
      "\n",
      "Epoch 01472: val_loss did not improve from 2.54449\n",
      "Epoch 1473/3000\n",
      "51530/51530 [==============================] - 19s 377us/step - loss: 1.7966 - val_loss: 2.6085\n",
      "\n",
      "Epoch 01473: val_loss did not improve from 2.54449\n",
      "Epoch 1474/3000\n",
      "51530/51530 [==============================] - 18s 354us/step - loss: 1.8018 - val_loss: 2.6198\n",
      "\n",
      "Epoch 01474: val_loss did not improve from 2.54449\n",
      "Epoch 1475/3000\n",
      "51530/51530 [==============================] - 16s 314us/step - loss: 1.7891 - val_loss: 2.6024\n",
      "\n",
      "Epoch 01475: val_loss did not improve from 2.54449\n",
      "Epoch 1476/3000\n",
      "51530/51530 [==============================] - 17s 331us/step - loss: 1.7882 - val_loss: 2.5948\n",
      "\n",
      "Epoch 01476: val_loss did not improve from 2.54449\n",
      "Epoch 1477/3000\n",
      "51530/51530 [==============================] - 18s 341us/step - loss: 1.7878 - val_loss: 2.5989\n",
      "\n",
      "Epoch 01477: val_loss did not improve from 2.54449\n",
      "Epoch 1478/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7816 - val_loss: 2.5841\n",
      "\n",
      "Epoch 01478: val_loss did not improve from 2.54449\n",
      "Epoch 1479/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7814 - val_loss: 2.6027\n",
      "\n",
      "Epoch 01479: val_loss did not improve from 2.54449\n",
      "Epoch 1480/3000\n",
      "51530/51530 [==============================] - 18s 349us/step - loss: 1.7902 - val_loss: 2.5947\n",
      "\n",
      "Epoch 01480: val_loss did not improve from 2.54449\n",
      "Epoch 1481/3000\n",
      "51530/51530 [==============================] - 17s 322us/step - loss: 1.7922 - val_loss: 2.6142\n",
      "\n",
      "Epoch 01481: val_loss did not improve from 2.54449\n",
      "Epoch 1482/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7898 - val_loss: 2.5917\n",
      "\n",
      "Epoch 01482: val_loss did not improve from 2.54449\n",
      "Epoch 1483/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7854 - val_loss: 2.5971\n",
      "\n",
      "Epoch 01483: val_loss did not improve from 2.54449\n",
      "Epoch 1484/3000\n",
      "51530/51530 [==============================] - 20s 392us/step - loss: 1.7917 - val_loss: 2.6000\n",
      "\n",
      "Epoch 01484: val_loss did not improve from 2.54449\n",
      "Epoch 1485/3000\n",
      "51530/51530 [==============================] - 18s 355us/step - loss: 1.7803 - val_loss: 2.6057\n",
      "\n",
      "Epoch 01485: val_loss did not improve from 2.54449\n",
      "Epoch 1486/3000\n",
      "51530/51530 [==============================] - 18s 355us/step - loss: 1.7825 - val_loss: 2.6091\n",
      "\n",
      "Epoch 01486: val_loss did not improve from 2.54449\n",
      "Epoch 1487/3000\n",
      "51530/51530 [==============================] - 20s 395us/step - loss: 1.7965 - val_loss: 2.5934\n",
      "\n",
      "Epoch 01487: val_loss did not improve from 2.54449\n",
      "Epoch 1488/3000\n",
      "51530/51530 [==============================] - 19s 368us/step - loss: 1.7925 - val_loss: 2.5946\n",
      "\n",
      "Epoch 01488: val_loss did not improve from 2.54449\n",
      "Epoch 1489/3000\n",
      "51530/51530 [==============================] - 18s 356us/step - loss: 1.7910 - val_loss: 2.6015\n",
      "\n",
      "Epoch 01489: val_loss did not improve from 2.54449\n",
      "Epoch 1490/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7985 - val_loss: 2.5999\n",
      "\n",
      "Epoch 01490: val_loss did not improve from 2.54449\n",
      "Epoch 1491/3000\n",
      "51530/51530 [==============================] - 17s 335us/step - loss: 1.7777 - val_loss: 2.5913\n",
      "\n",
      "Epoch 01491: val_loss did not improve from 2.54449\n",
      "Epoch 1492/3000\n",
      "51530/51530 [==============================] - 21s 400us/step - loss: 1.7857 - val_loss: 2.6001\n",
      "\n",
      "Epoch 01492: val_loss did not improve from 2.54449\n",
      "Epoch 1493/3000\n",
      "51530/51530 [==============================] - 18s 354us/step - loss: 1.7897 - val_loss: 2.6025\n",
      "\n",
      "Epoch 01493: val_loss did not improve from 2.54449\n",
      "Epoch 1494/3000\n",
      "51530/51530 [==============================] - 19s 364us/step - loss: 1.7933 - val_loss: 2.6041\n",
      "\n",
      "Epoch 01494: val_loss did not improve from 2.54449\n",
      "Epoch 1495/3000\n",
      "51530/51530 [==============================] - 19s 363us/step - loss: 1.7989 - val_loss: 2.6012\n",
      "\n",
      "Epoch 01495: val_loss did not improve from 2.54449\n",
      "Epoch 1496/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7961 - val_loss: 2.5942\n",
      "\n",
      "Epoch 01496: val_loss did not improve from 2.54449\n",
      "Epoch 1497/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7983 - val_loss: 2.6098\n",
      "\n",
      "Epoch 01497: val_loss did not improve from 2.54449\n",
      "Epoch 1498/3000\n",
      "51530/51530 [==============================] - 18s 346us/step - loss: 1.8055 - val_loss: 2.5901\n",
      "\n",
      "Epoch 01498: val_loss did not improve from 2.54449\n",
      "Epoch 1499/3000\n",
      "51530/51530 [==============================] - 18s 344us/step - loss: 1.7835 - val_loss: 2.5943\n",
      "\n",
      "Epoch 01499: val_loss did not improve from 2.54449\n",
      "Epoch 1500/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 19s 377us/step - loss: 1.7899 - val_loss: 2.5937\n",
      "\n",
      "Epoch 01500: val_loss did not improve from 2.54449\n",
      "Epoch 1501/3000\n",
      "51530/51530 [==============================] - 19s 368us/step - loss: 1.7759 - val_loss: 2.5947\n",
      "\n",
      "Epoch 01501: val_loss did not improve from 2.54449\n",
      "Epoch 1502/3000\n",
      "51530/51530 [==============================] - 18s 353us/step - loss: 1.7939 - val_loss: 2.6004\n",
      "\n",
      "Epoch 01502: val_loss did not improve from 2.54449\n",
      "Epoch 1503/3000\n",
      "51530/51530 [==============================] - 19s 373us/step - loss: 1.7858 - val_loss: 2.6014\n",
      "\n",
      "Epoch 01503: val_loss did not improve from 2.54449\n",
      "Epoch 1504/3000\n",
      "51530/51530 [==============================] - 20s 392us/step - loss: 1.7860 - val_loss: 2.5954\n",
      "\n",
      "Epoch 01504: val_loss did not improve from 2.54449\n",
      "Epoch 1505/3000\n",
      "51530/51530 [==============================] - 20s 398us/step - loss: 1.7814 - val_loss: 2.5924\n",
      "\n",
      "Epoch 01505: val_loss did not improve from 2.54449\n",
      "Epoch 1506/3000\n",
      "51530/51530 [==============================] - 20s 379us/step - loss: 1.7904 - val_loss: 2.6015\n",
      "\n",
      "Epoch 01506: val_loss did not improve from 2.54449\n",
      "Epoch 1507/3000\n",
      "51530/51530 [==============================] - 20s 388us/step - loss: 1.7872 - val_loss: 2.6028\n",
      "\n",
      "Epoch 01507: val_loss did not improve from 2.54449\n",
      "Epoch 1508/3000\n",
      "51530/51530 [==============================] - 21s 400us/step - loss: 1.7876 - val_loss: 2.5973\n",
      "\n",
      "Epoch 01508: val_loss did not improve from 2.54449\n",
      "Epoch 1509/3000\n",
      "51530/51530 [==============================] - 17s 327us/step - loss: 1.7936 - val_loss: 2.6005\n",
      "\n",
      "Epoch 01509: val_loss did not improve from 2.54449\n",
      "Epoch 1510/3000\n",
      "51530/51530 [==============================] - 16s 317us/step - loss: 1.7894 - val_loss: 2.6024\n",
      "\n",
      "Epoch 01510: val_loss did not improve from 2.54449\n",
      "Epoch 1511/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7897 - val_loss: 2.6083\n",
      "\n",
      "Epoch 01511: val_loss did not improve from 2.54449\n",
      "Epoch 1512/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7954 - val_loss: 2.6140\n",
      "\n",
      "Epoch 01512: val_loss did not improve from 2.54449\n",
      "Epoch 1513/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7922 - val_loss: 2.6046\n",
      "\n",
      "Epoch 01513: val_loss did not improve from 2.54449\n",
      "Epoch 1514/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7851 - val_loss: 2.5989\n",
      "\n",
      "Epoch 01514: val_loss did not improve from 2.54449\n",
      "Epoch 1515/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7878 - val_loss: 2.6116\n",
      "\n",
      "Epoch 01515: val_loss did not improve from 2.54449\n",
      "Epoch 1516/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7870 - val_loss: 2.5898\n",
      "\n",
      "Epoch 01516: val_loss did not improve from 2.54449\n",
      "Epoch 1517/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7799 - val_loss: 2.6048\n",
      "\n",
      "Epoch 01517: val_loss did not improve from 2.54449\n",
      "Epoch 1518/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7858 - val_loss: 2.6028\n",
      "\n",
      "Epoch 01518: val_loss did not improve from 2.54449\n",
      "Epoch 1519/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7937 - val_loss: 2.5845\n",
      "\n",
      "Epoch 01519: val_loss did not improve from 2.54449\n",
      "Epoch 1520/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7813 - val_loss: 2.5964\n",
      "\n",
      "Epoch 01520: val_loss did not improve from 2.54449\n",
      "Epoch 1521/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7779 - val_loss: 2.5869\n",
      "\n",
      "Epoch 01521: val_loss did not improve from 2.54449\n",
      "Epoch 1522/3000\n",
      "51530/51530 [==============================] - 16s 308us/step - loss: 1.7880 - val_loss: 2.6070\n",
      "\n",
      "Epoch 01522: val_loss did not improve from 2.54449\n",
      "Epoch 1523/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7921 - val_loss: 2.6099\n",
      "\n",
      "Epoch 01523: val_loss did not improve from 2.54449\n",
      "Epoch 1524/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7826 - val_loss: 2.6032\n",
      "\n",
      "Epoch 01524: val_loss did not improve from 2.54449\n",
      "Epoch 1525/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7843 - val_loss: 2.6028\n",
      "\n",
      "Epoch 01525: val_loss did not improve from 2.54449\n",
      "Epoch 1526/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7875 - val_loss: 2.6157\n",
      "\n",
      "Epoch 01526: val_loss did not improve from 2.54449\n",
      "Epoch 1527/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7922 - val_loss: 2.5931\n",
      "\n",
      "Epoch 01527: val_loss did not improve from 2.54449\n",
      "Epoch 1528/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7850 - val_loss: 2.6051\n",
      "\n",
      "Epoch 01528: val_loss did not improve from 2.54449\n",
      "Epoch 1529/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7849 - val_loss: 2.5916\n",
      "\n",
      "Epoch 01529: val_loss did not improve from 2.54449\n",
      "Epoch 1530/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7966 - val_loss: 2.6104\n",
      "\n",
      "Epoch 01530: val_loss did not improve from 2.54449\n",
      "Epoch 1531/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7931 - val_loss: 2.6065\n",
      "\n",
      "Epoch 01531: val_loss did not improve from 2.54449\n",
      "Epoch 1532/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7935 - val_loss: 2.6030\n",
      "\n",
      "Epoch 01532: val_loss did not improve from 2.54449\n",
      "Epoch 1533/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7836 - val_loss: 2.5899\n",
      "\n",
      "Epoch 01533: val_loss did not improve from 2.54449\n",
      "Epoch 1534/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7852 - val_loss: 2.5997\n",
      "\n",
      "Epoch 01534: val_loss did not improve from 2.54449\n",
      "Epoch 1535/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7896 - val_loss: 2.5901\n",
      "\n",
      "Epoch 01535: val_loss did not improve from 2.54449\n",
      "Epoch 1536/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.7926 - val_loss: 2.6072\n",
      "\n",
      "Epoch 01536: val_loss did not improve from 2.54449\n",
      "Epoch 1537/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.7905 - val_loss: 2.6022\n",
      "\n",
      "Epoch 01537: val_loss did not improve from 2.54449\n",
      "Epoch 1538/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7825 - val_loss: 2.6068\n",
      "\n",
      "Epoch 01538: val_loss did not improve from 2.54449\n",
      "Epoch 1539/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7823 - val_loss: 2.6046\n",
      "\n",
      "Epoch 01539: val_loss did not improve from 2.54449\n",
      "Epoch 1540/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7923 - val_loss: 2.6042\n",
      "\n",
      "Epoch 01540: val_loss did not improve from 2.54449\n",
      "Epoch 1541/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7878 - val_loss: 2.6101\n",
      "\n",
      "Epoch 01541: val_loss did not improve from 2.54449\n",
      "Epoch 1542/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7895 - val_loss: 2.5944\n",
      "\n",
      "Epoch 01542: val_loss did not improve from 2.54449\n",
      "Epoch 1543/3000\n",
      "51530/51530 [==============================] - 14s 273us/step - loss: 1.7968 - val_loss: 2.5947\n",
      "\n",
      "Epoch 01543: val_loss did not improve from 2.54449\n",
      "Epoch 1544/3000\n",
      "51530/51530 [==============================] - 14s 273us/step - loss: 1.7886 - val_loss: 2.6042\n",
      "\n",
      "Epoch 01544: val_loss did not improve from 2.54449\n",
      "Epoch 1545/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7783 - val_loss: 2.6073\n",
      "\n",
      "Epoch 01545: val_loss did not improve from 2.54449\n",
      "Epoch 1546/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7845 - val_loss: 2.6096\n",
      "\n",
      "Epoch 01546: val_loss did not improve from 2.54449\n",
      "Epoch 1547/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7834 - val_loss: 2.6104\n",
      "\n",
      "Epoch 01547: val_loss did not improve from 2.54449\n",
      "Epoch 1548/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7895 - val_loss: 2.6018\n",
      "\n",
      "Epoch 01548: val_loss did not improve from 2.54449\n",
      "Epoch 1549/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7993 - val_loss: 2.6013\n",
      "\n",
      "Epoch 01549: val_loss did not improve from 2.54449\n",
      "Epoch 1550/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7959 - val_loss: 2.6072\n",
      "\n",
      "Epoch 01550: val_loss did not improve from 2.54449\n",
      "Epoch 1551/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7911 - val_loss: 2.5965\n",
      "\n",
      "Epoch 01551: val_loss did not improve from 2.54449\n",
      "Epoch 1552/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7924 - val_loss: 2.6038\n",
      "\n",
      "Epoch 01552: val_loss did not improve from 2.54449\n",
      "Epoch 1553/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7789 - val_loss: 2.5920\n",
      "\n",
      "Epoch 01553: val_loss did not improve from 2.54449\n",
      "Epoch 1554/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7897 - val_loss: 2.5896\n",
      "\n",
      "Epoch 01554: val_loss did not improve from 2.54449\n",
      "Epoch 1555/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7843 - val_loss: 2.6008\n",
      "\n",
      "Epoch 01555: val_loss did not improve from 2.54449\n",
      "Epoch 1556/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7949 - val_loss: 2.5974\n",
      "\n",
      "Epoch 01556: val_loss did not improve from 2.54449\n",
      "Epoch 1557/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7969 - val_loss: 2.5878\n",
      "\n",
      "Epoch 01557: val_loss did not improve from 2.54449\n",
      "Epoch 1558/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7868 - val_loss: 2.5913\n",
      "\n",
      "Epoch 01558: val_loss did not improve from 2.54449\n",
      "Epoch 1559/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7883 - val_loss: 2.5943\n",
      "\n",
      "Epoch 01559: val_loss did not improve from 2.54449\n",
      "Epoch 1560/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7807 - val_loss: 2.5957\n",
      "\n",
      "Epoch 01560: val_loss did not improve from 2.54449\n",
      "Epoch 1561/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7922 - val_loss: 2.6032\n",
      "\n",
      "Epoch 01561: val_loss did not improve from 2.54449\n",
      "Epoch 1562/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7873 - val_loss: 2.6124\n",
      "\n",
      "Epoch 01562: val_loss did not improve from 2.54449\n",
      "Epoch 1563/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.8004 - val_loss: 2.6150\n",
      "\n",
      "Epoch 01563: val_loss did not improve from 2.54449\n",
      "Epoch 1564/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7844 - val_loss: 2.6083\n",
      "\n",
      "Epoch 01564: val_loss did not improve from 2.54449\n",
      "Epoch 1565/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7742 - val_loss: 2.6056\n",
      "\n",
      "Epoch 01565: val_loss did not improve from 2.54449\n",
      "Epoch 1566/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7898 - val_loss: 2.6121\n",
      "\n",
      "Epoch 01566: val_loss did not improve from 2.54449\n",
      "Epoch 1567/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7875 - val_loss: 2.6024\n",
      "\n",
      "Epoch 01567: val_loss did not improve from 2.54449\n",
      "Epoch 1568/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7963 - val_loss: 2.5845\n",
      "\n",
      "Epoch 01568: val_loss did not improve from 2.54449\n",
      "Epoch 1569/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7801 - val_loss: 2.6057\n",
      "\n",
      "Epoch 01569: val_loss did not improve from 2.54449\n",
      "Epoch 1570/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7948 - val_loss: 2.5974\n",
      "\n",
      "Epoch 01570: val_loss did not improve from 2.54449\n",
      "Epoch 1571/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7837 - val_loss: 2.6057\n",
      "\n",
      "Epoch 01571: val_loss did not improve from 2.54449\n",
      "Epoch 1572/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7819 - val_loss: 2.5901\n",
      "\n",
      "Epoch 01572: val_loss did not improve from 2.54449\n",
      "Epoch 1573/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7804 - val_loss: 2.6032\n",
      "\n",
      "Epoch 01573: val_loss did not improve from 2.54449\n",
      "Epoch 1574/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7781 - val_loss: 2.6028\n",
      "\n",
      "Epoch 01574: val_loss did not improve from 2.54449\n",
      "Epoch 1575/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7912 - val_loss: 2.5940\n",
      "\n",
      "Epoch 01575: val_loss did not improve from 2.54449\n",
      "Epoch 1576/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7913 - val_loss: 2.6050\n",
      "\n",
      "Epoch 01576: val_loss did not improve from 2.54449\n",
      "Epoch 1577/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7910 - val_loss: 2.5917\n",
      "\n",
      "Epoch 01577: val_loss did not improve from 2.54449\n",
      "Epoch 1578/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7940 - val_loss: 2.6017\n",
      "\n",
      "Epoch 01578: val_loss did not improve from 2.54449\n",
      "Epoch 1579/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7882 - val_loss: 2.6017\n",
      "\n",
      "Epoch 01579: val_loss did not improve from 2.54449\n",
      "Epoch 1580/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7825 - val_loss: 2.6044\n",
      "\n",
      "Epoch 01580: val_loss did not improve from 2.54449\n",
      "Epoch 1581/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7902 - val_loss: 2.5975\n",
      "\n",
      "Epoch 01581: val_loss did not improve from 2.54449\n",
      "Epoch 1582/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.8043 - val_loss: 2.6088\n",
      "\n",
      "Epoch 01582: val_loss did not improve from 2.54449\n",
      "Epoch 1583/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7837 - val_loss: 2.5862\n",
      "\n",
      "Epoch 01583: val_loss did not improve from 2.54449\n",
      "Epoch 1584/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7893 - val_loss: 2.6119\n",
      "\n",
      "Epoch 01584: val_loss did not improve from 2.54449\n",
      "Epoch 1585/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7813 - val_loss: 2.5946\n",
      "\n",
      "Epoch 01585: val_loss did not improve from 2.54449\n",
      "Epoch 1586/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7879 - val_loss: 2.5833\n",
      "\n",
      "Epoch 01586: val_loss did not improve from 2.54449\n",
      "Epoch 1587/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7791 - val_loss: 2.5913\n",
      "\n",
      "Epoch 01587: val_loss did not improve from 2.54449\n",
      "Epoch 1588/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7793 - val_loss: 2.5944\n",
      "\n",
      "Epoch 01588: val_loss did not improve from 2.54449\n",
      "Epoch 1589/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7933 - val_loss: 2.6118\n",
      "\n",
      "Epoch 01589: val_loss did not improve from 2.54449\n",
      "Epoch 1590/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7933 - val_loss: 2.6098\n",
      "\n",
      "Epoch 01590: val_loss did not improve from 2.54449\n",
      "Epoch 1591/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7838 - val_loss: 2.6004\n",
      "\n",
      "Epoch 01591: val_loss did not improve from 2.54449\n",
      "Epoch 1592/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7946 - val_loss: 2.6129\n",
      "\n",
      "Epoch 01592: val_loss did not improve from 2.54449\n",
      "Epoch 1593/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7968 - val_loss: 2.5985\n",
      "\n",
      "Epoch 01593: val_loss did not improve from 2.54449\n",
      "Epoch 1594/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7920 - val_loss: 2.5981\n",
      "\n",
      "Epoch 01594: val_loss did not improve from 2.54449\n",
      "Epoch 1595/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7778 - val_loss: 2.5965\n",
      "\n",
      "Epoch 01595: val_loss did not improve from 2.54449\n",
      "Epoch 1596/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7847 - val_loss: 2.6159\n",
      "\n",
      "Epoch 01596: val_loss did not improve from 2.54449\n",
      "Epoch 1597/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7913 - val_loss: 2.6043\n",
      "\n",
      "Epoch 01597: val_loss did not improve from 2.54449\n",
      "Epoch 1598/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7941 - val_loss: 2.5904\n",
      "\n",
      "Epoch 01598: val_loss did not improve from 2.54449\n",
      "Epoch 1599/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7864 - val_loss: 2.6078\n",
      "\n",
      "Epoch 01599: val_loss did not improve from 2.54449\n",
      "Epoch 1600/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7895 - val_loss: 2.6158\n",
      "\n",
      "Epoch 01600: val_loss did not improve from 2.54449\n",
      "Epoch 1601/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7841 - val_loss: 2.6075\n",
      "\n",
      "Epoch 01601: val_loss did not improve from 2.54449\n",
      "Epoch 1602/3000\n",
      "51530/51530 [==============================] - 16s 310us/step - loss: 1.7818 - val_loss: 2.5975\n",
      "\n",
      "Epoch 01602: val_loss did not improve from 2.54449\n",
      "Epoch 1603/3000\n",
      "51530/51530 [==============================] - 16s 307us/step - loss: 1.8010 - val_loss: 2.5964\n",
      "\n",
      "Epoch 01603: val_loss did not improve from 2.54449\n",
      "Epoch 1604/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7885 - val_loss: 2.6156\n",
      "\n",
      "Epoch 01604: val_loss did not improve from 2.54449\n",
      "Epoch 1605/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7811 - val_loss: 2.5932\n",
      "\n",
      "Epoch 01605: val_loss did not improve from 2.54449\n",
      "Epoch 1606/3000\n",
      "51530/51530 [==============================] - 15s 283us/step - loss: 1.7957 - val_loss: 2.5986\n",
      "\n",
      "Epoch 01606: val_loss did not improve from 2.54449\n",
      "Epoch 1607/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7959 - val_loss: 2.5999\n",
      "\n",
      "Epoch 01607: val_loss did not improve from 2.54449\n",
      "Epoch 1608/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.8026 - val_loss: 2.5965\n",
      "\n",
      "Epoch 01608: val_loss did not improve from 2.54449\n",
      "Epoch 1609/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7872 - val_loss: 2.5965\n",
      "\n",
      "Epoch 01609: val_loss did not improve from 2.54449\n",
      "Epoch 1610/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7918 - val_loss: 2.5998\n",
      "\n",
      "Epoch 01610: val_loss did not improve from 2.54449\n",
      "Epoch 1611/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7955 - val_loss: 2.6018\n",
      "\n",
      "Epoch 01611: val_loss did not improve from 2.54449\n",
      "Epoch 1612/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7900 - val_loss: 2.6123\n",
      "\n",
      "Epoch 01612: val_loss did not improve from 2.54449\n",
      "Epoch 1613/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7800 - val_loss: 2.5992\n",
      "\n",
      "Epoch 01613: val_loss did not improve from 2.54449\n",
      "Epoch 1614/3000\n",
      "51530/51530 [==============================] - 15s 281us/step - loss: 1.7845 - val_loss: 2.5888\n",
      "\n",
      "Epoch 01614: val_loss did not improve from 2.54449\n",
      "Epoch 1615/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7972 - val_loss: 2.6028\n",
      "\n",
      "Epoch 01615: val_loss did not improve from 2.54449\n",
      "Epoch 1616/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.7830 - val_loss: 2.6004\n",
      "\n",
      "Epoch 01616: val_loss did not improve from 2.54449\n",
      "Epoch 1617/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7888 - val_loss: 2.5951\n",
      "\n",
      "Epoch 01617: val_loss did not improve from 2.54449\n",
      "Epoch 1618/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7809 - val_loss: 2.6051\n",
      "\n",
      "Epoch 01618: val_loss did not improve from 2.54449\n",
      "Epoch 1619/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7788 - val_loss: 2.6159\n",
      "\n",
      "Epoch 01619: val_loss did not improve from 2.54449\n",
      "Epoch 1620/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.8074 - val_loss: 2.6133\n",
      "\n",
      "Epoch 01620: val_loss did not improve from 2.54449\n",
      "Epoch 1621/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7908 - val_loss: 2.6144\n",
      "\n",
      "Epoch 01621: val_loss did not improve from 2.54449\n",
      "Epoch 1622/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7932 - val_loss: 2.5900\n",
      "\n",
      "Epoch 01622: val_loss did not improve from 2.54449\n",
      "Epoch 1623/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7776 - val_loss: 2.6147\n",
      "\n",
      "Epoch 01623: val_loss did not improve from 2.54449\n",
      "Epoch 1624/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7847 - val_loss: 2.6103\n",
      "\n",
      "Epoch 01624: val_loss did not improve from 2.54449\n",
      "Epoch 1625/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7922 - val_loss: 2.5948\n",
      "\n",
      "Epoch 01625: val_loss did not improve from 2.54449\n",
      "Epoch 1626/3000\n",
      "51530/51530 [==============================] - 16s 303us/step - loss: 1.7903 - val_loss: 2.6208\n",
      "\n",
      "Epoch 01626: val_loss did not improve from 2.54449\n",
      "Epoch 1627/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7934 - val_loss: 2.6231\n",
      "\n",
      "Epoch 01627: val_loss did not improve from 2.54449\n",
      "Epoch 1628/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7902 - val_loss: 2.6057\n",
      "\n",
      "Epoch 01628: val_loss did not improve from 2.54449\n",
      "Epoch 1629/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7855 - val_loss: 2.6171\n",
      "\n",
      "Epoch 01629: val_loss did not improve from 2.54449\n",
      "Epoch 1630/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7948 - val_loss: 2.6028\n",
      "\n",
      "Epoch 01630: val_loss did not improve from 2.54449\n",
      "Epoch 1631/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7900 - val_loss: 2.6086\n",
      "\n",
      "Epoch 01631: val_loss did not improve from 2.54449\n",
      "Epoch 1632/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7959 - val_loss: 2.6115\n",
      "\n",
      "Epoch 01632: val_loss did not improve from 2.54449\n",
      "Epoch 1633/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7921 - val_loss: 2.5991\n",
      "\n",
      "Epoch 01633: val_loss did not improve from 2.54449\n",
      "Epoch 1634/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7872 - val_loss: 2.6175\n",
      "\n",
      "Epoch 01634: val_loss did not improve from 2.54449\n",
      "Epoch 1635/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7936 - val_loss: 2.6044\n",
      "\n",
      "Epoch 01635: val_loss did not improve from 2.54449\n",
      "Epoch 1636/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7812 - val_loss: 2.6199\n",
      "\n",
      "Epoch 01636: val_loss did not improve from 2.54449\n",
      "Epoch 1637/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7902 - val_loss: 2.6085\n",
      "\n",
      "Epoch 01637: val_loss did not improve from 2.54449\n",
      "Epoch 1638/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7949 - val_loss: 2.6230\n",
      "\n",
      "Epoch 01638: val_loss did not improve from 2.54449\n",
      "Epoch 1639/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7849 - val_loss: 2.6101\n",
      "\n",
      "Epoch 01639: val_loss did not improve from 2.54449\n",
      "Epoch 1640/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7854 - val_loss: 2.6211\n",
      "\n",
      "Epoch 01640: val_loss did not improve from 2.54449\n",
      "Epoch 1641/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7971 - val_loss: 2.6114\n",
      "\n",
      "Epoch 01641: val_loss did not improve from 2.54449\n",
      "Epoch 1642/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7886 - val_loss: 2.6127\n",
      "\n",
      "Epoch 01642: val_loss did not improve from 2.54449\n",
      "Epoch 1643/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7995 - val_loss: 2.6174\n",
      "\n",
      "Epoch 01643: val_loss did not improve from 2.54449\n",
      "Epoch 1644/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7937 - val_loss: 2.6118\n",
      "\n",
      "Epoch 01644: val_loss did not improve from 2.54449\n",
      "Epoch 1645/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.8003 - val_loss: 2.6021\n",
      "\n",
      "Epoch 01645: val_loss did not improve from 2.54449\n",
      "Epoch 1646/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7966 - val_loss: 2.6052\n",
      "\n",
      "Epoch 01646: val_loss did not improve from 2.54449\n",
      "Epoch 1647/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7955 - val_loss: 2.6094\n",
      "\n",
      "Epoch 01647: val_loss did not improve from 2.54449\n",
      "Epoch 1648/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7893 - val_loss: 2.6138\n",
      "\n",
      "Epoch 01648: val_loss did not improve from 2.54449\n",
      "Epoch 1649/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7840 - val_loss: 2.6102\n",
      "\n",
      "Epoch 01649: val_loss did not improve from 2.54449\n",
      "Epoch 1650/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7873 - val_loss: 2.6077\n",
      "\n",
      "Epoch 01650: val_loss did not improve from 2.54449\n",
      "Epoch 1651/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7952 - val_loss: 2.6075\n",
      "\n",
      "Epoch 01651: val_loss did not improve from 2.54449\n",
      "Epoch 1652/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7894 - val_loss: 2.6035\n",
      "\n",
      "Epoch 01652: val_loss did not improve from 2.54449\n",
      "Epoch 1653/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.7960 - val_loss: 2.5995\n",
      "\n",
      "Epoch 01653: val_loss did not improve from 2.54449\n",
      "Epoch 1654/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7825 - val_loss: 2.6156\n",
      "\n",
      "Epoch 01654: val_loss did not improve from 2.54449\n",
      "Epoch 1655/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7972 - val_loss: 2.5976\n",
      "\n",
      "Epoch 01655: val_loss did not improve from 2.54449\n",
      "Epoch 1656/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7955 - val_loss: 2.6052\n",
      "\n",
      "Epoch 01656: val_loss did not improve from 2.54449\n",
      "Epoch 1657/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7952 - val_loss: 2.5940\n",
      "\n",
      "Epoch 01657: val_loss did not improve from 2.54449\n",
      "Epoch 1658/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.7887 - val_loss: 2.6003\n",
      "\n",
      "Epoch 01658: val_loss did not improve from 2.54449\n",
      "Epoch 1659/3000\n",
      "51530/51530 [==============================] - 15s 301us/step - loss: 1.7908 - val_loss: 2.6045\n",
      "\n",
      "Epoch 01659: val_loss did not improve from 2.54449\n",
      "Epoch 1660/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7889 - val_loss: 2.6080\n",
      "\n",
      "Epoch 01660: val_loss did not improve from 2.54449\n",
      "Epoch 1661/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7777 - val_loss: 2.5957\n",
      "\n",
      "Epoch 01661: val_loss did not improve from 2.54449\n",
      "Epoch 1662/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7870 - val_loss: 2.6015\n",
      "\n",
      "Epoch 01662: val_loss did not improve from 2.54449\n",
      "Epoch 1663/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7843 - val_loss: 2.5976\n",
      "\n",
      "Epoch 01663: val_loss did not improve from 2.54449\n",
      "Epoch 1664/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7853 - val_loss: 2.5990\n",
      "\n",
      "Epoch 01664: val_loss did not improve from 2.54449\n",
      "Epoch 1665/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.8004 - val_loss: 2.6037\n",
      "\n",
      "Epoch 01665: val_loss did not improve from 2.54449\n",
      "Epoch 1666/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7842 - val_loss: 2.6164\n",
      "\n",
      "Epoch 01666: val_loss did not improve from 2.54449\n",
      "Epoch 1667/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7871 - val_loss: 2.6070\n",
      "\n",
      "Epoch 01667: val_loss did not improve from 2.54449\n",
      "Epoch 1668/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7876 - val_loss: 2.6097\n",
      "\n",
      "Epoch 01668: val_loss did not improve from 2.54449\n",
      "Epoch 1669/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7904 - val_loss: 2.6078\n",
      "\n",
      "Epoch 01669: val_loss did not improve from 2.54449\n",
      "Epoch 1670/3000\n",
      "51530/51530 [==============================] - 16s 302us/step - loss: 1.8035 - val_loss: 2.5822\n",
      "\n",
      "Epoch 01670: val_loss did not improve from 2.54449\n",
      "Epoch 1671/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7845 - val_loss: 2.6029\n",
      "\n",
      "Epoch 01671: val_loss did not improve from 2.54449\n",
      "Epoch 1672/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7834 - val_loss: 2.5953\n",
      "\n",
      "Epoch 01672: val_loss did not improve from 2.54449\n",
      "Epoch 1673/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7977 - val_loss: 2.5957\n",
      "\n",
      "Epoch 01673: val_loss did not improve from 2.54449\n",
      "Epoch 1674/3000\n",
      "51530/51530 [==============================] - 14s 281us/step - loss: 1.8023 - val_loss: 2.6036\n",
      "\n",
      "Epoch 01674: val_loss did not improve from 2.54449\n",
      "Epoch 1675/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7850 - val_loss: 2.6148\n",
      "\n",
      "Epoch 01675: val_loss did not improve from 2.54449\n",
      "Epoch 1676/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7839 - val_loss: 2.6019\n",
      "\n",
      "Epoch 01676: val_loss did not improve from 2.54449\n",
      "Epoch 1677/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7899 - val_loss: 2.5972\n",
      "\n",
      "Epoch 01677: val_loss did not improve from 2.54449\n",
      "Epoch 1678/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7766 - val_loss: 2.6149\n",
      "\n",
      "Epoch 01678: val_loss did not improve from 2.54449\n",
      "Epoch 1679/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.8019 - val_loss: 2.5991\n",
      "\n",
      "Epoch 01679: val_loss did not improve from 2.54449\n",
      "Epoch 1680/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7872 - val_loss: 2.6021\n",
      "\n",
      "Epoch 01680: val_loss did not improve from 2.54449\n",
      "Epoch 1681/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7889 - val_loss: 2.6188\n",
      "\n",
      "Epoch 01681: val_loss did not improve from 2.54449\n",
      "Epoch 1682/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7978 - val_loss: 2.6010\n",
      "\n",
      "Epoch 01682: val_loss did not improve from 2.54449\n",
      "Epoch 1683/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.8035 - val_loss: 2.6121\n",
      "\n",
      "Epoch 01683: val_loss did not improve from 2.54449\n",
      "Epoch 1684/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7991 - val_loss: 2.6131\n",
      "\n",
      "Epoch 01684: val_loss did not improve from 2.54449\n",
      "Epoch 1685/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7925 - val_loss: 2.6033\n",
      "\n",
      "Epoch 01685: val_loss did not improve from 2.54449\n",
      "Epoch 1686/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7861 - val_loss: 2.6111\n",
      "\n",
      "Epoch 01686: val_loss did not improve from 2.54449\n",
      "Epoch 1687/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7772 - val_loss: 2.6276\n",
      "\n",
      "Epoch 01687: val_loss did not improve from 2.54449\n",
      "Epoch 1688/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7886 - val_loss: 2.6103\n",
      "\n",
      "Epoch 01688: val_loss did not improve from 2.54449\n",
      "Epoch 1689/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7897 - val_loss: 2.6137\n",
      "\n",
      "Epoch 01689: val_loss did not improve from 2.54449\n",
      "Epoch 1690/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.7946 - val_loss: 2.6086\n",
      "\n",
      "Epoch 01690: val_loss did not improve from 2.54449\n",
      "Epoch 1691/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7939 - val_loss: 2.6048\n",
      "\n",
      "Epoch 01691: val_loss did not improve from 2.54449\n",
      "Epoch 1692/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.8065 - val_loss: 2.6074\n",
      "\n",
      "Epoch 01692: val_loss did not improve from 2.54449\n",
      "Epoch 1693/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.8005 - val_loss: 2.6180\n",
      "\n",
      "Epoch 01693: val_loss did not improve from 2.54449\n",
      "Epoch 1694/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7881 - val_loss: 2.6124\n",
      "\n",
      "Epoch 01694: val_loss did not improve from 2.54449\n",
      "Epoch 1695/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7916 - val_loss: 2.6122\n",
      "\n",
      "Epoch 01695: val_loss did not improve from 2.54449\n",
      "Epoch 1696/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7890 - val_loss: 2.6080\n",
      "\n",
      "Epoch 01696: val_loss did not improve from 2.54449\n",
      "Epoch 1697/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.8011 - val_loss: 2.6231\n",
      "\n",
      "Epoch 01697: val_loss did not improve from 2.54449\n",
      "Epoch 1698/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7897 - val_loss: 2.6147\n",
      "\n",
      "Epoch 01698: val_loss did not improve from 2.54449\n",
      "Epoch 1699/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7895 - val_loss: 2.6196\n",
      "\n",
      "Epoch 01699: val_loss did not improve from 2.54449\n",
      "Epoch 1700/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7888 - val_loss: 2.6170\n",
      "\n",
      "Epoch 01700: val_loss did not improve from 2.54449\n",
      "Epoch 1701/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7849 - val_loss: 2.6124\n",
      "\n",
      "Epoch 01701: val_loss did not improve from 2.54449\n",
      "Epoch 1702/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7804 - val_loss: 2.6009\n",
      "\n",
      "Epoch 01702: val_loss did not improve from 2.54449\n",
      "Epoch 1703/3000\n",
      "51530/51530 [==============================] - 15s 298us/step - loss: 1.7853 - val_loss: 2.6111\n",
      "\n",
      "Epoch 01703: val_loss did not improve from 2.54449\n",
      "Epoch 1704/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7804 - val_loss: 2.6045\n",
      "\n",
      "Epoch 01704: val_loss did not improve from 2.54449\n",
      "Epoch 1705/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7832 - val_loss: 2.6020\n",
      "\n",
      "Epoch 01705: val_loss did not improve from 2.54449\n",
      "Epoch 1706/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7830 - val_loss: 2.6025\n",
      "\n",
      "Epoch 01706: val_loss did not improve from 2.54449\n",
      "Epoch 1707/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7878 - val_loss: 2.6107\n",
      "\n",
      "Epoch 01707: val_loss did not improve from 2.54449\n",
      "Epoch 1708/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7951 - val_loss: 2.6040\n",
      "\n",
      "Epoch 01708: val_loss did not improve from 2.54449\n",
      "Epoch 1709/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7907 - val_loss: 2.6156\n",
      "\n",
      "Epoch 01709: val_loss did not improve from 2.54449\n",
      "Epoch 1710/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7807 - val_loss: 2.6163\n",
      "\n",
      "Epoch 01710: val_loss did not improve from 2.54449\n",
      "Epoch 1711/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7889 - val_loss: 2.6161\n",
      "\n",
      "Epoch 01711: val_loss did not improve from 2.54449\n",
      "Epoch 1712/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7911 - val_loss: 2.6255\n",
      "\n",
      "Epoch 01712: val_loss did not improve from 2.54449\n",
      "Epoch 1713/3000\n",
      "51530/51530 [==============================] - 15s 299us/step - loss: 1.7892 - val_loss: 2.6099\n",
      "\n",
      "Epoch 01713: val_loss did not improve from 2.54449\n",
      "Epoch 1714/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7919 - val_loss: 2.6080\n",
      "\n",
      "Epoch 01714: val_loss did not improve from 2.54449\n",
      "Epoch 1715/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7899 - val_loss: 2.6179\n",
      "\n",
      "Epoch 01715: val_loss did not improve from 2.54449\n",
      "Epoch 1716/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7967 - val_loss: 2.6083\n",
      "\n",
      "Epoch 01716: val_loss did not improve from 2.54449\n",
      "Epoch 1717/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7949 - val_loss: 2.6079\n",
      "\n",
      "Epoch 01717: val_loss did not improve from 2.54449\n",
      "Epoch 1718/3000\n",
      "51530/51530 [==============================] - 14s 277us/step - loss: 1.7834 - val_loss: 2.5930\n",
      "\n",
      "Epoch 01718: val_loss did not improve from 2.54449\n",
      "Epoch 1719/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7842 - val_loss: 2.6037\n",
      "\n",
      "Epoch 01719: val_loss did not improve from 2.54449\n",
      "Epoch 1720/3000\n",
      "51530/51530 [==============================] - 14s 278us/step - loss: 1.7933 - val_loss: 2.6094\n",
      "\n",
      "Epoch 01720: val_loss did not improve from 2.54449\n",
      "Epoch 1721/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7893 - val_loss: 2.6158\n",
      "\n",
      "Epoch 01721: val_loss did not improve from 2.54449\n",
      "Epoch 1722/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.8038 - val_loss: 2.6237\n",
      "\n",
      "Epoch 01722: val_loss did not improve from 2.54449\n",
      "Epoch 1723/3000\n",
      "51530/51530 [==============================] - 15s 285us/step - loss: 1.8014 - val_loss: 2.6191\n",
      "\n",
      "Epoch 01723: val_loss did not improve from 2.54449\n",
      "Epoch 1724/3000\n",
      "51530/51530 [==============================] - 15s 300us/step - loss: 1.7877 - val_loss: 2.6137\n",
      "\n",
      "Epoch 01724: val_loss did not improve from 2.54449\n",
      "Epoch 1725/3000\n",
      "51530/51530 [==============================] - 15s 296us/step - loss: 1.7908 - val_loss: 2.5941\n",
      "\n",
      "Epoch 01725: val_loss did not improve from 2.54449\n",
      "Epoch 1726/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7911 - val_loss: 2.5999\n",
      "\n",
      "Epoch 01726: val_loss did not improve from 2.54449\n",
      "Epoch 1727/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7829 - val_loss: 2.6015\n",
      "\n",
      "Epoch 01727: val_loss did not improve from 2.54449\n",
      "Epoch 1728/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7824 - val_loss: 2.6112\n",
      "\n",
      "Epoch 01728: val_loss did not improve from 2.54449\n",
      "Epoch 1729/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7892 - val_loss: 2.6137\n",
      "\n",
      "Epoch 01729: val_loss did not improve from 2.54449\n",
      "Epoch 1730/3000\n",
      "51530/51530 [==============================] - 18s 340us/step - loss: 1.7889 - val_loss: 2.6063\n",
      "\n",
      "Epoch 01730: val_loss did not improve from 2.54449\n",
      "Epoch 1731/3000\n",
      "51530/51530 [==============================] - 18s 354us/step - loss: 1.7830 - val_loss: 2.6257\n",
      "\n",
      "Epoch 01731: val_loss did not improve from 2.54449\n",
      "Epoch 1732/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7704 - val_loss: 2.6084\n",
      "\n",
      "Epoch 01732: val_loss did not improve from 2.54449\n",
      "Epoch 1733/3000\n",
      "51530/51530 [==============================] - 14s 280us/step - loss: 1.7942 - val_loss: 2.6014\n",
      "\n",
      "Epoch 01733: val_loss did not improve from 2.54449\n",
      "Epoch 1734/3000\n",
      "51530/51530 [==============================] - 14s 279us/step - loss: 1.7879 - val_loss: 2.6017\n",
      "\n",
      "Epoch 01734: val_loss did not improve from 2.54449\n",
      "Epoch 1735/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7997 - val_loss: 2.6088\n",
      "\n",
      "Epoch 01735: val_loss did not improve from 2.54449\n",
      "Epoch 1736/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7944 - val_loss: 2.6144\n",
      "\n",
      "Epoch 01736: val_loss did not improve from 2.54449\n",
      "Epoch 1737/3000\n",
      "51530/51530 [==============================] - 16s 315us/step - loss: 1.7862 - val_loss: 2.6215\n",
      "\n",
      "Epoch 01737: val_loss did not improve from 2.54449\n",
      "Epoch 1738/3000\n",
      "51530/51530 [==============================] - 16s 301us/step - loss: 1.7933 - val_loss: 2.6188\n",
      "\n",
      "Epoch 01738: val_loss did not improve from 2.54449\n",
      "Epoch 1739/3000\n",
      "51530/51530 [==============================] - 16s 304us/step - loss: 1.7868 - val_loss: 2.6213\n",
      "\n",
      "Epoch 01739: val_loss did not improve from 2.54449\n",
      "Epoch 1740/3000\n",
      "51530/51530 [==============================] - 19s 371us/step - loss: 1.7919 - val_loss: 2.6112\n",
      "\n",
      "Epoch 01740: val_loss did not improve from 2.54449\n",
      "Epoch 1741/3000\n",
      "51530/51530 [==============================] - 19s 361us/step - loss: 1.7975 - val_loss: 2.6188\n",
      "\n",
      "Epoch 01741: val_loss did not improve from 2.54449\n",
      "Epoch 1742/3000\n",
      "51530/51530 [==============================] - 19s 362us/step - loss: 1.7970 - val_loss: 2.6137\n",
      "\n",
      "Epoch 01742: val_loss did not improve from 2.54449\n",
      "Epoch 1743/3000\n",
      "51530/51530 [==============================] - 18s 346us/step - loss: 1.7894 - val_loss: 2.6160\n",
      "\n",
      "Epoch 01743: val_loss did not improve from 2.54449\n",
      "Epoch 1744/3000\n",
      "51530/51530 [==============================] - 18s 358us/step - loss: 1.7919 - val_loss: 2.6116\n",
      "\n",
      "Epoch 01744: val_loss did not improve from 2.54449\n",
      "Epoch 1745/3000\n",
      "51530/51530 [==============================] - 19s 365us/step - loss: 1.7872 - val_loss: 2.6105\n",
      "\n",
      "Epoch 01745: val_loss did not improve from 2.54449\n",
      "Epoch 1746/3000\n",
      "51530/51530 [==============================] - 18s 356us/step - loss: 1.7927 - val_loss: 2.6120\n",
      "\n",
      "Epoch 01746: val_loss did not improve from 2.54449\n",
      "Epoch 1747/3000\n",
      "51530/51530 [==============================] - 18s 348us/step - loss: 1.8041 - val_loss: 2.6227\n",
      "\n",
      "Epoch 01747: val_loss did not improve from 2.54449\n",
      "Epoch 1748/3000\n",
      "51530/51530 [==============================] - 19s 375us/step - loss: 1.7915 - val_loss: 2.6115\n",
      "\n",
      "Epoch 01748: val_loss did not improve from 2.54449\n",
      "Epoch 1749/3000\n",
      "51530/51530 [==============================] - 18s 348us/step - loss: 1.7803 - val_loss: 2.6153\n",
      "\n",
      "Epoch 01749: val_loss did not improve from 2.54449\n",
      "Epoch 1750/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 18s 344us/step - loss: 1.7789 - val_loss: 2.6089\n",
      "\n",
      "Epoch 01750: val_loss did not improve from 2.54449\n",
      "Epoch 1751/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7899 - val_loss: 2.6120\n",
      "\n",
      "Epoch 01751: val_loss did not improve from 2.54449\n",
      "Epoch 1752/3000\n",
      "51530/51530 [==============================] - 14s 276us/step - loss: 1.7917 - val_loss: 2.6209\n",
      "\n",
      "Epoch 01752: val_loss did not improve from 2.54449\n",
      "Epoch 1753/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7985 - val_loss: 2.6201\n",
      "\n",
      "Epoch 01753: val_loss did not improve from 2.54449\n",
      "Epoch 1754/3000\n",
      "51530/51530 [==============================] - 17s 337us/step - loss: 1.7869 - val_loss: 2.6019\n",
      "\n",
      "Epoch 01754: val_loss did not improve from 2.54449\n",
      "Epoch 1755/3000\n",
      "51530/51530 [==============================] - 17s 330us/step - loss: 1.7783 - val_loss: 2.6113\n",
      "\n",
      "Epoch 01755: val_loss did not improve from 2.54449\n",
      "Epoch 1756/3000\n",
      "51530/51530 [==============================] - 16s 311us/step - loss: 1.7976 - val_loss: 2.6284\n",
      "\n",
      "Epoch 01756: val_loss did not improve from 2.54449\n",
      "Epoch 1757/3000\n",
      "51530/51530 [==============================] - 15s 297us/step - loss: 1.7779 - val_loss: 2.6269\n",
      "\n",
      "Epoch 01757: val_loss did not improve from 2.54449\n",
      "Epoch 1758/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7782 - val_loss: 2.6053\n",
      "\n",
      "Epoch 01758: val_loss did not improve from 2.54449\n",
      "Epoch 1759/3000\n",
      "51530/51530 [==============================] - 14s 275us/step - loss: 1.7808 - val_loss: 2.6181\n",
      "\n",
      "Epoch 01759: val_loss did not improve from 2.54449\n",
      "Epoch 1760/3000\n",
      "51530/51530 [==============================] - 16s 306us/step - loss: 1.8035 - val_loss: 2.6334\n",
      "\n",
      "Epoch 01760: val_loss did not improve from 2.54449\n",
      "Epoch 1761/3000\n",
      "51530/51530 [==============================] - 16s 305us/step - loss: 1.7861 - val_loss: 2.6165\n",
      "\n",
      "Epoch 01761: val_loss did not improve from 2.54449\n",
      "Epoch 1762/3000\n",
      "51530/51530 [==============================] - 15s 295us/step - loss: 1.7917 - val_loss: 2.6100\n",
      "\n",
      "Epoch 01762: val_loss did not improve from 2.54449\n",
      "Epoch 1763/3000\n",
      "51530/51530 [==============================] - 19s 371us/step - loss: 1.7898 - val_loss: 2.6140\n",
      "\n",
      "Epoch 01763: val_loss did not improve from 2.54449\n",
      "Epoch 1764/3000\n",
      "51530/51530 [==============================] - 18s 357us/step - loss: 1.7915 - val_loss: 2.6244\n",
      "\n",
      "Epoch 01764: val_loss did not improve from 2.54449\n",
      "Epoch 1765/3000\n",
      "51530/51530 [==============================] - 18s 341us/step - loss: 1.7969 - val_loss: 2.6236\n",
      "\n",
      "Epoch 01765: val_loss did not improve from 2.54449\n",
      "Epoch 1766/3000\n",
      "51530/51530 [==============================] - 19s 371us/step - loss: 1.7872 - val_loss: 2.6256\n",
      "\n",
      "Epoch 01766: val_loss did not improve from 2.54449\n",
      "Epoch 1767/3000\n",
      "51530/51530 [==============================] - 19s 369us/step - loss: 1.8000 - val_loss: 2.6062\n",
      "\n",
      "Epoch 01767: val_loss did not improve from 2.54449\n",
      "Epoch 1768/3000\n",
      "51530/51530 [==============================] - 20s 384us/step - loss: 1.8044 - val_loss: 2.6189\n",
      "\n",
      "Epoch 01768: val_loss did not improve from 2.54449\n",
      "Epoch 1769/3000\n",
      "51530/51530 [==============================] - 19s 378us/step - loss: 1.8005 - val_loss: 2.6161\n",
      "\n",
      "Epoch 01769: val_loss did not improve from 2.54449\n",
      "Epoch 1770/3000\n",
      "51530/51530 [==============================] - 20s 386us/step - loss: 1.7869 - val_loss: 2.6071\n",
      "\n",
      "Epoch 01770: val_loss did not improve from 2.54449\n",
      "Epoch 1771/3000\n",
      "51530/51530 [==============================] - 21s 407us/step - loss: 1.7916 - val_loss: 2.6206\n",
      "\n",
      "Epoch 01771: val_loss did not improve from 2.54449\n",
      "Epoch 1772/3000\n",
      "51530/51530 [==============================] - 18s 349us/step - loss: 1.7842 - val_loss: 2.6163\n",
      "\n",
      "Epoch 01772: val_loss did not improve from 2.54449\n",
      "Epoch 1773/3000\n",
      "51530/51530 [==============================] - 19s 370us/step - loss: 1.7818 - val_loss: 2.6142\n",
      "\n",
      "Epoch 01773: val_loss did not improve from 2.54449\n",
      "Epoch 1774/3000\n",
      "51530/51530 [==============================] - 20s 385us/step - loss: 1.7899 - val_loss: 2.6089\n",
      "\n",
      "Epoch 01774: val_loss did not improve from 2.54449\n",
      "Epoch 1775/3000\n",
      "51530/51530 [==============================] - 20s 396us/step - loss: 1.7915 - val_loss: 2.6212\n",
      "\n",
      "Epoch 01775: val_loss did not improve from 2.54449\n",
      "Epoch 1776/3000\n",
      "51530/51530 [==============================] - 20s 387us/step - loss: 1.7988 - val_loss: 2.6023\n",
      "\n",
      "Epoch 01776: val_loss did not improve from 2.54449\n",
      "Epoch 1777/3000\n",
      "51530/51530 [==============================] - 19s 375us/step - loss: 1.7789 - val_loss: 2.6018\n",
      "\n",
      "Epoch 01777: val_loss did not improve from 2.54449\n",
      "Epoch 1778/3000\n",
      "51530/51530 [==============================] - 18s 342us/step - loss: 1.7972 - val_loss: 2.6160\n",
      "\n",
      "Epoch 01778: val_loss did not improve from 2.54449\n",
      "Epoch 1779/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7873 - val_loss: 2.5980\n",
      "\n",
      "Epoch 01779: val_loss did not improve from 2.54449\n",
      "Epoch 1780/3000\n",
      "51530/51530 [==============================] - 16s 309us/step - loss: 1.7970 - val_loss: 2.6169\n",
      "\n",
      "Epoch 01780: val_loss did not improve from 2.54449\n",
      "Epoch 1781/3000\n",
      "51530/51530 [==============================] - 17s 326us/step - loss: 1.7900 - val_loss: 2.6013\n",
      "\n",
      "Epoch 01781: val_loss did not improve from 2.54449\n",
      "Epoch 1782/3000\n",
      "51530/51530 [==============================] - 18s 344us/step - loss: 1.7963 - val_loss: 2.6155\n",
      "\n",
      "Epoch 01782: val_loss did not improve from 2.54449\n",
      "Epoch 1783/3000\n",
      "51530/51530 [==============================] - 17s 325us/step - loss: 1.7958 - val_loss: 2.5986\n",
      "\n",
      "Epoch 01783: val_loss did not improve from 2.54449\n",
      "Epoch 1784/3000\n",
      "51530/51530 [==============================] - 17s 332us/step - loss: 1.7721 - val_loss: 2.6038\n",
      "\n",
      "Epoch 01784: val_loss did not improve from 2.54449\n",
      "Epoch 1785/3000\n",
      "51530/51530 [==============================] - 15s 294us/step - loss: 1.7872 - val_loss: 2.6062\n",
      "\n",
      "Epoch 01785: val_loss did not improve from 2.54449\n",
      "Epoch 1786/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7974 - val_loss: 2.6099\n",
      "\n",
      "Epoch 01786: val_loss did not improve from 2.54449\n",
      "Epoch 1787/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7876 - val_loss: 2.6135\n",
      "\n",
      "Epoch 01787: val_loss did not improve from 2.54449\n",
      "Epoch 1788/3000\n",
      "51530/51530 [==============================] - 15s 286us/step - loss: 1.7898 - val_loss: 2.5940\n",
      "\n",
      "Epoch 01788: val_loss did not improve from 2.54449\n",
      "Epoch 1789/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7934 - val_loss: 2.6272\n",
      "\n",
      "Epoch 01789: val_loss did not improve from 2.54449\n",
      "Epoch 1790/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7952 - val_loss: 2.6210\n",
      "\n",
      "Epoch 01790: val_loss did not improve from 2.54449\n",
      "Epoch 1791/3000\n",
      "51530/51530 [==============================] - 15s 287us/step - loss: 1.7972 - val_loss: 2.6188\n",
      "\n",
      "Epoch 01791: val_loss did not improve from 2.54449\n",
      "Epoch 1792/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7912 - val_loss: 2.6256\n",
      "\n",
      "Epoch 01792: val_loss did not improve from 2.54449\n",
      "Epoch 1793/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7827 - val_loss: 2.6133\n",
      "\n",
      "Epoch 01793: val_loss did not improve from 2.54449\n",
      "Epoch 1794/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7983 - val_loss: 2.6305\n",
      "\n",
      "Epoch 01794: val_loss did not improve from 2.54449\n",
      "Epoch 1795/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7977 - val_loss: 2.6020\n",
      "\n",
      "Epoch 01795: val_loss did not improve from 2.54449\n",
      "Epoch 1796/3000\n",
      "51530/51530 [==============================] - 15s 289us/step - loss: 1.7994 - val_loss: 2.5988\n",
      "\n",
      "Epoch 01796: val_loss did not improve from 2.54449\n",
      "Epoch 1797/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7831 - val_loss: 2.5949\n",
      "\n",
      "Epoch 01797: val_loss did not improve from 2.54449\n",
      "Epoch 1798/3000\n",
      "51530/51530 [==============================] - 15s 291us/step - loss: 1.7879 - val_loss: 2.6002\n",
      "\n",
      "Epoch 01798: val_loss did not improve from 2.54449\n",
      "Epoch 1799/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.7819 - val_loss: 2.6141\n",
      "\n",
      "Epoch 01799: val_loss did not improve from 2.54449\n",
      "Epoch 1800/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7997 - val_loss: 2.6048\n",
      "\n",
      "Epoch 01800: val_loss did not improve from 2.54449\n",
      "Epoch 1801/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7959 - val_loss: 2.6003\n",
      "\n",
      "Epoch 01801: val_loss did not improve from 2.54449\n",
      "Epoch 1802/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7932 - val_loss: 2.6204\n",
      "\n",
      "Epoch 01802: val_loss did not improve from 2.54449\n",
      "Epoch 1803/3000\n",
      "51530/51530 [==============================] - 15s 293us/step - loss: 1.8042 - val_loss: 2.6132\n",
      "\n",
      "Epoch 01803: val_loss did not improve from 2.54449\n",
      "Epoch 1804/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7932 - val_loss: 2.6129\n",
      "\n",
      "Epoch 01804: val_loss did not improve from 2.54449\n",
      "Epoch 1805/3000\n",
      "51530/51530 [==============================] - 15s 290us/step - loss: 1.7859 - val_loss: 2.5953\n",
      "\n",
      "Epoch 01805: val_loss did not improve from 2.54449\n",
      "Epoch 1806/3000\n",
      "51530/51530 [==============================] - 15s 292us/step - loss: 1.7811 - val_loss: 2.6091\n",
      "\n",
      "Epoch 01806: val_loss did not improve from 2.54449\n",
      "Epoch 1807/3000\n",
      "51530/51530 [==============================] - 17s 329us/step - loss: 1.7971 - val_loss: 2.6026\n",
      "\n",
      "Epoch 01807: val_loss did not improve from 2.54449\n",
      "Epoch 1808/3000\n",
      "51530/51530 [==============================] - 17s 336us/step - loss: 1.7939 - val_loss: 2.6065\n",
      "\n",
      "Epoch 01808: val_loss did not improve from 2.54449\n",
      "Epoch 1809/3000\n",
      "51530/51530 [==============================] - 15s 288us/step - loss: 1.7833 - val_loss: 2.6051\n",
      "\n",
      "Epoch 01809: val_loss did not improve from 2.54449\n",
      "Epoch 1810/3000\n",
      "51530/51530 [==============================] - 15s 282us/step - loss: 1.7832 - val_loss: 2.6119\n",
      "\n",
      "Epoch 01810: val_loss did not improve from 2.54449\n",
      "Epoch 1811/3000\n",
      "51530/51530 [==============================] - 14s 274us/step - loss: 1.7834 - val_loss: 2.6319\n",
      "\n",
      "Epoch 01811: val_loss did not improve from 2.54449\n",
      "Epoch 1812/3000\n",
      "51530/51530 [==============================] - 14s 268us/step - loss: 1.7894 - val_loss: 2.6263\n",
      "\n",
      "Epoch 01812: val_loss did not improve from 2.54449\n",
      "Epoch 1813/3000\n",
      "51530/51530 [==============================] - 16s 319us/step - loss: 1.7978 - val_loss: 2.6197\n",
      "\n",
      "Epoch 01813: val_loss did not improve from 2.54449\n",
      "Epoch 1814/3000\n",
      "51530/51530 [==============================] - 15s 284us/step - loss: 1.7871 - val_loss: 2.6121\n",
      "\n",
      "Epoch 01814: val_loss did not improve from 2.54449\n",
      "Epoch 1815/3000\n",
      "28032/51530 [===============>..............] - ETA: 6s - loss: 1.7635"
     ]
    }
   ],
   "source": [
    "#training wavenet model\n",
    "history = model.fit(np.array(x_tr),\n",
    "                    np.array(y_tr),\n",
    "                    batch_size=128,\n",
    "                    epochs=3000, \n",
    "                    validation_data=(np.array(x_val),\n",
    "                                     np.array(y_val)),\n",
    "                    verbose=1, \n",
    "                    callbacks=[mc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Step 8: Prediction</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading best model\n",
    "from keras.models import load_model\n",
    "model = load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 37, 70, 70, 70, 70, 70, 70, 125, 70, 70, 70, 10, 10, 18, 76, 87, 125, 87, 10, 10, 10, 125, 125, 10, 125, 125, 125, 76, 76, 85, 76, 11, 76, 33, 85, 85, 85, 85, 85, 85, 85, 85, 85, 18, 18, 18, 18, 18, 18]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = np.random.randint(0,len(x_val)-1)\n",
    "\n",
    "random_music = x_val[ind]\n",
    "\n",
    "# print(random_music)\n",
    "\n",
    "predictions=[]\n",
    "for i in range(50):\n",
    "\n",
    "    random_music = random_music.reshape(1,no_of_timesteps)\n",
    "\n",
    "    prob  = model.predict(random_music)[0]\n",
    "    y_pred= np.argmax(prob,axis=0)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "    random_music = np.insert(random_music[0],len(random_music[0]),y_pred)\n",
    "    random_music = random_music[1:]\n",
    "    \n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the intergers back into notes\n",
    "x_int_to_note = dict((number, note_) for number, note_ in enumerate(unique_x)) \n",
    "predicted_notes = [x_int_to_note[i] for i in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_midi(prediction_output):\n",
    "   \n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "    for pattern in prediction_output:\n",
    "        \n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                \n",
    "                cn=int(current_note)\n",
    "                new_note = note.Note(cn)\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "                \n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "            \n",
    "        # pattern is a note\n",
    "        else:\n",
    "            \n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 1\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    midi_stream.write('midi', fp='music.mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_to_midi(predicted_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
